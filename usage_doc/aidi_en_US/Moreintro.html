

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Software Introduction &mdash; AIDI 3.2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=4f6ddb47"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Introduction to Tool Usage" href="moduleintro.html" />
    <link rel="prev" title="Reference" href="Reference.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            AIDI
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="AIDIintroduce.html">Introduction to AIDI</a></li>
<li class="toctree-l1"><a class="reference internal" href="opintro.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="SecondaryDevelopment.html">Secondary Development Guidelines</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="Reference.html">Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Software Introduction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#functional-layout">Functional layout</a></li>
<li class="toctree-l3"><a class="reference internal" href="#terminological-concepts">Terminological concepts</a></li>
<li class="toctree-l3"><a class="reference internal" href="#engineering-management">Engineering management</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#engineering-management-sample-case">Engineering management Sample Case</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#image-operation">Image operation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#import-image">Import Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-export">Data export</a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-import">Data import</a></li>
<li class="toctree-l4"><a class="reference internal" href="#annotations-between-different-modules-support-each-other">Annotations between different modules support each other</a></li>
<li class="toctree-l4"><a class="reference internal" href="#compatible-with-old-version-annotations">Compatible with old version annotations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#third-party-annotation-import">Third party annotation import</a></li>
<li class="toctree-l4"><a class="reference internal" href="#image-list-function">Image list function</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#add-tools">Add tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-annotation">Data annotation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#brush-tools">Brush tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="#annotation-mode">Annotation mode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#label-management">Label management</a></li>
<li class="toctree-l3"><a class="reference internal" href="#annotation-filtering">Annotation filtering</a></li>
<li class="toctree-l3"><a class="reference internal" href="#annotation-distribution">Annotation distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tag-management">Tag management</a></li>
<li class="toctree-l3"><a class="reference internal" href="#view-operations">View operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#view-filtering">View filtering</a></li>
<li class="toctree-l4"><a class="reference internal" href="#view-transformation">View transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#view-mask">View Mask</a></li>
<li class="toctree-l4"><a class="reference internal" href="#view-conversion-image-list-filter">View Conversion - Image List Filter</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#add-training-set">Add training set</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#automatic-partitioning-model-training-assistant">Automatic partitioning (model training assistant)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#manual-division">Manual division</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#training">Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#training-parameter">Training Parameter</a></li>
<li class="toctree-l4"><a class="reference internal" href="#execute-training">Execute training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#inference">Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#inference-parameter">Inference Parameter</a></li>
<li class="toctree-l4"><a class="reference internal" href="#execute-inference">Execute inference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#evaluation-results">Evaluation results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#confusion-matrix">Confusion matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="#category-overview">Category Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-details">Model details</a></li>
<li class="toctree-l4"><a class="reference internal" href="#training-curve">Training Curve</a></li>
<li class="toctree-l4"><a class="reference internal" href="#more">More</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#image-filtering">Image filtering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#filter">Filter</a></li>
<li class="toctree-l4"><a class="reference internal" href="#sort">Sort</a></li>
<li class="toctree-l4"><a class="reference internal" href="#list-right-click-menu">List right-click menu</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#menu-bar">Menu bar</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#files">Files</a></li>
<li class="toctree-l4"><a class="reference internal" href="#version">Version</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tools">Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="#image">Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="#training-inference">Training &amp; Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model">Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#settings">Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="#window">Window</a></li>
<li class="toctree-l4"><a class="reference internal" href="#help">Help</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#version-upgrade-tool">Version upgrade tool</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#usage">Usage</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="moduleintro.html">Introduction to Tool Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="UserGuide.html">Optimal Performance Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="Shortcut.html">Shortcuts</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AIDI</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="Reference.html">Reference</a></li>
      <li class="breadcrumb-item active">Software Introduction</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Moreintro.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="software-introduction">
<h1>Software Introduction<a class="headerlink" href="#software-introduction" title="Link to this heading"></a></h1>
<section id="functional-layout">
<h2>Functional layout<a class="headerlink" href="#functional-layout" title="Link to this heading"></a></h2>
<p><img alt="Alt text" src="_images/image-18.png" /></p>
</section>
<section id="terminological-concepts">
<h2>Terminological concepts<a class="headerlink" href="#terminological-concepts" title="Link to this heading"></a></h2>
<p>● Workspace:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">It</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">storage</span> <span class="n">location</span> <span class="k">for</span> <span class="n">newly</span> <span class="n">created</span> <span class="n">AI</span> <span class="n">projects</span><span class="o">.</span> <span class="n">Generally</span><span class="p">,</span> <span class="n">the</span> <span class="n">projects</span> <span class="n">at</span> <span class="n">a</span> <span class="n">project</span> <span class="n">site</span> <span class="n">are</span> <span class="n">saved</span> <span class="n">within</span> <span class="n">one</span> <span class="n">workspace</span><span class="p">,</span> <span class="n">which</span> <span class="n">facilitates</span> <span class="n">project</span> <span class="n">management</span> <span class="ow">and</span> <span class="n">maintenance</span> <span class="n">by</span> <span class="n">on</span> <span class="o">-</span> <span class="n">site</span> <span class="n">personnel</span><span class="o">.</span>
</pre></div>
</div>
<p>● Project:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Usually</span><span class="p">,</span> <span class="k">for</span> <span class="n">the</span> <span class="n">images</span> <span class="n">under</span> <span class="n">an</span> <span class="n">optical</span> <span class="n">solution</span><span class="p">,</span> <span class="n">one</span> <span class="n">project</span> <span class="ow">is</span> <span class="n">established</span><span class="o">.</span> <span class="n">Then</span><span class="p">,</span> <span class="n">one</span> <span class="ow">or</span> <span class="n">more</span> <span class="n">AI</span> <span class="n">modules</span> <span class="n">are</span> <span class="n">created</span> <span class="n">within</span> <span class="n">the</span> <span class="n">project</span> <span class="n">to</span> <span class="n">achieve</span> <span class="n">defect</span> <span class="n">annotation</span> <span class="ow">and</span> <span class="n">model</span> <span class="n">training</span><span class="o">.</span>
</pre></div>
</div>
<p>● Dataset:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>○ Training set:  After defect annotation is completed, the images are added to the training set. These are the data used for training the model to learn defect features.
○ Test set: The images with completed defect annotation that are not added to the training set. After the model is trained, these images are used to evaluate the model&#39;s recognition effect on other defect features.
○ Unmarked: Can be used for manual model evaluation
</pre></div>
</div>
<p>● View:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">View</span><span class="p">:</span> <span class="n">A</span> <span class="n">rectangular</span> <span class="n">box</span> <span class="p">(</span><span class="n">ROI</span><span class="p">)</span> <span class="n">based</span> <span class="n">on</span> <span class="n">the</span> <span class="n">original</span> <span class="n">image</span><span class="p">,</span> <span class="k">with</span> <span class="n">the</span> <span class="n">image</span> <span class="n">inside</span> <span class="n">the</span> <span class="n">box</span> <span class="n">referred</span> <span class="n">to</span> <span class="k">as</span> <span class="n">the</span> <span class="n">view</span>
<span class="n">View</span> <span class="n">transformation</span><span class="p">:</span> <span class="n">The</span> <span class="n">transformation</span> <span class="n">settings</span> <span class="n">of</span> <span class="n">the</span> <span class="n">view</span> <span class="n">box</span>
<span class="n">View</span> <span class="n">Mask</span><span class="p">:</span> <span class="n">Draw</span> <span class="n">interference</span> <span class="n">areas</span><span class="p">,</span> <span class="n">which</span> <span class="n">will</span> <span class="n">be</span> <span class="n">blacked</span> <span class="n">out</span> <span class="ow">and</span> <span class="n">will</span> <span class="ow">not</span> <span class="n">participate</span> <span class="ow">in</span> <span class="n">training</span>
<span class="n">View</span> <span class="n">filtering</span><span class="p">:</span> <span class="n">By</span> <span class="n">filtering</span> <span class="n">settings</span><span class="p">,</span> <span class="n">retain</span> <span class="n">the</span> <span class="n">desired</span> <span class="n">views</span>
</pre></div>
</div>
<p>● OK and NG diagrams:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>○ OK image: Good product image
○ NG diagram: defect diagram
</pre></div>
</div>
<p>● Unannotated Images:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Images</span> <span class="n">imported</span> <span class="n">into</span> <span class="n">the</span> <span class="n">software</span> <span class="n">but</span> <span class="ow">not</span> <span class="n">manually</span> <span class="n">annotated</span><span class="o">.</span>  <span class="n">They</span> <span class="n">can</span> <span class="n">be</span> <span class="n">used</span> <span class="k">as</span> <span class="n">data</span> <span class="n">to</span> <span class="n">test</span> <span class="n">the</span> <span class="n">model</span><span class="s1">&#39;s performance after the model is trained.  However, due to the lack of annotation information on these images, it is impossible to count the defect over - detection and missed - detection information on such images in the software&#39;</span><span class="n">s</span> <span class="n">evaluation</span> <span class="n">page</span><span class="o">.</span>  <span class="n">It</span> <span class="ow">is</span> <span class="n">necessary</span> <span class="n">to</span> <span class="n">manually</span> <span class="n">check</span> <span class="n">the</span> <span class="n">recognition</span> <span class="n">effect</span> <span class="n">of</span> <span class="n">the</span> <span class="n">model</span> <span class="n">on</span> <span class="n">each</span> <span class="n">of</span> <span class="n">these</span> <span class="n">images</span> <span class="n">one</span> <span class="n">by</span> <span class="n">one</span><span class="o">.</span>
</pre></div>
</div>
<p>● Annotated Images:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Images</span> <span class="n">imported</span> <span class="n">into</span> <span class="n">the</span> <span class="n">software</span><span class="p">,</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">defect</span> <span class="n">annotation</span> <span class="n">tool</span> <span class="n">of</span> <span class="n">the</span> <span class="n">AI</span> <span class="n">module</span> <span class="ow">is</span> <span class="n">used</span> <span class="n">to</span> <span class="n">mark</span> <span class="n">the</span> <span class="n">defects</span> <span class="n">on</span> <span class="n">the</span> <span class="n">images</span><span class="o">.</span> <span class="n">These</span> <span class="n">are</span> <span class="n">the</span> <span class="n">data</span> <span class="n">used</span> <span class="k">for</span> <span class="n">training</span> <span class="ow">and</span> <span class="n">evaluating</span> <span class="n">the</span> <span class="n">model</span><span class="o">.</span>
</pre></div>
</div>
<p>● Indicators:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>○ Missing detection rate=Number of Un-detected NG / Total Number of NG
○ Over-Detection Rate = Number of OK Marked as NG / Total Number of OK
○ Inspection rate = Number of OK judged as NG/Total number of OK
○ Accuracy = Number of Correct Classifications / Total Number
○ Recall = Number of NG Marked as NG by the Model / (Number of NG Marked as NG by the Model + Number of NG Marked as OK by the Model). The higher the recall, the fewer missed-detected areas there are in the image.
○ Precision = Number of NG Marked as NG by the Model / (Number of NG Marked as NG by the Model + Number of OK Marked as NG by the Model). The higher the precision, the fewer over-detected areas there are in the image.
</pre></div>
</div>
<p>● Confusion matrix:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Confusion</span> <span class="n">matrix</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">commonly</span> <span class="n">used</span> <span class="n">model</span> <span class="n">evaluation</span> <span class="n">tool</span><span class="p">,</span> <span class="k">with</span> <span class="n">manual</span> <span class="n">annotation</span> <span class="n">vertically</span> <span class="ow">and</span> <span class="n">inference</span> <span class="n">results</span> <span class="n">horizontally</span><span class="o">.</span> <span class="n">The</span> <span class="n">confusion</span> <span class="n">matrix</span> <span class="n">can</span> <span class="n">intuitively</span> <span class="n">understand</span> <span class="n">which</span> <span class="k">class</span><span class="w"> </span><span class="nc">of</span> <span class="n">samples</span> <span class="n">the</span> <span class="n">model</span> <span class="n">performs</span> <span class="n">poorly</span> <span class="ow">in</span> <span class="ow">and</span> <span class="n">which</span> <span class="n">other</span> <span class="n">classes</span> <span class="n">are</span> <span class="n">easily</span> <span class="n">confused</span> <span class="k">with</span><span class="o">.</span>
</pre></div>
</div>
<p>● Tag：<br></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span> <span class="n">Tag</span><span class="p">:</span> <span class="n">used</span> <span class="n">to</span> <span class="n">identify</span> <span class="n">images</span> <span class="ow">and</span> <span class="n">can</span> <span class="n">identify</span> <span class="n">their</span> <span class="n">attributes</span> <span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">collection</span> <span class="n">time</span><span class="p">,</span> <span class="nb">type</span> <span class="n">of</span> <span class="n">defect</span><span class="p">,</span> <span class="n">etc</span><span class="o">.</span><span class="p">);</span>
<span class="n">View</span> <span class="n">Tag</span><span class="p">:</span> <span class="n">The</span> <span class="n">tag</span> <span class="n">of</span> <span class="n">a</span> <span class="n">view</span> <span class="n">that</span> <span class="n">can</span> <span class="n">identify</span> <span class="n">the</span> <span class="n">features</span> <span class="n">of</span> <span class="n">the</span> <span class="n">view</span>
</pre></div>
</div>
<p>● Basic operations:<br></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Annotation</span><span class="p">:</span> <span class="n">Draw</span> <span class="n">defect</span> <span class="n">areas</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">image</span><span class="o">.</span>
<span class="n">Label</span><span class="p">:</span> <span class="n">Category</span> <span class="n">of</span> <span class="n">defect</span><span class="o">.</span>
<span class="n">Do</span> <span class="ow">not</span> <span class="n">learn</span> <span class="n">regions</span><span class="o">/</span><span class="n">masks</span><span class="p">:</span><span class="n">regions</span> <span class="n">that</span> <span class="n">the</span> <span class="n">model</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">want</span> <span class="n">to</span> <span class="n">focus</span> <span class="n">on</span><span class="o">.</span>
<span class="n">Key</span> <span class="n">learning</span> <span class="n">areas</span><span class="p">:</span> <span class="n">The</span> <span class="n">areas</span> <span class="n">that</span> <span class="n">the</span> <span class="n">model</span> <span class="ow">is</span> <span class="n">expected</span> <span class="n">to</span> <span class="n">focus</span> <span class="n">on</span><span class="o">.</span>
</pre></div>
</div>
<p>● TP:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">True</span> <span class="n">Positive</span> <span class="n">refers</span> <span class="n">to</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">positive</span><span class="o">-</span><span class="k">class</span><span class="w"> </span><span class="nc">samples</span> <span class="n">that</span> <span class="n">are</span> <span class="n">correctly</span> <span class="n">predicted</span> <span class="k">as</span> <span class="n">positive</span> <span class="o">-</span> <span class="n">class</span><span class="o">.</span> <span class="n">In</span> <span class="n">the</span> <span class="n">software</span><span class="p">,</span> <span class="n">it</span> <span class="n">can</span> <span class="n">be</span> <span class="n">understood</span> <span class="k">as</span> <span class="s2">&quot;the number of NG cases that are correctly identified as NG by the model&quot;</span><span class="o">.</span>
</pre></div>
</div>
<p>● FP:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">False</span> <span class="n">Positive</span> <span class="n">refers</span> <span class="n">to</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">negative</span><span class="o">-</span><span class="k">class</span><span class="w"> </span><span class="nc">samples</span> <span class="n">that</span> <span class="n">are</span> <span class="n">incorrectly</span> <span class="n">predicted</span> <span class="k">as</span> <span class="n">positive</span> <span class="o">-</span> <span class="n">class</span><span class="o">.</span> <span class="n">In</span> <span class="n">the</span> <span class="n">software</span><span class="p">,</span> <span class="n">it</span> <span class="n">can</span> <span class="n">be</span> <span class="n">understood</span> <span class="k">as</span> <span class="s2">&quot;the number of OK cases that are wrongly identified as NG by the model&quot;</span><span class="o">.</span>
</pre></div>
</div>
<p>● FN:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">False</span> <span class="n">Negative</span> <span class="n">refers</span> <span class="n">to</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">positive</span><span class="o">-</span><span class="k">class</span><span class="w"> </span><span class="nc">samples</span> <span class="n">that</span> <span class="n">are</span> <span class="n">actually</span> <span class="n">positive</span> <span class="n">but</span> <span class="n">are</span> <span class="n">incorrectly</span> <span class="n">predicted</span> <span class="k">as</span> <span class="n">negative</span> <span class="o">-</span> <span class="n">class</span><span class="o">.&lt;</span><span class="n">br</span><span class="o">&gt;</span> <span class="n">In</span> <span class="n">the</span> <span class="n">software</span><span class="p">,</span> <span class="n">it</span> <span class="n">can</span> <span class="n">be</span> <span class="n">understood</span> <span class="k">as</span> <span class="s2">&quot;the number of NG cases that are wrongly identified as OK by the model&quot;</span><span class="o">.</span>
</pre></div>
</div>
</section>
<section id="engineering-management">
<h2>Engineering management<a class="headerlink" href="#engineering-management" title="Link to this heading"></a></h2>
<p>(1) Entrance</p>
<p><img alt="Alt text" src="_images/image-19.png" /></p>
<p>(2) Create a workspace<br>
Users can choose to load local directories or create new sub workspaces under existing workspaces</p>
<p><img alt="Alt text" src="_images/image-20.png" /></p>
<p>(3) Create Project</p>
<p><img alt="Alt text" src="_images/image-21.png" /></p>
<p>Select the desired project type and enter the project name</p>
<p><img alt="Alt text" src="_images/image-22.png" /></p>
<p>(4) Operations supported by the workspace</p>
<p><img alt="Alt text" src="_images/image-23.png" /></p>
<ol class="simple">
<li><p>Renaming the workspace<br></p></li>
<li><p>Save workspace as<br></p></li>
<li><p>New construction project<br></p></li>
<li><p>Engineering List<br></p></li>
<li><p>Open all projects<br></p></li>
<li><p>View workspace information<br></p></li>
<li><p>Delete workspace<br></p></li>
</ol>
<p>(5) Engineering supported operations</p>
<p><img alt="Alt text" src="_images/image-24.png" /></p>
<ol class="simple">
<li><p>Thumbnails<br></p></li>
<li><p>Project renaming<br></p></li>
<li><p>Engineering Information<br></p></li>
<li><p>Annotation information editing<br></p></li>
<li><p>Delete project<br></p></li>
<li><p>Open the project<br></p></li>
</ol>
<section id="engineering-management-sample-case">
<h3>Engineering management Sample Case<a class="headerlink" href="#engineering-management-sample-case" title="Link to this heading"></a></h3>
<p><img alt="Alt text" src="_images/image-25.png" /></p>
<ol class="simple">
<li><p>create the project based on camera positon</p></li>
</ol>
</section>
</section>
<section id="image-operation">
<h2>Image operation<a class="headerlink" href="#image-operation" title="Link to this heading"></a></h2>
<section id="import-image">
<h3>Import Image<a class="headerlink" href="#import-image" title="Link to this heading"></a></h3>
<p>(1) Import on an image basis</p>
<p><img alt="Alt text" src="_images/image-26.png" /></p>
<p>(2) Import by folder</p>
<p><img alt="Alt text" src="_images/image-27.png" /></p>
</section>
<section id="data-export">
<h3>Data export<a class="headerlink" href="#data-export" title="Link to this heading"></a></h3>
<p>If exporting the image of the algorithm module, <br>the steps for exporting are as follows:<br>
1.First, select the corresponding image in the image list<br>
2.Click the export button in the IO area of the current module image or right-click on the image list and select “<strong>Export Selected Images/Annotation</strong>s”<br></p>
<p><img alt="Alt text" src="_images/image-28.png" />
<img alt="Alt text" src="_images/image-29.png" /><br></p>
<p>3.Choose to export the original image/annotations, or choose to export the rendered image<br></p>
<p><img alt="Alt text" src="_images/image-30.png" /><br></p>
<p>4.If you choose to export the original image/annotations, <br>you can check the options in the original image and annotations (you can freely choose to export only annotations/original image or export all)<br>
5.Select the desired export path and click OK to complete the data export<br>
6.Under the specified path, you can see the data package file stored this time</p>
</section>
<section id="data-import">
<h3>Data import<a class="headerlink" href="#data-import" title="Link to this heading"></a></h3>
<p><img alt="Alt text" src="_images/image-31.png" /></p>
<p>1.Click on the upper right corner of the main interface to import images<br>
2.Select the 3.0 exported data package file</p>
<p><img alt="Alt text" src="_images/image-32.png" /></p>
<p>3.Enter the packet panel</p>
<p><img alt="Alt text" src="_images/image-33.png" /></p>
<p>4.Further data filtering can be performed based on image tags. <br>The connection conditions between tag filters are and, with a maximum of 3 added</p>
<p><img alt="Alt text" src="_images/image-34.png" /></p>
<p>5.The original image and annotations can be checked, and the image can be checked<br>
6.Click OK to proceed <br>
In addition, if the current module already has an image, importing the data package can only select annotations corresponding to the existing image, which can achieve automatic matching</p>
</section>
<section id="annotations-between-different-modules-support-each-other">
<h3>Annotations between different modules support each other<a class="headerlink" href="#annotations-between-different-modules-support-each-other" title="Link to this heading"></a></h3>
<ol class="simple">
<li><p>Annotations for segmentation and detection support each other<br></p></li>
<li><p>Annotations for segmentation and unsupervised segmentation support each other<br></p></li>
<li><p>OCR and detection annotations support each other<br></p></li>
<li><p>The labeling of detection and positioning (assembly inspection) supports each other</p></li>
</ol>
</section>
<section id="compatible-with-old-version-annotations">
<h3>Compatible with old version annotations<a class="headerlink" href="#compatible-with-old-version-annotations" title="Link to this heading"></a></h3>
<section id="compatibility-instructions">
<h4>Compatibility instructions<a class="headerlink" href="#compatibility-instructions" title="Link to this heading"></a></h4>
<p>Annotations for versions 2.3 and 2.4 can be imported and used in version 3.2 (compatible with aqlabel files)</p>
</section>
<section id="operation-steps">
<h4>Operation steps<a class="headerlink" href="#operation-steps" title="Link to this heading"></a></h4>
<p><strong>2.X first module annotation import 3.0:</strong><br></p>
<p>(1) Data to be prepared:<br> 2. X first module source folder and label folder, and these two folders need to be placed in the same level directory<br></p>
<p>(2) 3.0 New Construction Projects<br></p>
<p>(3) Add the corresponding first module after the input node<br></p>
<p>(4) Click on “<strong>Add Image</strong>” in the first module, select the image from the source, and click “<strong>Add</strong>”<br></p>
<p>(5) Go to the view converter of the current module and click <strong>Apply</strong>. You can see the reserved annotations now</p>
</section>
</section>
<section id="third-party-annotation-import">
<h3>Third party annotation import<a class="headerlink" href="#third-party-annotation-import" title="Link to this heading"></a></h3>
<p>Splitting module:<br>
● Support Labelme: JSON format annotation files<br>
Detection module:<br>
● Support Labelme: JSON format annotation files<br>
● Support Labelimage: XML, JSON format annotation files</p>
</section>
<section id="image-list-function">
<h3>Image list function<a class="headerlink" href="#image-list-function" title="Link to this heading"></a></h3>
<p>(1) Right click function:</p>
<p><img alt="Alt text" src="_images/image-35.png" /></p>
</section>
</section>
<section id="add-tools">
<h2>Add tools<a class="headerlink" href="#add-tools" title="Link to this heading"></a></h2>
<p>(1) Click the add button</p>
<p><img alt="Alt text" src="_images/image-36.png" /></p>
<p>(2) Enter the Add Module interface</p>
<p><img alt="Alt text" src="_images/image-37.png" /></p>
<ol class="simple">
<li><p>Click to add the corresponding module<br></p></li>
<li><p>Click on the module to view the introduction information<br></p></li>
</ol>
<p>(3) Parallel modules<br>
Continue to add other tools behind the module to complete module parallel connection</p>
<p><img alt="Alt text" src="_images/image-38.png" />
<img alt="Alt text" src="_images/image-40.png" /></p>
<p>(4) Series module<br>
Continue to add modules after the modules to complete module concatenation</p>
<p><img alt="Alt text" src="_images/image-41.png" />
<img alt="Alt text" src="_images/image-42.png" /></p>
</section>
<section id="data-annotation">
<h2>Data annotation<a class="headerlink" href="#data-annotation" title="Link to this heading"></a></h2>
<section id="brush-tools">
<h3>Brush tools<a class="headerlink" href="#brush-tools" title="Link to this heading"></a></h3>
<section id="polygon-drawing-tools">
<h4>Polygon drawing tools<a class="headerlink" href="#polygon-drawing-tools" title="Link to this heading"></a></h4>
<p>The polygon drawing tools are: <br>circular pen, square pen, circular line pen, square line pen, pen, pencil, two-point circle drawing tool, magic wand tool, and quick annotation tool.</p>
<p>(1) Circular and square pens: <br>Circular brush tools with a diameter of the brush size. <br>A square brush tool with a side length equal to the size of the brush. <br>The <strong>A</strong> key on the keyboard increases the brush size, while the <strong>D</strong> key reduces the brush size.</p>
<p><img alt="Alt text" src="_images/image-43.png" /></p>
<p>(2) Circular Line Pen and Square Line Pen: <br>Circular Line Pen tool. <br>After setting the starting point with the left mouse button, you can continuously left click to draw multiple straight line annotations. Double click the left mouse button to end the annotation. <br>The diameter is the size of the brush. <br>The square line pen has a square shape. <br>After setting the starting point with the left mouse button, you can continuously click to draw multiple straight line annotations. Double click the left mouse button to end the annotation. <br>The line width is the size of the brush.</p>
<p><img alt="Alt text" src="_images/image-44.png" /></p>
<p>(3) After filling with a pen and setting the starting point with the left mouse button, click continuously with the left mouse button to draw multiple line segment contours. <br>Double click the left mouse button to close the contour, and the area enclosed by the contour will be automatically filled with annotations, which is not affected by the size of the brush. When using, avoid crossing the contour line segments.<br>
Pencil filling: <br>Press and hold the left mouse button to draw the outline of the annotation. <br>Release the left mouse button to automatically fill it as the annotation, which is not affected by the size of the brush.<br> When using it, avoid crossing the outline line segments.</p>
<p><img alt="Alt text" src="_images/image-45.png" /></p>
<p>(4) Draw a circle at two points: <br>After setting the starting point with the left mouse button, drag the mouse to draw a circle, double-click the left mouse button to close the contour, and the area enclosed by the contour is automatically filled with annotations, which is not affected by the size of the brush.</p>
<p><img alt="Alt text" src="_images/image-46.png" /></p>
<p>(5) Magic Wand: <br>For some images with clear boundaries, the Magic Wand tool can quickly extract the images. <br>The function of the Magic Wand is to know the color of the position you clicked on, and automatically obtain the same color in nearby areas, making them in a selection state. <br>Not affected by brush size. <br>And you can set the effective range (ROI) of the magic wand.<br> In addition, you can also choose whether to fill the holes and voids when using the magic wand tool</p>
<p><img alt="Alt text" src="_images/image-47.png" />
<img alt="Alt text" src="_images/image-48.png" /></p>
<p>(6) Quick annotation: <br>Select the area by adding a tool pen and deleting the tool pen deletion area. <br>When adding a tool pen to enclose the area, the area is selected. <br>When deleting the tool pen, annotate the selected area. If the area is not enclosed by the deleted pen, it is no longer selected. <br>After completing the drawing, click <strong>Apply</strong> to complete the annotation. <br>Not affected by brush size.<br>* When there is a certain contrast between the defect boundary and the product background, it is recommended to use other tools. <br>* For slender defects with less than 3 pixels, it is recommended to use other tools.</p>
<p><img alt="Alt text" src="_images/image-49.png" />
<img alt="Alt text" src="_images/image-50.png" /></p>
<p>(7) Intelligent Annotation: <br>For defects with clear object boundaries and high contrast, intelligent annotation can quickly identify and outline the contours of these defects, effectively improving the annotation efficiency. When using it for the first time, a loading pop-up window will appear, indicating that it takes about 4 to 5 minutes to perform the initialization (the specific time consumption may vary depending on the computing power of the graphics card). First, use the selection pen<img alt="Alt text" src="_images/image-577.png" /> to annotate the target area, and then use the deletion pen<img alt="Alt text" src="_images/image-578.png" /> to remove the redundant target area.<br></p>
<p><img alt="Alt text" src="_images/image-579.png" /></p>
<p><img alt="Alt text" src="_images/image-580.png" /></p>
<p>(8) Eraser:<br>
The diameter of the circular eraser is the size of a brush and is used to erase annotations.<br>
A square eraser with a brush size edge is used to erase annotations.<br>
The linear eraser pen is circular in shape. After setting the starting point with the left mouse button, you can continuously click to draw multiple straight line annotations. Double click the left mouse button to end the annotation. <br>The line width is the size of the brush and is used to erase the annotation.<br>
*Erasers can choose the shape of the eraser and the type of defect to be erased.<br></p>
<p>(9) Brush size: <br>Display the brush size in pixels. <br>The keyboard “<strong>A</strong>” key enlarges the brush, and the “<strong>D</strong>” key reduces the brush.<br></p>
<p>(10) Reverse selection: <br>Click reverse selection to convert the original defect annotation area to the area without defect annotation.<br></p>
<p>(11) Mark corrosion expansion:<br>
① Select the annotation category you want to perform corrosion expansion on<br>
② Fill in the specific pixel values for expansion or corrosion, click OK to proceed</p>
<p><img alt="Alt text" src="_images/image-51.png" /></p>
</section>
<section id="rectangle-drawing-tool">
<h4>Rectangle drawing tool<a class="headerlink" href="#rectangle-drawing-tool" title="Link to this heading"></a></h4>
<p>[Application scenario: Detection tool]<br></p>
<ol class="simple">
<li><p><strong>Free box:</strong><br>After clicking, draw any rectangular box label diagonally. <br>After popping up the label box, select the label name and complete the annotation.<br></p></li>
<li><p><strong>Standard box:</strong> <br>Click to directly place a fixed size rectangular box annotation, which can adjust the width and height of the rectangular box. <br>After popping up the label box, select the label name and complete the annotation.<br>
*It is recommended to use standard mode for annotation when the target size is fixed<br></p></li>
</ol>
</section>
<section id="single-point-drawing-tool">
<h4>Single point drawing tool<a class="headerlink" href="#single-point-drawing-tool" title="Link to this heading"></a></h4>
<p>[Application scenario: Positioning tool]<br></p>
<ol class="simple">
<li><p>Precise point positioning tool: <br>Precise annotation of location feature points with category labels is required in the image.<br>
*The annotation points have been changed from circles to squares, expanding their usage scenarios. <br>In addition, square annotations are also applicable to circular targets and can be detected normally.<br>
*When using single point positioning, it is recommended to use copy (<strong>ctrl+C</strong>) and paste (<strong>ctrl+V</strong>) for quick annotation.<br></p></li>
<li><p>Quick annotation tool:<br>
(1) First, draw a line segment parallel to the height or width of the target</p></li>
</ol>
<p><img alt="Alt text" src="_images/image-52.png" /></p>
<p>(2) Then hold down the left mouse button to draw</p>
<p><img alt="Alt text" src="_images/image-53.png" /></p>
</section>
<section id="attribute-system">
<h4>Attribute system<a class="headerlink" href="#attribute-system" title="Link to this heading"></a></h4>
<p>(1) Set unique color attributes for annotation and inference results, and cannot set the same color attribute repeatedly. <br>Colors that have already been selected cannot be selected again.<br>
(2) Set the color properties for the drawing process.<br></p>
<p><img alt="Alt text" src="_images/image-54.png" /></p>
</section>
</section>
<section id="annotation-mode">
<h3>Annotation mode<a class="headerlink" href="#annotation-mode" title="Link to this heading"></a></h3>
<p><img alt="Alt text" src="_images/image-55.png" /></p>
<section id="defect-annotation-mode">
<h4>Defect annotation mode<a class="headerlink" href="#defect-annotation-mode" title="Link to this heading"></a></h4>
<p>Defect labeling: <br>used to identify defect features or extract product locations<br>
In this mode, regions within the image view can be annotated</p>
<p><img alt="Alt text" src="_images/image-56.png" /></p>
</section>
<section id="key-learning-area-drawing-mode">
<h4>Key learning area drawing mode<a class="headerlink" href="#key-learning-area-drawing-mode" title="Link to this heading"></a></h4>
<p>[Only the segmentation tool has this function]<br>
Key learning areas: <br>areas that the model hopes to focus on<br>
In this mode, it is possible to draw key learning areas within the image view</p>
</section>
<section id="not-learning-region-drawing-mode">
<h4>Not learning region drawing mode<a class="headerlink" href="#not-learning-region-drawing-mode" title="Link to this heading"></a></h4>
<p>Not learning regions: <br>regions that the model does not want to focus on<br>
In this mode, it is possible to draw non learning regions within the image view</p>
</section>
</section>
</section>
<section id="label-management">
<h2>Label management<a class="headerlink" href="#label-management" title="Link to this heading"></a></h2>
<p><img alt="Alt text" src="_images/image-57.png" /></p>
<p>1.add label here<br></p>
<p>2.label list<br></p>
<p>3.delete label<br></p>
</section>
<section id="annotation-filtering">
<h2>Annotation filtering<a class="headerlink" href="#annotation-filtering" title="Link to this heading"></a></h2>
<p><img alt="Alt text" src="_images/image-58.png" /></p>
<ol class="simple">
<li><p>set filter here<br></p></li>
<li><p>click after setting<br></p></li>
<li><p>clear filter<br></p></li>
<li><p>set the filter as the tag results<br></p></li>
</ol>
<p><img alt="Alt text" src="_images/image-59.png" /></p>
<p>The filtering items include:<br> category, category attributes, set, position, width, height, angle, area, etc<br></p>
<p>The annotation filtering result corresponds to the canvas: <br>Clicking on a row can directly jump to the corresponding annotation of the image</p>
<p><img alt="Alt text" src="_images/image-60.png" /></p>
</section>
<section id="annotation-distribution">
<h2>Annotation distribution<a class="headerlink" href="#annotation-distribution" title="Link to this heading"></a></h2>
<p><img alt="Alt text" src="_images/image-61.png" /></p>
<ol class="simple">
<li><p>You can select the type of distribution you want to view<br></p></li>
<li><p>You can select the labeling, test results, all<br></p></li>
</ol>
<p>When the distribution type being viewed is category:</p>
<p><img alt="Alt text" src="_images/image-62.png" /></p>
<ol class="simple">
<li><p>Two filters<br></p></li>
<li><p>Y axis show the count<br></p></li>
<li><p>specific images info<br></p></li>
<li><p>X axis show the defect category<br></p></li>
<li><p>The current statistics are based on the range of images, which can be adjusted in the main list<br></p></li>
</ol>
<p>When the distribution type being viewed is location:</p>
<p><img alt="Alt text" src="_images/image-63.png" /></p>
<p>1.Filters can be specified<br></p>
<p>2.Coordinate information is displayed on mouse hover<br></p>
<p>3.Click to add a real image as a background to visualize the distribution of coordinate points.<br></p>
<p>When viewing distribution types such as width/height/angle:</p>
<p><img alt="Alt text" src="_images/image-64.png" /></p>
<ol class="simple">
<li><p>Value of the corresponding statistical range segment<br></p></li>
</ol>
</section>
<section id="tag-management">
<h2>Tag management<a class="headerlink" href="#tag-management" title="Link to this heading"></a></h2>
<p>Tag types: <br>Image Tag, View Tag<br>
Image Tag: <br>used to identify images and can identify their attributes (batch, collection time, type of defect, etc.);<br>
View Tag: <br>The tag of a view that can identify the features of the view<br></p>
<ol class="simple">
<li><p>Set Tag<br>
Entrance: <br>Right click on the image list and use shortcut keys to directly set tags for images</p></li>
</ol>
<p><img alt="Alt text" src="_images/image-65.png" /></p>
<p>After clicking, the Tag window for the setting module will appear, allowing you to perform tag operations on the selected images in a centralized manner</p>
<p><img alt="Alt text" src="_images/image-67.png" /></p>
<p>Click the delete button in the Tag icon in the image information to quickly delete the corresponding view tag or image tag of the current image</p>
<p><img alt="Alt text" src="_images/image-68.png" /></p>
</section>
<section id="view-operations">
<h2>View operations<a class="headerlink" href="#view-operations" title="Link to this heading"></a></h2>
<p>What is view conversion?<br>
It is used to select the effective image range of the current module according to the detection results of the previous module. <br>The image area within this range is the view</p>
<section id="view-filtering">
<h3>View filtering<a class="headerlink" href="#view-filtering" title="Link to this heading"></a></h3>
<p>entrance:</p>
<p><img alt="Alt text" src="_images/image-69.png" /></p>
<p>By default, all NG categories are retained in the view. <br>Users can manually choose to retain defects of the specified category as the view source, or choose OK images as the view source<br>
Select to keep the view, <br>uncheck to not keep the view</p>
<p><img alt="Alt text" src="_images/image-70.png" /></p>
</section>
<section id="view-transformation">
<h3>View transformation<a class="headerlink" href="#view-transformation" title="Link to this heading"></a></h3>
<p>(1) Can draw new views</p>
<p><img alt="Alt text" src="_images/image-71.png" /></p>
<p>(2) You can modify the size, position, angle, and corrosion expansion of the generated view. <br>Recommend manually dragging the view box for quick editing</p>
<p><img alt="Alt text" src="_images/image-72.png" /></p>
<p>(3) Existing views can be deleted</p>
<p><img alt="Alt text" src="_images/image-73.png" /></p>
<p>(4) Views can be divided and merged</p>
<p><img alt="Alt text" src="_images/image-74.png" /></p>
<p>Can define the number of horizontal and vertical partitions as well as the partition interval, click on the partition to take effect, support recall and redo</p>
<p><img alt="Alt text" src="_images/image-75.png" /></p>
<p>Hold down the keyboard  “<strong>ctrl</strong>” and click in sequence to select multiple views. <br>Right click and select merge to perform the view merge operation<br>
<strong>Other:</strong><br>
Parameter initialization</p>
<p><img alt="Alt text" src="_images/image-76.png" /></p>
<p>Recall and redo</p>
<p><img alt="Alt text" src="_images/image-77.png" /></p>
<p>Current view transformation identifier</p>
<p><img alt="Alt text" src="_images/image-78.png" /></p>
</section>
<section id="view-mask">
<h3>View Mask<a class="headerlink" href="#view-mask" title="Link to this heading"></a></h3>
<p>(1) Automatic generation: <br>after clicking, the detection result of the previous module will be automatically used as the mask. <br>Also supports reverse selection, which can use areas other than the detection area as masks</p>
<p><img alt="Alt text" src="_images/image-79.png" /></p>
<p>(2) Manual drawing: <br>supports manual framing of new view areas</p>
<p><img alt="Alt text" src="_images/image-80.png" /></p>
</section>
<section id="view-conversion-image-list-filter">
<h3>View Conversion - Image List Filter<a class="headerlink" href="#view-conversion-image-list-filter" title="Link to this heading"></a></h3>
<p><img alt="Alt text" src="_images/image-81.png" /></p>
<p>Supported filtering items:<br>
Search by image name<br>
Search by Image Tag</p>
</section>
</section>
<section id="add-training-set">
<h2>Add training set<a class="headerlink" href="#add-training-set" title="Link to this heading"></a></h2>
<section id="automatic-partitioning-model-training-assistant">
<h3>Automatic partitioning (model training assistant)<a class="headerlink" href="#automatic-partitioning-model-training-assistant" title="Link to this heading"></a></h3>
<p>entrance:</p>
<p><img alt="Alt text" src="_images/image-82.png" /></p>
<p>Model Training Assistant Main Interface:<br>
It is divided into two functional sections: <br>data partitioning and training set recommendation.</p>
<p><img alt="Alt text" src="_images/image-83.png" />
<img alt="Alt text" src="_images/image-84.png" /></p>
<section id="data-partitioning">
<h4>Data partitioning<a class="headerlink" href="#data-partitioning" title="Link to this heading"></a></h4>
<p><strong>Proportional partitioning:</strong> <br>All annotated data is divided into training and testing sets according to the specified ratio<br>
<strong>Quantity division:</strong> <br>All annotated data is divided into training and testing sets according to the specified quantity</p>
</section>
<section id="training-set-recommendation">
<h4>Training set recommendation<a class="headerlink" href="#training-set-recommendation" title="Link to this heading"></a></h4>
<p>Automatically select training recommended data based on existing basic models.<br> It is recommended to train the basic model with a training set/complete set&gt;=5%, covering various types of defects. <br>Selection ratio=selection quantity/complete set, recommended to take 5%<br>
Note: <br>As long as the current model changes (switching models, retraining, etc.), all training recommendation sets will be cleared</p>
</section>
</section>
<section id="manual-division">
<h3>Manual division<a class="headerlink" href="#manual-division" title="Link to this heading"></a></h3>
<p>Right click on the image in the image list to add/remove the training set. <br>Support multiple selections.</p>
<p><img alt="Alt text" src="_images/image-85.png" /></p>
</section>
</section>
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Link to this heading"></a></h2>
<section id="training-parameter">
<h3>Training Parameter<a class="headerlink" href="#training-parameter" title="Link to this heading"></a></h3>
<p><img alt="Alt text" src="_images/image-86.png" /></p>
</section>
<section id="execute-training">
<h3>Execute training<a class="headerlink" href="#execute-training" title="Link to this heading"></a></h3>
<p><img alt="Alt text" src="_images/image-87.png" /></p>
</section>
</section>
<section id="inference">
<h2>Inference<a class="headerlink" href="#inference" title="Link to this heading"></a></h2>
<section id="inference-parameter">
<h3>Inference Parameter<a class="headerlink" href="#inference-parameter" title="Link to this heading"></a></h3>
<p><img alt="Alt text" src="_images/image-88.png" /></p>
</section>
<section id="execute-inference">
<h3>Execute inference<a class="headerlink" href="#execute-inference" title="Link to this heading"></a></h3>
<p><img alt="Alt text" src="_images/image-89.png" /></p>
</section>
</section>
<section id="evaluation-results">
<h2>Evaluation results<a class="headerlink" href="#evaluation-results" title="Link to this heading"></a></h2>
<p>entrance:</p>
<p><img alt="Alt text" src="_images/image-90.png" /></p>
<p>Comprehensive indicators</p>
<p><img alt="Alt text" src="_images/image-91.png" /></p>
<p>Training set accuracy: TP/(TP+FP) in the training set<br></p>
<p>Training set recall rate: TP/(TP+FN) in the training set<br></p>
<p>Test set accuracy: TP/(TP+FP) in the test set<br></p>
<p>Test set recall rate: TP/(TP+FN) in the test set<br></p>
<p>Accuracy: <br>The higher the accuracy, the fewer regional level passes; <br>Accuracy is relative to the predicted result, which represents how much of the positive predicted samples (defect samples) are correct. <br>Therefore, accuracy is: P=TP/(TP+FP)</p>
<p>Recall rate:<br> The higher the recall rate, the fewer missed detections at the regional level; <br>The recall rate is relative to the sample, that is, how many positive samples (defective samples) are predicted correctly in the sample, such as TP. <br>All positive samples have two directions, one is judged positive and the other is misjudged negative, so there are a total of TP+FN. <br>Therefore, the recall rate R=TP/(TP+FN)</p>
<p>Correct prediction: <br>The proportion of correctly predicted images at the image level to all evaluated images can be redirected to the corresponding image range by clicking the mouse.</p>
<p>Error prediction: <br>The proportion of image level error prediction images to all participating images in the evaluation can be redirected to the corresponding image range by clicking the mouse.</p>
<p>Total number of missed defects: <br>The number of missed defects (at the regional level), which can be clicked with the mouse to jump to the corresponding image range.</p>
<p>Total number of inspected defects: <br>The number of inspected defects (at the regional level), which can be clicked with the mouse to jump to the corresponding image range.</p>
<section id="confusion-matrix">
<h3>Confusion matrix<a class="headerlink" href="#confusion-matrix" title="Link to this heading"></a></h3>
<p>Confusion matrix is a commonly used model evaluation tool, with manual annotation vertically and inference results horizontally. <br>The confusion matrix can intuitively understand which class of samples the model performs poorly in and which other classes are easily confused with.</p>
<p><strong>Usage rules:</strong><br>
(1) First, filter the dataset range:<br>
All: The confusion matrix for all images.<br>
Name retrieval: <br>Only display the confusion matrix of the filtered image based on the image storage name.<br>
View Tag Retrieval:<br> Only display the confusion matrix of images filtered based on view tags.<br>
Image Tag Retrieval: <br>Only display the confusion matrix of the filtered image based on the image tag<br>
Training set:<br> Only display the confusion matrix of the training set.<br>
Test set: <br>Only display the confusion matrix of the test set.</p>
<p><img alt="Alt text" src="_images/image-92.png" /></p>
<p>(2) After selecting the dataset, you can choose whether to view the image level matrix or the region level matrix:<br>
Image level is a qualitative result based on the entire image.<br>
The regional level is a qualitative result based on the region of each image.</p>
<p><img alt="Alt text" src="_images/image-93.png" /></p>
<p>(3) Then you can choose whether to view the quantity matrix or the probability matrix<br>
The quantity matrix is the result of statistics based on the number of items.<br>
The probability matrix is the result of statistics conducted proportionally.</p>
<p><img alt="Alt text" src="_images/image-94.png" /></p>
<p>(4) After filtering to the desired result, you can click on any grid in the matrix, and the image list will automatically jump to the corresponding image according to the filtering rules.<br> It is possible to verify the results of each image in order to further optimize the model in a targeted manner.</p>
<p><img alt="Alt text" src="_images/image-95.png" /></p>
</section>
<section id="category-overview">
<h3>Category Overview<a class="headerlink" href="#category-overview" title="Link to this heading"></a></h3>
<p>Provided: <br>Number of missed defects (number of missed defects), number of passed defects (number of passed defects), accuracy (TP/(TP+FP)), recall (TP/(TP+FN)) for each defect category</p>
</section>
<section id="model-details">
<h3>Model details<a class="headerlink" href="#model-details" title="Link to this heading"></a></h3>
<p>Three sets of model time information are provided, namely total time, single graph testing time (average+maximum), and single iteration time (average+maximum)</p>
<p><img alt="Alt text" src="_images/image-96.png" /></p>
</section>
<section id="training-curve">
<h3>Training Curve<a class="headerlink" href="#training-curve" title="Link to this heading"></a></h3>
<p>During the training process, users can observe the loss curve to help observe the progress of the training process.</p>
</section>
<section id="more">
<h3>More<a class="headerlink" href="#more" title="Link to this heading"></a></h3>
<p>Detailed information of the model, <br>including recall, accuracy, number of annotations, recall, regional accuracy, and regional recall for the training and testing sets, respectively</p>
<p><img alt="Alt text" src="_images/image-97.png" /></p>
<p>Area accuracy: <br>The accuracy calculated in units of defect area<br></p>
<p>Regional recall rate: <br>The recall rate calculated in units of defect areas</p>
</section>
</section>
<section id="image-filtering">
<h2>Image filtering<a class="headerlink" href="#image-filtering" title="Link to this heading"></a></h2>
<section id="filter">
<h3>Filter<a class="headerlink" href="#filter" title="Link to this heading"></a></h3>
<p>Filter criteria support:</p>
<p><img alt="Alt text" src="_images/image-98.png" />
<img alt="Alt text" src="_images/image-99.png" />
<img alt="Alt text" src="_images/image-100.png" />
<img alt="Alt text" src="_images/image-101.png" /></p>
<p>The filtering criteria support “and”, “or”, and “non connection”.</p>
<p><img alt="Alt text" src="_images/image-102.png" /></p>
<p>One click reset: <br>Click the reset button at the top of the list to quickly return to the initial state</p>
<p><img alt="Alt text" src="_images/image-103.png" /></p>
</section>
<section id="sort">
<h3>Sort<a class="headerlink" href="#sort" title="Link to this heading"></a></h3>
<p><img alt="Alt text" src="_images/image-104.png" /></p>
</section>
<section id="list-right-click-menu">
<h3>List right-click menu<a class="headerlink" href="#list-right-click-menu" title="Link to this heading"></a></h3>
<p><img alt="Alt text" src="_images/image-105.png" /></p>
</section>
</section>
<section id="menu-bar">
<h2>Menu bar<a class="headerlink" href="#menu-bar" title="Link to this heading"></a></h2>
<section id="files">
<h3>Files<a class="headerlink" href="#files" title="Link to this heading"></a></h3>
<p>-New Project: Create a new project in the current workspace<br></p>
<p>-Recently opened projects: Recently opened projects<br></p>
<p>-Close Current Project: Close the current project on the main page<br></p>
<p>-Close All Projects: Close all currently open projects<br></p>
<p>-Delete Current Project: Delete the current project on the main page with caution</p>
<p><img alt="img" src="_images/cdl_wj.png" /></p>
</section>
<section id="version">
<h3>Version<a class="headerlink" href="#version" title="Link to this heading"></a></h3>
<p>-Save Current as Version: <br>Save the current status of the current project as version<br>
-Fallback to the most recent version: <br>Fallback to the version that was previously saved in the current project<br>
-Manage existing versions: <br>Manage all versions of the current project</p>
<p><img alt="img" src="_images/cdl_bb.png" /></p>
</section>
<section id="tools">
<h3>Tools<a class="headerlink" href="#tools" title="Link to this heading"></a></h3>
<p>-Factory Mode: <br>Enter the factory mode of the current project<br>
-Comprehensive judgment tool: <br>Add a comprehensive judgment tool to the current project.<br> If a comprehensive judgment tool has already been established, it needs to be deleted first and then re created<br>
-Export Report: <br>Edit the report for the current module of the current project and export the report</p>
<p><img alt="img" src="_images/cdl_gj.png" /></p>
</section>
<section id="image">
<h3>Image<a class="headerlink" href="#image" title="Link to this heading"></a></h3>
<p>-Import Image: The current project imports images in units of images<br>
-Import folder: Import images in folders for the current project</p>
<p><img alt="img" src="_images/cdl_tx.png" /></p>
</section>
<section id="training-inference">
<h3>Training &amp; Inference<a class="headerlink" href="#training-inference" title="Link to this heading"></a></h3>
<p>-Training current module: <br>Add the current module to the training/training queue in the current project<br>
-Inference current module: <br>Adding inference to the current project module<br>
-Training Task Management: <br>View/Manage Current Training Tasks<br>
-One click inference for all images: <br>infer all images of the current project through a tree process<br>
-One click reasoning for adding images: <br>Reasoning the current new image through a tree process</p>
<p><img alt="img" src="_images/cdl_xltl.png" /></p>
</section>
<section id="model">
<h3>Model<a class="headerlink" href="#model" title="Link to this heading"></a></h3>
<p>-Model export: <br>Export the current engineering model<br>
-Training process curve: <br>View the training process curve of the current module in the current project<br>
-Model Time: <br>View the model time information of the current module in the current project<br>
-Model Information: <br>View the detailed model information of the current module in the current project</p>
<p><img alt="img" src="_images/cdl_mx.png" /></p>
</section>
<section id="settings">
<h3>Settings<a class="headerlink" href="#settings" title="Link to this heading"></a></h3>
<p>-Preferences: <br>Open preference settings<br>
-Hardware selection: <br>Select the maximum number of GPUs and GPU priority for engineering training and inference, respectively<br>
-Management of Judgment Standard Functions: <br>Managing the Judgment Standard Functions of Comprehensive Judgment Nodes<br>
-Engineering volume optimization: <br>cleaning temporary engineering files to achieve significant reduction in engineering volume</p>
<p><img alt="img" src="_images/cdl_sz.png" /></p>
</section>
<section id="window">
<h3>Window<a class="headerlink" href="#window" title="Link to this heading"></a></h3>
<p>-Ruler: <br>Turn ruler on/off<br>
-Auxiliary lines: <br>turning on/off auxiliary lines<br>
-Coordinate values: <br>enable/disable coordinate values<br>
-Image information:<br> enable/disable image information display<br>
-Display advanced parameters: <br>enable/disable advanced parameters<br>
-Enable OK/NG display: <br>Turn on/off the display of results in the bottom left corner of the canvas</p>
<p><img alt="img" src="_images/cdl_sc.png" /></p>
</section>
<section id="help">
<h3>Help<a class="headerlink" href="#help" title="Link to this heading"></a></h3>
<p>-Using Documents<br>
-Development documentation<br>
-Example Engineering<br>
-Graphics Card Widgets<br>
-View logs<br>
-Shortcut key information<br>
-About AIDI</p>
<p><img alt="img" src="_images/cdl_bz.png" /></p>
</section>
</section>
<section id="version-upgrade-tool">
<h2>Version upgrade tool<a class="headerlink" href="#version-upgrade-tool" title="Link to this heading"></a></h2>
<section id="usage">
<h3>Usage<a class="headerlink" href="#usage" title="Link to this heading"></a></h3>
<ol class="simple">
<li><p>Find the Tools folder in the AIDI installation directory<br></p></li>
<li><p>Find the 2To3 tool and double-click to open it
<img alt="Alt text" src="_images/image-271.png" /></p></li>
<li><p>Select the old 2.4 project and the storage path after conversion</p></li>
</ol>
<p><img alt="Alt text" src="_images/image-272.png" />
The data scope of the retained old project includes the following content:<br>
(1) Figure<br>
(2) Annotation<br>
(3) Dataset partitioning<br>
(4) View Tag<br>
Applicable module scope:<br>
Quick inspection+segmentation<br>
Split+Split<br>
Each individual module (except for positioning and region extraction)</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Reference.html" class="btn btn-neutral float-left" title="Reference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="moduleintro.html" class="btn btn-neutral float-right" title="Introduction to Tool Usage" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Aqrose.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>