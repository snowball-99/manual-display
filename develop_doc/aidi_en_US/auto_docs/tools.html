<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="C++ API Reference" href="../cpp_api/cpp_index.html" /><link rel="prev" title="图片绘制几何图形和文字" href="../advanced_topics/image_draw.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2023.09.10 -->
        <title>工具清单及详细流程图 - VisionFlow</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">VisionFlow</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/visionflow-logo-cb.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">VisionFlow</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../about_visionflow.html">关于 VisionFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">在开发环境中引入VisionFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../core_concepts.html">VisionFlow 中的概念及其关系</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">VisionFlow 入门教程</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials/index.html">详细使用教程</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of 详细使用教程</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/project.html">工程的使用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/workspace.html">工作区</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/tool_manage.html">管理工程中的工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/dataset.html">数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/data_visit.html">通过数据集管理工程数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/config.html">设置参数及训练模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/eval_model.html">评估算法模型的效果</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/export_model.html">导出模型与使用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/runtime.html">运行时（Runtime）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/project_backup.html">工程备份</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/license.html">授权</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/product_mark.html">产品标识</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/datapack.html">VisionFlow的数据包</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/script_pipeline.html">脚本流程</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../whitepapers/index.html">算法工具白皮书</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of 算法工具白皮书</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../whitepapers/el_unsuper_seg.html">EL非监督分割白皮书</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tool_introduction/index.html">算法工具说明</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of 算法工具说明</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tool_introduction/segmentation.html">分割工具介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tool_introduction/unsuper_segmentation.html">非监督分割工具介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tool_introduction/unsuper_classification.html">非监督分类工具介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tool_introduction/location.html">定位工具介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tool_introduction/assemblyverification.html">装配检查工具介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tool_introduction/detection.html">检测工具介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tool_introduction/classification.html">分类工具介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tool_introduction/incremental_check.html">增量训练检查（分割、分类）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tool_introduction/OCR.html">OCR工具介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tool_introduction/geometry_search.html">几何定位工具介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tool_introduction/camera_calibration.html">相机标定工具介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tool_introduction/el_unsuper_seg.html">EL非监督分割工具使用说明</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../advanced_topics/index.html">更多细节</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of 更多细节</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../advanced_topics/command_line.html">命令行工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced_topics/training_callback.html">训练进度回调</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced_topics/compatibility_rule.html">版本兼容性与自动升级</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced_topics/image_draw.html">图片绘制几何图形和文字</a></li>
</ul>
</li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">工具清单及详细流程图</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cpp_api/cpp_index.html">C++ API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of C++ API Reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/namespace.html">Namespace</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/global_setting.html">Global Settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/core.html">Core Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/common.html">Common</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/helpers.html">Helper Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/compatible.html">Compatibility</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/sampleset.html">Sample Set Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/props.html">Property Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/param.html">Parameter Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/confs.html">Configurator Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/opers.html">Operator Types and Factory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/tools.html">Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/node_names.html">Constant String Node Names</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/image.html">Image type and image algorithm interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/geometry.html">Geometry Structure and Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/gauge.html">Gauge Parameters and Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/excepts.html">Exception Handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpp_api/datapack.html">Data Package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="compatibility.html">Version Compatibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../known_issues.html">已知问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">常见问题及解决方案</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../relnotes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../old_versions.html">Historic versions</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="id1">
<h1>工具清单及详细流程图<a class="headerlink" href="#id1" title="Link to this heading">#</a></h1>
<section id="idreader-tool">
<h2>IDReader Tool<a class="headerlink" href="#idreader-tool" title="Link to this heading">#</a></h2>
<p>IDReader tool. for locating and reading 1d and 2d barcode.</p>
<div class="graphviz"><object data="../_images/graphviz-ea28d5aadfbe0d702c98c62d485e26eb6ec67db0.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: IDReader&quot; {
  label=&quot;OnlyTool: IDReader&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;IDReader/decoder&quot;;
  &quot;IDReader/featmap_filter&quot;;
  &quot;IDReader/filter&quot;;
  &quot;IDReader/infer&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;IDReader/batch_size.conf&quot;;
  &quot;IDReader/decoder.conf&quot;;
  &quot;IDReader/featmap_filter.conf&quot;;
  &quot;IDReader/filter.conf&quot;;
  &quot;IDReader/infer.conf&quot;;
  &quot;IDReader/model.conf&quot;;
  &quot;IDReader/model_generator&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;IDReader/feature_map&quot;;
  &quot;IDReader/filter_pred&quot;;
  &quot;IDReader/raw_pred&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;IDReader/image&quot;;
  &quot;IDReader/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;IDReader/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;IDReader/batch_size&quot;;
  &quot;IDReader/decoder.args&quot;;
  &quot;IDReader/featmap_filter.args&quot;;
  &quot;IDReader/filter.args&quot;;
  &quot;IDReader/infer.args&quot;;
  &quot;IDReader/model&quot;;
  &quot;IDReader/model.args&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style



  subgraph &quot;cluster_IDReader&quot; {
    label=&quot;IDReader&quot;;
    &quot;IDReader/batch_size&quot; [label=&quot;id: IDReader/batch_size\ltype: visionflow::param::InferenceBatchSize\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Inference BatchSize and Inference \lMode. Currently only contains \lbatch size. It may need to be \lrefactored in the future.\l&quot;];
    &quot;IDReader/batch_size.conf&quot; [label=&quot;id: IDReader/batch_size.conf\ltype: visionflow::confs::InferenceBatchSizeConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set inference \lbatch size.\l&quot;];
    &quot;IDReader/decoder&quot; [label=&quot;id: IDReader/decoder\ltype: visionflow::opers::IDReaderDecoder\lupdate: 1970-01-01 00:00:00.0000000\ldocs: IDReader inference engine.\l&quot;];
    &quot;IDReader/decoder.args&quot; [label=&quot;id: IDReader/decoder.args\ltype: visionflow::param::IDReaderDecoderParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;IDReader/decoder.conf&quot; [label=&quot;id: IDReader/decoder.conf\ltype: visionflow::confs::IDReaderDecoderConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config the IDReader \linference parameters.\l&quot;];
    &quot;IDReader/featmap_filter&quot; [label=&quot;id: IDReader/featmap_filter\ltype: visionflow::opers::SegmentationFeatureMapFilter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to filter feature map \linto list of polygon regions.\l&quot;];
    &quot;IDReader/featmap_filter.args&quot; [label=&quot;id: IDReader/featmap_filter.args\ltype: visionflow::param::FeatureMapFilterParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Parameters to config the feature \lmap filter.\l&quot;];
    &quot;IDReader/featmap_filter.conf&quot; [label=&quot;id: IDReader/featmap_filter.conf\ltype: visionflow::confs::FeatureMapFilterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to config the \lfeature map filter.\l&quot;];
    &quot;IDReader/feature_map&quot; [label=&quot;id: IDReader/feature_map\ltype: visionflow::props::FeatureMap\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure used to store \lfeature maps detected by each \lalgorithm module.\l&quot;];
    &quot;IDReader/filter&quot; [label=&quot;id: IDReader/filter\ltype: visionflow::opers::PolygonsFilter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: An operator to filter list of \lregions with some common thresholds \lor customized python filter script.\l&quot;];
    &quot;IDReader/filter.args&quot; [label=&quot;id: IDReader/filter.args\ltype: visionflow::param::PolygonsFilterParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;IDReader/filter.conf&quot; [label=&quot;id: IDReader/filter.conf\ltype: visionflow::confs::PolygonsFilterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to generate the \lpolygon filter args.\l&quot;];
    &quot;IDReader/filter_pred&quot; [label=&quot;id: IDReader/filter_pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;IDReader/infer&quot; [label=&quot;id: IDReader/infer\ltype: visionflow::opers::IDReaderInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: IDReader Caffe inference engine.\l&quot;];
    &quot;IDReader/infer.args&quot; [label=&quot;id: IDReader/infer.args\ltype: visionflow::param::SegmentationInferenceParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;IDReader/infer.conf&quot; [label=&quot;id: IDReader/infer.conf\ltype: visionflow::confs::SegmentationInferenceConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config the segmentation \linference parameters.\l&quot;];
    &quot;IDReader/model&quot; [label=&quot;id: IDReader/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;IDReader/model.args&quot; [label=&quot;id: IDReader/model.args\ltype: visionflow::param::IDReaderLocationModelParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;IDReader/model.conf&quot; [label=&quot;id: IDReader/model.conf\ltype: visionflow::confs::IDReaderLocationModelParamConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config the IDReader \llocation model parameters.\l&quot;];
    &quot;IDReader/model_generator&quot; [label=&quot;id: IDReader/model_generator\ltype: visionflow::confs::IDReaderLocationModelConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: IDReader location model configurator.\l&quot;];
    &quot;IDReader/pred&quot; [label=&quot;id: IDReader/pred\ltype: visionflow::props::IDReaderRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;IDReader/raw_pred&quot; [label=&quot;id: IDReader/raw_pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;]
  }

  &quot;IDReader/batch_size&quot; -&gt; &quot;IDReader/infer&quot;;
  &quot;IDReader/batch_size.conf&quot; -&gt; &quot;IDReader/batch_size&quot;;
  &quot;IDReader/decoder&quot; -&gt; &quot;IDReader/pred&quot;;
  &quot;IDReader/decoder.args&quot; -&gt; &quot;IDReader/decoder&quot;;
  &quot;IDReader/decoder.conf&quot; -&gt; &quot;IDReader/decoder.args&quot;;
  &quot;IDReader/featmap_filter&quot; -&gt; &quot;IDReader/raw_pred&quot;;
  &quot;IDReader/featmap_filter.args&quot; -&gt; &quot;IDReader/featmap_filter&quot;;
  &quot;IDReader/featmap_filter.conf&quot; -&gt; &quot;IDReader/featmap_filter.args&quot;;
  &quot;IDReader/feature_map&quot; -&gt; &quot;IDReader/featmap_filter&quot;;
  &quot;IDReader/filter&quot; -&gt; &quot;IDReader/filter_pred&quot;;
  &quot;IDReader/filter.args&quot; -&gt; &quot;IDReader/filter&quot;;
  &quot;IDReader/filter.conf&quot; -&gt; &quot;IDReader/filter.args&quot;;
  &quot;IDReader/filter_pred&quot; -&gt; &quot;IDReader/decoder&quot;;
  &quot;IDReader/image&quot; -&gt; &quot;IDReader/decoder&quot;;
  &quot;IDReader/image&quot; -&gt; &quot;IDReader/infer&quot;;
  &quot;IDReader/infer&quot; -&gt; &quot;IDReader/feature_map&quot;;
  &quot;IDReader/infer.args&quot; -&gt; &quot;IDReader/infer&quot;;
  &quot;IDReader/infer.conf&quot; -&gt; &quot;IDReader/infer.args&quot;;
  &quot;IDReader/model&quot; -&gt; &quot;IDReader/infer&quot;;
  &quot;IDReader/model.args&quot; -&gt; &quot;IDReader/model_generator&quot;;
  &quot;IDReader/model.conf&quot; -&gt; &quot;IDReader/model.args&quot;;
  &quot;IDReader/model_generator&quot; -&gt; &quot;IDReader/model&quot;;
  &quot;IDReader/raw_pred&quot; -&gt; &quot;IDReader/filter&quot;;
  &quot;IDReader/views&quot; -&gt; &quot;IDReader/infer&quot;

}</p></object></div>
</section>
<section id="unsupersegmentation-tool">
<h2>UnsuperSegmentation Tool<a class="headerlink" href="#unsupersegmentation-tool" title="Link to this heading">#</a></h2>
<p>Unsuper Segmentation Tool, It is suitable for pixel-level defect detection tasks, and can identify the pixel-level fine structure of the target.</p>
<div class="graphviz"><object data="../_images/graphviz-5716b978f10362414935cb9d4cbb6ff51e197cf5.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: UnsuperSegmentation&quot; {
  label=&quot;OnlyTool: UnsuperSegmentation&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;UnsuperSegmentation/comparator&quot;;
  &quot;UnsuperSegmentation/featmap_filter&quot;;
  &quot;UnsuperSegmentation/filter&quot;;
  &quot;UnsuperSegmentation/infer&quot;;
  &quot;UnsuperSegmentation/label_oper&quot;;
  &quot;UnsuperSegmentation/view_tagger&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;UnsuperSegmentation/base_color_conf&quot;;
  &quot;UnsuperSegmentation/batch_size_conf&quot;;
  &quot;UnsuperSegmentation/featmap_filter.conf&quot;;
  &quot;UnsuperSegmentation/filter.conf&quot;;
  &quot;UnsuperSegmentation/image_mean_conf&quot;;
  &quot;UnsuperSegmentation/infer.conf&quot;;
  &quot;UnsuperSegmentation/label_oper.conf&quot;;
  &quot;UnsuperSegmentation/statistician&quot;;
  &quot;UnsuperSegmentation/trainer&quot;;
  &quot;UnsuperSegmentation/trainer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;UnsuperSegmentation/feature_map&quot;;
  &quot;UnsuperSegmentation/mask&quot;;
  &quot;UnsuperSegmentation/match_result&quot;;
  &quot;UnsuperSegmentation/raw_pred&quot;;
  &quot;UnsuperSegmentation/tagged_polygons&quot;;
  &quot;UnsuperSegmentation/tagged_views&quot;;
  &quot;UnsuperSegmentation/truth&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;UnsuperSegmentation/image&quot;;
  &quot;UnsuperSegmentation/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;UnsuperSegmentation/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;UnsuperSegmentation/base_color&quot;;
  &quot;UnsuperSegmentation/batch_size&quot;;
  &quot;UnsuperSegmentation/featmap_filter.args&quot;;
  &quot;UnsuperSegmentation/filter.args&quot;;
  &quot;UnsuperSegmentation/image_mean&quot;;
  &quot;UnsuperSegmentation/infer.args&quot;;
  &quot;UnsuperSegmentation/label_oper.args&quot;;
  &quot;UnsuperSegmentation/model&quot;;
  &quot;UnsuperSegmentation/statistics&quot;;
  &quot;UnsuperSegmentation/trainer.args&quot;;
  &quot;UnsuperSegmentation/training_log&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style



  subgraph &quot;cluster_UnsuperSegmentation&quot; {
    label=&quot;UnsuperSegmentation&quot;;
    &quot;UnsuperSegmentation/base_color&quot; [label=&quot;id: UnsuperSegmentation/base_color\ltype: visionflow::param::BaseColor\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;UnsuperSegmentation/base_color_conf&quot; [label=&quot;id: UnsuperSegmentation/base_color_conf\ltype: visionflow::confs::BaseColorConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config input images' \lbase color.\l&quot;];
    &quot;UnsuperSegmentation/batch_size&quot; [label=&quot;id: UnsuperSegmentation/batch_size\ltype: visionflow::param::InferenceBatchSize\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Inference BatchSize and Inference \lMode. Currently only contains \lbatch size. It may need to be \lrefactored in the future.\l&quot;];
    &quot;UnsuperSegmentation/batch_size_conf&quot; [label=&quot;id: UnsuperSegmentation/batch_size_conf\ltype: visionflow::confs::InferenceBatchSizeConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set inference \lbatch size.\l&quot;];
    &quot;UnsuperSegmentation/comparator&quot; [label=&quot;id: UnsuperSegmentation/comparator\ltype: visionflow::opers::RegionsMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to compare the predicted \lregions with the ground truth \lto get the category (in [TP, FP, \lTN, FN]) of each region.\l&quot;];
    &quot;UnsuperSegmentation/featmap_filter&quot; [label=&quot;id: UnsuperSegmentation/featmap_filter\ltype: visionflow::opers::SegmentationFeatureMapFilter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to filter feature map \linto list of polygon regions.\l&quot;];
    &quot;UnsuperSegmentation/featmap_filter.args&quot; [label=&quot;id: UnsuperSegmentation/featmap_filter.args\ltype: visionflow::param::FeatureMapFilterParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Parameters to config the feature \lmap filter.\l&quot;];
    &quot;UnsuperSegmentation/featmap_filter.conf&quot; [label=&quot;id: UnsuperSegmentation/featmap_filter.conf\ltype: visionflow::confs::FeatureMapFilterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to config the \lfeature map filter.\l&quot;];
    &quot;UnsuperSegmentation/feature_map&quot; [label=&quot;id: UnsuperSegmentation/feature_map\ltype: visionflow::props::FeatureMap\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure used to store \lfeature maps detected by each \lalgorithm module.\l&quot;];
    &quot;UnsuperSegmentation/filter&quot; [label=&quot;id: UnsuperSegmentation/filter\ltype: visionflow::opers::PolygonsFilter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: An operator to filter list of \lregions with some common thresholds \lor customized python filter script.\l&quot;];
    &quot;UnsuperSegmentation/filter.args&quot; [label=&quot;id: UnsuperSegmentation/filter.args\ltype: visionflow::param::PolygonsFilterParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;UnsuperSegmentation/filter.conf&quot; [label=&quot;id: UnsuperSegmentation/filter.conf\ltype: visionflow::confs::PolygonsFilterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to generate the \lpolygon filter args.\l&quot;];
    &quot;UnsuperSegmentation/image_mean&quot; [label=&quot;id: UnsuperSegmentation/image_mean\ltype: visionflow::param::ImageMean\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Image mean parameters\l&quot;];
    &quot;UnsuperSegmentation/image_mean_conf&quot; [label=&quot;id: UnsuperSegmentation/image_mean_conf\ltype: visionflow::confs::ImageMeanConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: ImageMeanConf Configurator class \lto compute the image mean values \lin the views.\l&quot;];
    &quot;UnsuperSegmentation/infer&quot; [label=&quot;id: UnsuperSegmentation/infer\ltype: visionflow::opers::UnsuperSegmentationInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Unsuper Segmentation Caffe inference \lengine.\l&quot;];
    &quot;UnsuperSegmentation/infer.args&quot; [label=&quot;id: UnsuperSegmentation/infer.args\ltype: visionflow::param::UnsuperSegmentationInferenceParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: UnsuperSegmentationInferenceParameters\l&quot;];
    &quot;UnsuperSegmentation/infer.conf&quot; [label=&quot;id: UnsuperSegmentation/infer.conf\ltype: visionflow::confs::UnsuperSegmentationInferConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set unsuper segmentation \linfer param\l&quot;];
    &quot;UnsuperSegmentation/label_oper&quot; [label=&quot;id: UnsuperSegmentation/label_oper\ltype: visionflow::opers::UnsuperSegmentationLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for unsuper \lsegmentation tool.\l&quot;];
    &quot;UnsuperSegmentation/label_oper.args&quot; [label=&quot;id: UnsuperSegmentation/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;UnsuperSegmentation/label_oper.conf&quot; [label=&quot;id: UnsuperSegmentation/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;UnsuperSegmentation/mask&quot; [label=&quot;id: UnsuperSegmentation/mask\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;UnsuperSegmentation/match_result&quot; [label=&quot;id: UnsuperSegmentation/match_result\ltype: visionflow::props::RegionMatchResultList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure to store list \lof RegionMatchResult.\l&quot;];
    &quot;UnsuperSegmentation/model&quot; [label=&quot;id: UnsuperSegmentation/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;UnsuperSegmentation/pred&quot; [label=&quot;id: UnsuperSegmentation/pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;UnsuperSegmentation/raw_pred&quot; [label=&quot;id: UnsuperSegmentation/raw_pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;UnsuperSegmentation/statistician&quot; [label=&quot;id: UnsuperSegmentation/statistician\ltype: visionflow::confs::RegionMatchResultCounterV2\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count region match \lresults after filtered no-train \lregions.\l&quot;];
    &quot;UnsuperSegmentation/statistics&quot; [label=&quot;id: UnsuperSegmentation/statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;UnsuperSegmentation/tagged_polygons&quot; [label=&quot;id: UnsuperSegmentation/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;UnsuperSegmentation/tagged_views&quot; [label=&quot;id: UnsuperSegmentation/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;UnsuperSegmentation/trainer&quot; [label=&quot;id: UnsuperSegmentation/trainer\ltype: visionflow::confs::UnsuperSegmentationTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Model trainer for Unsuper Segmentation \lTool.\l&quot;];
    &quot;UnsuperSegmentation/trainer.args&quot; [label=&quot;id: UnsuperSegmentation/trainer.args\ltype: visionflow::param::UnsuperSegmentationTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Unsuper Segmentation Training \lParameters Group.\l&quot;];
    &quot;UnsuperSegmentation/trainer.conf&quot; [label=&quot;id: UnsuperSegmentation/trainer.conf\ltype: visionflow::confs::UnsuperSegmentationTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set unsuper segmentation \ltrainer options.\l&quot;];
    &quot;UnsuperSegmentation/training_log&quot; [label=&quot;id: UnsuperSegmentation/training_log\ltype: visionflow::param::TrainingLog\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;UnsuperSegmentation/truth&quot; [label=&quot;id: UnsuperSegmentation/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;UnsuperSegmentation/view_tagger&quot; [label=&quot;id: UnsuperSegmentation/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;]
  }

  &quot;UnsuperSegmentation/base_color&quot; -&gt; &quot;UnsuperSegmentation/image_mean_conf&quot;;
  &quot;UnsuperSegmentation/base_color&quot; -&gt; &quot;UnsuperSegmentation/trainer&quot;;
  &quot;UnsuperSegmentation/base_color_conf&quot; -&gt; &quot;UnsuperSegmentation/base_color&quot;;
  &quot;UnsuperSegmentation/batch_size&quot; -&gt; &quot;UnsuperSegmentation/infer&quot;;
  &quot;UnsuperSegmentation/batch_size_conf&quot; -&gt; &quot;UnsuperSegmentation/batch_size&quot;;
  &quot;UnsuperSegmentation/comparator&quot; -&gt; &quot;UnsuperSegmentation/match_result&quot;;
  &quot;UnsuperSegmentation/featmap_filter&quot; -&gt; &quot;UnsuperSegmentation/raw_pred&quot;;
  &quot;UnsuperSegmentation/featmap_filter.args&quot; -&gt; &quot;UnsuperSegmentation/featmap_filter&quot;;
  &quot;UnsuperSegmentation/featmap_filter.conf&quot; -&gt; &quot;UnsuperSegmentation/featmap_filter.args&quot;;
  &quot;UnsuperSegmentation/feature_map&quot; -&gt; &quot;UnsuperSegmentation/featmap_filter&quot;;
  &quot;UnsuperSegmentation/filter&quot; -&gt; &quot;UnsuperSegmentation/pred&quot;;
  &quot;UnsuperSegmentation/filter.args&quot; -&gt; &quot;UnsuperSegmentation/filter&quot;;
  &quot;UnsuperSegmentation/filter.conf&quot; -&gt; &quot;UnsuperSegmentation/filter.args&quot;;
  &quot;UnsuperSegmentation/image&quot; -&gt; &quot;UnsuperSegmentation/image_mean_conf&quot;;
  &quot;UnsuperSegmentation/image&quot; -&gt; &quot;UnsuperSegmentation/infer&quot;;
  &quot;UnsuperSegmentation/image&quot; -&gt; &quot;UnsuperSegmentation/label_oper&quot;;
  &quot;UnsuperSegmentation/image&quot; -&gt; &quot;UnsuperSegmentation/trainer&quot;;
  &quot;UnsuperSegmentation/image_mean&quot; -&gt; &quot;UnsuperSegmentation/trainer&quot;;
  &quot;UnsuperSegmentation/image_mean_conf&quot; -&gt; &quot;UnsuperSegmentation/image_mean&quot;;
  &quot;UnsuperSegmentation/infer&quot; -&gt; &quot;UnsuperSegmentation/feature_map&quot;;
  &quot;UnsuperSegmentation/infer.args&quot; -&gt; &quot;UnsuperSegmentation/infer&quot;;
  &quot;UnsuperSegmentation/infer.conf&quot; -&gt; &quot;UnsuperSegmentation/infer.args&quot;;
  &quot;UnsuperSegmentation/label_oper&quot; -&gt; &quot;UnsuperSegmentation/mask&quot;;
  &quot;UnsuperSegmentation/label_oper&quot; -&gt; &quot;UnsuperSegmentation/tagged_polygons&quot;;
  &quot;UnsuperSegmentation/label_oper&quot; -&gt; &quot;UnsuperSegmentation/truth&quot;;
  &quot;UnsuperSegmentation/label_oper.args&quot; -&gt; &quot;UnsuperSegmentation/label_oper&quot;;
  &quot;UnsuperSegmentation/label_oper.conf&quot; -&gt; &quot;UnsuperSegmentation/label_oper.args&quot;;
  &quot;UnsuperSegmentation/mask&quot; -&gt; &quot;UnsuperSegmentation/statistician&quot;;
  &quot;UnsuperSegmentation/mask&quot; -&gt; &quot;UnsuperSegmentation/trainer&quot;;
  &quot;UnsuperSegmentation/model&quot; -&gt; &quot;UnsuperSegmentation/infer&quot;;
  &quot;UnsuperSegmentation/pred&quot; -&gt; &quot;UnsuperSegmentation/comparator&quot;;
  &quot;UnsuperSegmentation/pred&quot; -&gt; &quot;UnsuperSegmentation/statistician&quot;;
  &quot;UnsuperSegmentation/raw_pred&quot; -&gt; &quot;UnsuperSegmentation/filter&quot;;
  &quot;UnsuperSegmentation/statistician&quot; -&gt; &quot;UnsuperSegmentation/statistics&quot;;
  &quot;UnsuperSegmentation/tagged_polygons&quot; -&gt; &quot;UnsuperSegmentation/view_tagger&quot;;
  &quot;UnsuperSegmentation/tagged_views&quot; -&gt; &quot;UnsuperSegmentation/comparator&quot;;
  &quot;UnsuperSegmentation/tagged_views&quot; -&gt; &quot;UnsuperSegmentation/image_mean_conf&quot;;
  &quot;UnsuperSegmentation/tagged_views&quot; -&gt; &quot;UnsuperSegmentation/statistician&quot;;
  &quot;UnsuperSegmentation/tagged_views&quot; -&gt; &quot;UnsuperSegmentation/trainer&quot;;
  &quot;UnsuperSegmentation/trainer&quot; -&gt; &quot;UnsuperSegmentation/model&quot;;
  &quot;UnsuperSegmentation/trainer&quot; -&gt; &quot;UnsuperSegmentation/training_log&quot;;
  &quot;UnsuperSegmentation/trainer.args&quot; -&gt; &quot;UnsuperSegmentation/trainer&quot;;
  &quot;UnsuperSegmentation/trainer.conf&quot; -&gt; &quot;UnsuperSegmentation/trainer.args&quot;;
  &quot;UnsuperSegmentation/truth&quot; -&gt; &quot;UnsuperSegmentation/comparator&quot;;
  &quot;UnsuperSegmentation/truth&quot; -&gt; &quot;UnsuperSegmentation/statistician&quot;;
  &quot;UnsuperSegmentation/truth&quot; -&gt; &quot;UnsuperSegmentation/trainer&quot;;
  &quot;UnsuperSegmentation/view_tagger&quot; -&gt; &quot;UnsuperSegmentation/tagged_views&quot;;
  &quot;UnsuperSegmentation/views&quot; -&gt; &quot;UnsuperSegmentation/infer&quot;;
  &quot;UnsuperSegmentation/views&quot; -&gt; &quot;UnsuperSegmentation/view_tagger&quot;

}</p></object></div>
</section>
<section id="input-tool">
<h2>Input Tool<a class="headerlink" href="#input-tool" title="Link to this heading">#</a></h2>
<p>Input Tool, Use to add image files into the project from filesystem or camera.</p>
<div class="graphviz"><object data="../_images/graphviz-78024d0aead1c31fbcf15fe4c8ae811b59f421f4.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: Input&quot; {
  label=&quot;OnlyTool: Input&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;Input/cam_image_grabber&quot;;
  &quot;Input/file_image_grabber&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;Input/cam_image_grabber.conf&quot;;
  &quot;Input/file_image_grabber.conf&quot;;
  &quot;Input/input_image.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style


  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style


  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;Input/image&quot;;
  &quot;Input/image_info&quot;;
  &quot;Input/image_user_data&quot;;
  &quot;Input/views&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;Input/cam_image_grabber.args&quot;;
  &quot;Input/file_image_grabber.args&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style
  &quot;Input/input_image.param&quot;


  subgraph &quot;cluster_Input&quot; {
    label=&quot;Input&quot;;
    &quot;Input/cam_image_grabber&quot; [label=&quot;id: Input/cam_image_grabber\ltype: visionflow::opers::CameraImageGrabber\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to grab image from camera.\l&quot;];
    &quot;Input/cam_image_grabber.args&quot; [label=&quot;id: Input/cam_image_grabber.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;Input/cam_image_grabber.conf&quot; [label=&quot;id: Input/cam_image_grabber.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;Input/file_image_grabber&quot; [label=&quot;id: Input/file_image_grabber\ltype: visionflow::opers::FileImageGrabber\lupdate: 1970-01-01 00:00:00.0000000\ldocs:  Operator to grab image from file.\l&quot;];
    &quot;Input/file_image_grabber.args&quot; [label=&quot;id: Input/file_image_grabber.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;Input/file_image_grabber.conf&quot; [label=&quot;id: Input/file_image_grabber.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;Input/image&quot; [label=&quot;id: Input/image\ltype: visionflow::props::Image\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property Image implementation.\l&quot;];
    &quot;Input/image_info&quot; [label=&quot;id: Input/image_info\ltype: visionflow::props::RawImageInfo\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Raw Image information.\l&quot;];
    &quot;Input/image_user_data&quot; [label=&quot;id: Input/image_user_data\ltype: visionflow::props::ImageUserData\lupdate: 1970-01-01 00:00:00.0000000\ldocs: User-defined image-related information.\l&quot;];
    &quot;Input/input_image.conf&quot; [label=&quot;id: Input/input_image.conf\ltype: visionflow::confs::InputImageConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \linput image parameter.\l&quot;];
    &quot;Input/input_image.param&quot; [label=&quot;id: Input/input_image.param\ltype: visionflow::param::InputImageParam\lupdate: 1970-01-01 00:00:00.0000000\ldocs: 输入图像相关参数，用\l于控制工程的输入图像\l格式规范.\l&quot;];
    &quot;Input/views&quot; [label=&quot;id: Input/views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;]
  }

  &quot;Input/cam_image_grabber&quot; -&gt; &quot;Input/image&quot;;
  &quot;Input/cam_image_grabber&quot; -&gt; &quot;Input/image_info&quot;;
  &quot;Input/cam_image_grabber&quot; -&gt; &quot;Input/image_user_data&quot;;
  &quot;Input/cam_image_grabber&quot; -&gt; &quot;Input/views&quot;;
  &quot;Input/cam_image_grabber.args&quot; -&gt; &quot;Input/cam_image_grabber&quot;;
  &quot;Input/cam_image_grabber.conf&quot; -&gt; &quot;Input/cam_image_grabber.args&quot;;
  &quot;Input/file_image_grabber&quot; -&gt; &quot;Input/image&quot;;
  &quot;Input/file_image_grabber&quot; -&gt; &quot;Input/image_info&quot;;
  &quot;Input/file_image_grabber&quot; -&gt; &quot;Input/image_user_data&quot;;
  &quot;Input/file_image_grabber&quot; -&gt; &quot;Input/views&quot;;
  &quot;Input/file_image_grabber.args&quot; -&gt; &quot;Input/file_image_grabber&quot;;
  &quot;Input/file_image_grabber.conf&quot; -&gt; &quot;Input/file_image_grabber.args&quot;;
  &quot;Input/input_image.conf&quot; -&gt; &quot;Input/input_image.param&quot;;
  &quot;Input/input_image.param&quot; -&gt; &quot;Input/cam_image_grabber&quot;;
  &quot;Input/input_image.param&quot; -&gt; &quot;Input/file_image_grabber&quot;

}</p></object></div>
</section>
<section id="ocr-tool">
<h2>OCR Tool<a class="headerlink" href="#ocr-tool" title="Link to this heading">#</a></h2>
<p>OCR Tool, suitable for recognizing various characters.</p>
<div class="graphviz"><object data="../_images/graphviz-1a70ad3800bf2046f946a889331844972f8c0876.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: OCR&quot; {
  label=&quot;OnlyTool: OCR&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;OCR/comparator&quot;;
  &quot;OCR/infer&quot;;
  &quot;OCR/infer_string_matcher&quot;;
  &quot;OCR/label_oper&quot;;
  &quot;OCR/truth_string_matcher&quot;;
  &quot;OCR/view_tagger&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;OCR/base_color_conf&quot;;
  &quot;OCR/batch_size_conf&quot;;
  &quot;OCR/image_mean_conf&quot;;
  &quot;OCR/infer.conf&quot;;
  &quot;OCR/label_classes.conf&quot;;
  &quot;OCR/label_oper.conf&quot;;
  &quot;OCR/statistician&quot;;
  &quot;OCR/strings_statistician&quot;;
  &quot;OCR/templates_conf&quot;;
  &quot;OCR/trainer&quot;;
  &quot;OCR/trainer.conf&quot;;
  &quot;OCR/universal_conf&quot;;
  &quot;OCR/universal_model.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;OCR/mask&quot;;
  &quot;OCR/match_result&quot;;
  &quot;OCR/tagged_polygons&quot;;
  &quot;OCR/tagged_views&quot;;
  &quot;OCR/truth&quot;;
  &quot;OCR/truth.strings&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;OCR/image&quot;;
  &quot;OCR/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;OCR/pred.characters&quot;;
  &quot;OCR/pred.strings&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;OCR/base_color&quot;;
  &quot;OCR/batch_size&quot;;
  &quot;OCR/image_mean&quot;;
  &quot;OCR/infer.args&quot;;
  &quot;OCR/label_oper.args&quot;;
  &quot;OCR/model&quot;;
  &quot;OCR/statistics&quot;;
  &quot;OCR/strings_statistics&quot;;
  &quot;OCR/templates&quot;;
  &quot;OCR/trainer.args&quot;;
  &quot;OCR/training_log&quot;;
  &quot;OCR/universal_model.args&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style
  &quot;OCR/classes&quot;


  subgraph &quot;cluster_OCR&quot; {
    label=&quot;OCR&quot;;
    &quot;OCR/base_color&quot; [label=&quot;id: OCR/base_color\ltype: visionflow::param::BaseColor\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;OCR/base_color_conf&quot; [label=&quot;id: OCR/base_color_conf\ltype: visionflow::confs::BaseColorConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config input images' \lbase color.\l&quot;];
    &quot;OCR/batch_size&quot; [label=&quot;id: OCR/batch_size\ltype: visionflow::param::InferenceBatchSize\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Inference BatchSize and Inference \lMode. Currently only contains \lbatch size. It may need to be \lrefactored in the future.\l&quot;];
    &quot;OCR/batch_size_conf&quot; [label=&quot;id: OCR/batch_size_conf\ltype: visionflow::confs::InferenceBatchSizeConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set inference \lbatch size.\l&quot;];
    &quot;OCR/classes&quot; [label=&quot;id: OCR/classes\ltype: visionflow::param::LabelClasses\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage label classes.\l&quot;];
    &quot;OCR/comparator&quot; [label=&quot;id: OCR/comparator\ltype: visionflow::opers::RegionsMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to compare the predicted \lregions with the ground truth \lto get the category (in [TP, FP, \lTN, FN]) of each region.\l&quot;];
    &quot;OCR/image_mean&quot; [label=&quot;id: OCR/image_mean\ltype: visionflow::param::ImageMean\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Image mean parameters\l&quot;];
    &quot;OCR/image_mean_conf&quot; [label=&quot;id: OCR/image_mean_conf\ltype: visionflow::confs::ImageMeanConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: ImageMeanConf Configurator class \lto compute the image mean values \lin the views.\l&quot;];
    &quot;OCR/infer&quot; [label=&quot;id: OCR/infer\ltype: visionflow::opers::OCRInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: OCR Caffe inference engine.\l&quot;];
    &quot;OCR/infer.args&quot; [label=&quot;id: OCR/infer.args\ltype: visionflow::param::OCRInferParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;OCR/infer.conf&quot; [label=&quot;id: OCR/infer.conf\ltype: visionflow::confs::OCRInferConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set OCR inference \lparameters.\l&quot;];
    &quot;OCR/infer_string_matcher&quot; [label=&quot;id: OCR/infer_string_matcher\ltype: visionflow::opers::OCRInferStringMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: OCR infer string matcher.\l&quot;];
    &quot;OCR/label_classes.conf&quot; [label=&quot;id: OCR/label_classes.conf\ltype: visionflow::confs::LabelClassesConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \llabel classes parameter.\l&quot;];
    &quot;OCR/label_oper&quot; [label=&quot;id: OCR/label_oper\ltype: visionflow::opers::OCRLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for OCR tool.\l&quot;];
    &quot;OCR/label_oper.args&quot; [label=&quot;id: OCR/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;OCR/label_oper.conf&quot; [label=&quot;id: OCR/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;OCR/mask&quot; [label=&quot;id: OCR/mask\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;OCR/match_result&quot; [label=&quot;id: OCR/match_result\ltype: visionflow::props::RegionMatchResultList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure to store list \lof RegionMatchResult.\l&quot;];
    &quot;OCR/model&quot; [label=&quot;id: OCR/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;OCR/pred.characters&quot; [label=&quot;id: OCR/pred.characters\ltype: visionflow::props::MultiNamesPolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;OCR/pred.strings&quot; [label=&quot;id: OCR/pred.strings\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;OCR/statistician&quot; [label=&quot;id: OCR/statistician\ltype: visionflow::confs::OCRRegionMatchResultCounter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count ocr region \lmatch results.\l&quot;];
    &quot;OCR/statistics&quot; [label=&quot;id: OCR/statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;OCR/strings_statistician&quot; [label=&quot;id: OCR/strings_statistician\ltype: visionflow::confs::RegionMatchResultCounter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count region match \lresults.\l&quot;];
    &quot;OCR/strings_statistics&quot; [label=&quot;id: OCR/strings_statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;OCR/tagged_polygons&quot; [label=&quot;id: OCR/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;OCR/tagged_views&quot; [label=&quot;id: OCR/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;OCR/templates&quot; [label=&quot;id: OCR/templates\ltype: visionflow::param::OCRTemplates\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;OCR/templates_conf&quot; [label=&quot;id: OCR/templates_conf\ltype: visionflow::confs::OCRTemplateConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to config OCR \lstring match templates.\l&quot;];
    &quot;OCR/trainer&quot; [label=&quot;id: OCR/trainer\ltype: visionflow::confs::OCRTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: OCR model trainer.\l&quot;];
    &quot;OCR/trainer.args&quot; [label=&quot;id: OCR/trainer.args\ltype: visionflow::param::OCRTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;OCR/trainer.conf&quot; [label=&quot;id: OCR/trainer.conf\ltype: visionflow::confs::OCRTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set OCR trainer \loptions.\l&quot;];
    &quot;OCR/training_log&quot; [label=&quot;id: OCR/training_log\ltype: visionflow::param::TrainingLog\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;OCR/truth&quot; [label=&quot;id: OCR/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;OCR/truth.strings&quot; [label=&quot;id: OCR/truth.strings\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;OCR/truth_string_matcher&quot; [label=&quot;id: OCR/truth_string_matcher\ltype: visionflow::opers::OCRTruthStringMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: OCR truth string matcher.\l&quot;];
    &quot;OCR/universal_conf&quot; [label=&quot;id: OCR/universal_conf\ltype: visionflow::confs::OCRUniversalModelConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: OCR universal model configurator.\l&quot;];
    &quot;OCR/universal_model.args&quot; [label=&quot;id: OCR/universal_model.args\ltype: visionflow::param::OCRUniversalModelParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;OCR/universal_model.conf&quot; [label=&quot;id: OCR/universal_model.conf\ltype: visionflow::confs::OCRUniversalModelParamConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set OCR universal \lmodel parameters.\l&quot;];
    &quot;OCR/view_tagger&quot; [label=&quot;id: OCR/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;]
  }

  &quot;OCR/base_color&quot; -&gt; &quot;OCR/image_mean_conf&quot;;
  &quot;OCR/base_color&quot; -&gt; &quot;OCR/trainer&quot;;
  &quot;OCR/base_color_conf&quot; -&gt; &quot;OCR/base_color&quot;;
  &quot;OCR/batch_size&quot; -&gt; &quot;OCR/infer&quot;;
  &quot;OCR/batch_size_conf&quot; -&gt; &quot;OCR/batch_size&quot;;
  &quot;OCR/classes&quot; -&gt; &quot;OCR/label_oper&quot;;
  &quot;OCR/classes&quot; -&gt; &quot;OCR/trainer&quot;;
  &quot;OCR/comparator&quot; -&gt; &quot;OCR/match_result&quot;;
  &quot;OCR/image&quot; -&gt; &quot;OCR/image_mean_conf&quot;;
  &quot;OCR/image&quot; -&gt; &quot;OCR/infer&quot;;
  &quot;OCR/image&quot; -&gt; &quot;OCR/label_oper&quot;;
  &quot;OCR/image&quot; -&gt; &quot;OCR/trainer&quot;;
  &quot;OCR/image_mean&quot; -&gt; &quot;OCR/trainer&quot;;
  &quot;OCR/image_mean_conf&quot; -&gt; &quot;OCR/image_mean&quot;;
  &quot;OCR/infer&quot; -&gt; &quot;OCR/pred.characters&quot;;
  &quot;OCR/infer.args&quot; -&gt; &quot;OCR/infer&quot;;
  &quot;OCR/infer.conf&quot; -&gt; &quot;OCR/infer.args&quot;;
  &quot;OCR/infer_string_matcher&quot; -&gt; &quot;OCR/pred.strings&quot;;
  &quot;OCR/label_classes.conf&quot; -&gt; &quot;OCR/classes&quot;;
  &quot;OCR/label_oper&quot; -&gt; &quot;OCR/mask&quot;;
  &quot;OCR/label_oper&quot; -&gt; &quot;OCR/tagged_polygons&quot;;
  &quot;OCR/label_oper&quot; -&gt; &quot;OCR/truth&quot;;
  &quot;OCR/label_oper.args&quot; -&gt; &quot;OCR/label_oper&quot;;
  &quot;OCR/label_oper.conf&quot; -&gt; &quot;OCR/label_oper.args&quot;;
  &quot;OCR/mask&quot; -&gt; &quot;OCR/statistician&quot;;
  &quot;OCR/mask&quot; -&gt; &quot;OCR/trainer&quot;;
  &quot;OCR/model&quot; -&gt; &quot;OCR/infer&quot;;
  &quot;OCR/model&quot; -&gt; &quot;OCR/infer_string_matcher&quot;;
  &quot;OCR/model&quot; -&gt; &quot;OCR/truth_string_matcher&quot;;
  &quot;OCR/pred.characters&quot; -&gt; &quot;OCR/comparator&quot;;
  &quot;OCR/pred.characters&quot; -&gt; &quot;OCR/infer_string_matcher&quot;;
  &quot;OCR/pred.characters&quot; -&gt; &quot;OCR/statistician&quot;;
  &quot;OCR/pred.strings&quot; -&gt; &quot;OCR/strings_statistician&quot;;
  &quot;OCR/statistician&quot; -&gt; &quot;OCR/statistics&quot;;
  &quot;OCR/strings_statistician&quot; -&gt; &quot;OCR/strings_statistics&quot;;
  &quot;OCR/tagged_polygons&quot; -&gt; &quot;OCR/view_tagger&quot;;
  &quot;OCR/tagged_views&quot; -&gt; &quot;OCR/comparator&quot;;
  &quot;OCR/tagged_views&quot; -&gt; &quot;OCR/image_mean_conf&quot;;
  &quot;OCR/tagged_views&quot; -&gt; &quot;OCR/statistician&quot;;
  &quot;OCR/tagged_views&quot; -&gt; &quot;OCR/strings_statistician&quot;;
  &quot;OCR/tagged_views&quot; -&gt; &quot;OCR/trainer&quot;;
  &quot;OCR/templates&quot; -&gt; &quot;OCR/infer_string_matcher&quot;;
  &quot;OCR/templates&quot; -&gt; &quot;OCR/truth_string_matcher&quot;;
  &quot;OCR/templates_conf&quot; -&gt; &quot;OCR/templates&quot;;
  &quot;OCR/trainer&quot; -&gt; &quot;OCR/model&quot;;
  &quot;OCR/trainer&quot; -&gt; &quot;OCR/training_log&quot;;
  &quot;OCR/trainer.args&quot; -&gt; &quot;OCR/trainer&quot;;
  &quot;OCR/trainer.conf&quot; -&gt; &quot;OCR/trainer.args&quot;;
  &quot;OCR/truth&quot; -&gt; &quot;OCR/comparator&quot;;
  &quot;OCR/truth&quot; -&gt; &quot;OCR/statistician&quot;;
  &quot;OCR/truth&quot; -&gt; &quot;OCR/trainer&quot;;
  &quot;OCR/truth&quot; -&gt; &quot;OCR/truth_string_matcher&quot;;
  &quot;OCR/truth.strings&quot; -&gt; &quot;OCR/strings_statistician&quot;;
  &quot;OCR/truth_string_matcher&quot; -&gt; &quot;OCR/truth.strings&quot;;
  &quot;OCR/universal_conf&quot; -&gt; &quot;OCR/model&quot;;
  &quot;OCR/universal_model.args&quot; -&gt; &quot;OCR/universal_conf&quot;;
  &quot;OCR/universal_model.conf&quot; -&gt; &quot;OCR/universal_model.args&quot;;
  &quot;OCR/view_tagger&quot; -&gt; &quot;OCR/tagged_views&quot;;
  &quot;OCR/views&quot; -&gt; &quot;OCR/infer&quot;;
  &quot;OCR/views&quot; -&gt; &quot;OCR/infer_string_matcher&quot;;
  &quot;OCR/views&quot; -&gt; &quot;OCR/truth_string_matcher&quot;;
  &quot;OCR/views&quot; -&gt; &quot;OCR/view_tagger&quot;

}</p></object></div>
</section>
<section id="segmentation-tool">
<h2>Segmentation Tool<a class="headerlink" href="#segmentation-tool" title="Link to this heading">#</a></h2>
<p>Segmentation Tool, It is suitable for pixel-level defect detection tasks, and can identify the pixel-level fine structure of the target.</p>
<div class="graphviz"><object data="../_images/graphviz-a579babcef45eef89fbec06c3d80014ad160bdea.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: Segmentation&quot; {
  label=&quot;OnlyTool: Segmentation&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;Segmentation/comparator&quot;;
  &quot;Segmentation/featmap_filter&quot;;
  &quot;Segmentation/filter&quot;;
  &quot;Segmentation/infer&quot;;
  &quot;Segmentation/label_oper&quot;;
  &quot;Segmentation/view_tagger&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;Segmentation/base_color_conf&quot;;
  &quot;Segmentation/batch_size_conf&quot;;
  &quot;Segmentation/featmap_filter.conf&quot;;
  &quot;Segmentation/filter.conf&quot;;
  &quot;Segmentation/image_mean_conf&quot;;
  &quot;Segmentation/infer.conf&quot;;
  &quot;Segmentation/label_classes.conf&quot;;
  &quot;Segmentation/label_oper.conf&quot;;
  &quot;Segmentation/sample_recommend&quot;;
  &quot;Segmentation/sample_recommend.conf&quot;;
  &quot;Segmentation/statistician&quot;;
  &quot;Segmentation/trainer&quot;;
  &quot;Segmentation/trainer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;Segmentation/feature_map&quot;;
  &quot;Segmentation/mask&quot;;
  &quot;Segmentation/match_result&quot;;
  &quot;Segmentation/raw_pred&quot;;
  &quot;Segmentation/tagged_polygons&quot;;
  &quot;Segmentation/tagged_views&quot;;
  &quot;Segmentation/truth&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;Segmentation/image&quot;;
  &quot;Segmentation/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;Segmentation/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;Segmentation/base_color&quot;;
  &quot;Segmentation/batch_size&quot;;
  &quot;Segmentation/featmap_filter.args&quot;;
  &quot;Segmentation/filter.args&quot;;
  &quot;Segmentation/image_mean&quot;;
  &quot;Segmentation/infer.args&quot;;
  &quot;Segmentation/label_oper.args&quot;;
  &quot;Segmentation/model&quot;;
  &quot;Segmentation/recommend_sample_set&quot;;
  &quot;Segmentation/sample_recommend.args&quot;;
  &quot;Segmentation/statistics&quot;;
  &quot;Segmentation/trainer.args&quot;;
  &quot;Segmentation/training_log&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style
  &quot;Segmentation/classes&quot;


  subgraph &quot;cluster_Segmentation&quot; {
    label=&quot;Segmentation&quot;;
    &quot;Segmentation/base_color&quot; [label=&quot;id: Segmentation/base_color\ltype: visionflow::param::BaseColor\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Segmentation/base_color_conf&quot; [label=&quot;id: Segmentation/base_color_conf\ltype: visionflow::confs::BaseColorConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config input images' \lbase color.\l&quot;];
    &quot;Segmentation/batch_size&quot; [label=&quot;id: Segmentation/batch_size\ltype: visionflow::param::InferenceBatchSize\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Inference BatchSize and Inference \lMode. Currently only contains \lbatch size. It may need to be \lrefactored in the future.\l&quot;];
    &quot;Segmentation/batch_size_conf&quot; [label=&quot;id: Segmentation/batch_size_conf\ltype: visionflow::confs::InferenceBatchSizeConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set inference \lbatch size.\l&quot;];
    &quot;Segmentation/classes&quot; [label=&quot;id: Segmentation/classes\ltype: visionflow::param::LabelClasses\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage label classes.\l&quot;];
    &quot;Segmentation/comparator&quot; [label=&quot;id: Segmentation/comparator\ltype: visionflow::opers::RegionsMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to compare the predicted \lregions with the ground truth \lto get the category (in [TP, FP, \lTN, FN]) of each region.\l&quot;];
    &quot;Segmentation/featmap_filter&quot; [label=&quot;id: Segmentation/featmap_filter\ltype: visionflow::opers::SegmentationFeatureMapFilter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to filter feature map \linto list of polygon regions.\l&quot;];
    &quot;Segmentation/featmap_filter.args&quot; [label=&quot;id: Segmentation/featmap_filter.args\ltype: visionflow::param::FeatureMapFilterParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Parameters to config the feature \lmap filter.\l&quot;];
    &quot;Segmentation/featmap_filter.conf&quot; [label=&quot;id: Segmentation/featmap_filter.conf\ltype: visionflow::confs::FeatureMapFilterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to config the \lfeature map filter.\l&quot;];
    &quot;Segmentation/feature_map&quot; [label=&quot;id: Segmentation/feature_map\ltype: visionflow::props::FeatureMap\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure used to store \lfeature maps detected by each \lalgorithm module.\l&quot;];
    &quot;Segmentation/filter&quot; [label=&quot;id: Segmentation/filter\ltype: visionflow::opers::PolygonsFilter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: An operator to filter list of \lregions with some common thresholds \lor customized python filter script.\l&quot;];
    &quot;Segmentation/filter.args&quot; [label=&quot;id: Segmentation/filter.args\ltype: visionflow::param::PolygonsFilterParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Segmentation/filter.conf&quot; [label=&quot;id: Segmentation/filter.conf\ltype: visionflow::confs::PolygonsFilterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to generate the \lpolygon filter args.\l&quot;];
    &quot;Segmentation/image_mean&quot; [label=&quot;id: Segmentation/image_mean\ltype: visionflow::param::ImageMean\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Image mean parameters\l&quot;];
    &quot;Segmentation/image_mean_conf&quot; [label=&quot;id: Segmentation/image_mean_conf\ltype: visionflow::confs::ImageMeanConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: ImageMeanConf Configurator class \lto compute the image mean values \lin the views.\l&quot;];
    &quot;Segmentation/infer&quot; [label=&quot;id: Segmentation/infer\ltype: visionflow::opers::SegmentationInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Segmentation Caffe inference engine.\l&quot;];
    &quot;Segmentation/infer.args&quot; [label=&quot;id: Segmentation/infer.args\ltype: visionflow::param::SegmentationInferenceParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Segmentation/infer.conf&quot; [label=&quot;id: Segmentation/infer.conf\ltype: visionflow::confs::SegmentationInferenceConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config the segmentation \linference parameters.\l&quot;];
    &quot;Segmentation/label_classes.conf&quot; [label=&quot;id: Segmentation/label_classes.conf\ltype: visionflow::confs::LabelClassesConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \llabel classes parameter.\l&quot;];
    &quot;Segmentation/label_oper&quot; [label=&quot;id: Segmentation/label_oper\ltype: visionflow::opers::SegmentationLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for segmentation \ltool.\l&quot;];
    &quot;Segmentation/label_oper.args&quot; [label=&quot;id: Segmentation/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;Segmentation/label_oper.conf&quot; [label=&quot;id: Segmentation/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;Segmentation/mask&quot; [label=&quot;id: Segmentation/mask\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Segmentation/match_result&quot; [label=&quot;id: Segmentation/match_result\ltype: visionflow::props::RegionMatchResultList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure to store list \lof RegionMatchResult.\l&quot;];
    &quot;Segmentation/model&quot; [label=&quot;id: Segmentation/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;Segmentation/pred&quot; [label=&quot;id: Segmentation/pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Segmentation/raw_pred&quot; [label=&quot;id: Segmentation/raw_pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Segmentation/recommend_sample_set&quot; [label=&quot;id: Segmentation/recommend_sample_set\ltype: visionflow::param::PropertyObjectIdSet\lupdate: 1970-01-01 00:00:00.0000000\ldocs:
    Parameter group for a set \lof property object IDs.
    \l&quot;];
    &quot;Segmentation/sample_recommend&quot; [label=&quot;id: Segmentation/sample_recommend\ltype: visionflow::confs::SegmentSampleRecommend\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Segmentation sample recommend \ltool.\l&quot;];
    &quot;Segmentation/sample_recommend.args&quot; [label=&quot;id: Segmentation/sample_recommend.args\ltype: visionflow::param::SampleRecommendationParameter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Parameter for the sample recommendation \lalgorithm\l&quot;];
    &quot;Segmentation/sample_recommend.conf&quot; [label=&quot;id: Segmentation/sample_recommend.conf\ltype: visionflow::confs::SampleRecommendationParameterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set sample recommend \lparam.\l&quot;];
    &quot;Segmentation/statistician&quot; [label=&quot;id: Segmentation/statistician\ltype: visionflow::confs::RegionMatchResultCounterV2\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count region match \lresults after filtered no-train \lregions.\l&quot;];
    &quot;Segmentation/statistics&quot; [label=&quot;id: Segmentation/statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;Segmentation/tagged_polygons&quot; [label=&quot;id: Segmentation/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;Segmentation/tagged_views&quot; [label=&quot;id: Segmentation/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;Segmentation/trainer&quot; [label=&quot;id: Segmentation/trainer\ltype: visionflow::confs::SegmentationTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Model trainer for Segmentation \lTool.\l&quot;];
    &quot;Segmentation/trainer.args&quot; [label=&quot;id: Segmentation/trainer.args\ltype: visionflow::param::SegmentationTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Segmentation Training Parameters \lGroup.\l&quot;];
    &quot;Segmentation/trainer.conf&quot; [label=&quot;id: Segmentation/trainer.conf\ltype: visionflow::confs::SegmentationTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set segmentation \ltrainer options.\l&quot;];
    &quot;Segmentation/training_log&quot; [label=&quot;id: Segmentation/training_log\ltype: visionflow::param::TrainingLog\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Segmentation/truth&quot; [label=&quot;id: Segmentation/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Segmentation/view_tagger&quot; [label=&quot;id: Segmentation/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;]
  }

  &quot;Segmentation/base_color&quot; -&gt; &quot;Segmentation/image_mean_conf&quot;;
  &quot;Segmentation/base_color&quot; -&gt; &quot;Segmentation/trainer&quot;;
  &quot;Segmentation/base_color_conf&quot; -&gt; &quot;Segmentation/base_color&quot;;
  &quot;Segmentation/batch_size&quot; -&gt; &quot;Segmentation/infer&quot;;
  &quot;Segmentation/batch_size_conf&quot; -&gt; &quot;Segmentation/batch_size&quot;;
  &quot;Segmentation/classes&quot; -&gt; &quot;Segmentation/label_oper&quot;;
  &quot;Segmentation/classes&quot; -&gt; &quot;Segmentation/trainer&quot;;
  &quot;Segmentation/comparator&quot; -&gt; &quot;Segmentation/match_result&quot;;
  &quot;Segmentation/featmap_filter&quot; -&gt; &quot;Segmentation/raw_pred&quot;;
  &quot;Segmentation/featmap_filter.args&quot; -&gt; &quot;Segmentation/featmap_filter&quot;;
  &quot;Segmentation/featmap_filter.conf&quot; -&gt; &quot;Segmentation/featmap_filter.args&quot;;
  &quot;Segmentation/feature_map&quot; -&gt; &quot;Segmentation/featmap_filter&quot;;
  &quot;Segmentation/filter&quot; -&gt; &quot;Segmentation/pred&quot;;
  &quot;Segmentation/filter.args&quot; -&gt; &quot;Segmentation/filter&quot;;
  &quot;Segmentation/filter.conf&quot; -&gt; &quot;Segmentation/filter.args&quot;;
  &quot;Segmentation/image&quot; -&gt; &quot;Segmentation/image_mean_conf&quot;;
  &quot;Segmentation/image&quot; -&gt; &quot;Segmentation/infer&quot;;
  &quot;Segmentation/image&quot; -&gt; &quot;Segmentation/label_oper&quot;;
  &quot;Segmentation/image&quot; -&gt; &quot;Segmentation/sample_recommend&quot;;
  &quot;Segmentation/image&quot; -&gt; &quot;Segmentation/trainer&quot;;
  &quot;Segmentation/image_mean&quot; -&gt; &quot;Segmentation/trainer&quot;;
  &quot;Segmentation/image_mean_conf&quot; -&gt; &quot;Segmentation/image_mean&quot;;
  &quot;Segmentation/infer&quot; -&gt; &quot;Segmentation/feature_map&quot;;
  &quot;Segmentation/infer.args&quot; -&gt; &quot;Segmentation/infer&quot;;
  &quot;Segmentation/infer.conf&quot; -&gt; &quot;Segmentation/infer.args&quot;;
  &quot;Segmentation/label_classes.conf&quot; -&gt; &quot;Segmentation/classes&quot;;
  &quot;Segmentation/label_oper&quot; -&gt; &quot;Segmentation/mask&quot;;
  &quot;Segmentation/label_oper&quot; -&gt; &quot;Segmentation/tagged_polygons&quot;;
  &quot;Segmentation/label_oper&quot; -&gt; &quot;Segmentation/truth&quot;;
  &quot;Segmentation/label_oper.args&quot; -&gt; &quot;Segmentation/label_oper&quot;;
  &quot;Segmentation/label_oper.conf&quot; -&gt; &quot;Segmentation/label_oper.args&quot;;
  &quot;Segmentation/mask&quot; -&gt; &quot;Segmentation/statistician&quot;;
  &quot;Segmentation/mask&quot; -&gt; &quot;Segmentation/trainer&quot;;
  &quot;Segmentation/model&quot; -&gt; &quot;Segmentation/infer&quot;;
  &quot;Segmentation/model&quot; -&gt; &quot;Segmentation/sample_recommend&quot;;
  &quot;Segmentation/pred&quot; -&gt; &quot;Segmentation/comparator&quot;;
  &quot;Segmentation/pred&quot; -&gt; &quot;Segmentation/statistician&quot;;
  &quot;Segmentation/raw_pred&quot; -&gt; &quot;Segmentation/filter&quot;;
  &quot;Segmentation/sample_recommend&quot; -&gt; &quot;Segmentation/recommend_sample_set&quot;;
  &quot;Segmentation/sample_recommend.args&quot; -&gt; &quot;Segmentation/sample_recommend&quot;;
  &quot;Segmentation/sample_recommend.conf&quot; -&gt; &quot;Segmentation/sample_recommend.args&quot;;
  &quot;Segmentation/statistician&quot; -&gt; &quot;Segmentation/statistics&quot;;
  &quot;Segmentation/tagged_polygons&quot; -&gt; &quot;Segmentation/view_tagger&quot;;
  &quot;Segmentation/tagged_views&quot; -&gt; &quot;Segmentation/comparator&quot;;
  &quot;Segmentation/tagged_views&quot; -&gt; &quot;Segmentation/image_mean_conf&quot;;
  &quot;Segmentation/tagged_views&quot; -&gt; &quot;Segmentation/sample_recommend&quot;;
  &quot;Segmentation/tagged_views&quot; -&gt; &quot;Segmentation/statistician&quot;;
  &quot;Segmentation/tagged_views&quot; -&gt; &quot;Segmentation/trainer&quot;;
  &quot;Segmentation/trainer&quot; -&gt; &quot;Segmentation/model&quot;;
  &quot;Segmentation/trainer&quot; -&gt; &quot;Segmentation/training_log&quot;;
  &quot;Segmentation/trainer.args&quot; -&gt; &quot;Segmentation/trainer&quot;;
  &quot;Segmentation/trainer.conf&quot; -&gt; &quot;Segmentation/trainer.args&quot;;
  &quot;Segmentation/truth&quot; -&gt; &quot;Segmentation/comparator&quot;;
  &quot;Segmentation/truth&quot; -&gt; &quot;Segmentation/statistician&quot;;
  &quot;Segmentation/truth&quot; -&gt; &quot;Segmentation/trainer&quot;;
  &quot;Segmentation/view_tagger&quot; -&gt; &quot;Segmentation/tagged_views&quot;;
  &quot;Segmentation/views&quot; -&gt; &quot;Segmentation/infer&quot;;
  &quot;Segmentation/views&quot; -&gt; &quot;Segmentation/view_tagger&quot;

}</p></object></div>
</section>
<section id="integration-tool">
<h2>Integration Tool<a class="headerlink" href="#integration-tool" title="Link to this heading">#</a></h2>
<p>Integration classification tool.</p>
<div class="graphviz"><object data="../_images/graphviz-b129cc869e7be2cb5964e05aaf657c9682771a3b.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: Integration&quot; {
  label=&quot;OnlyTool: Integration&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;Integration/classifier&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;Integration/classifier.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style


  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style


  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style
  &quot;Integration/properties&quot;

  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;Integration/integration_class&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;Integration/classifier.args&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style



  subgraph &quot;cluster_Integration&quot; {
    label=&quot;Integration&quot;;
    &quot;Integration/classifier&quot; [label=&quot;id: Integration/classifier\ltype: visionflow::opers::IntegrationClassifier\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Classifier operator for integration \ltool.\l&quot;];
    &quot;Integration/classifier.args&quot; [label=&quot;id: Integration/classifier.args\ltype: visionflow::param::IntegrationClassifyParameter\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Integration/classifier.conf&quot; [label=&quot;id: Integration/classifier.conf\ltype: visionflow::confs::IntegrationClassifierConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config the integration \lclassifier.\l&quot;];
    &quot;Integration/integration_class&quot; [label=&quot;id: Integration/integration_class\ltype: visionflow::props::StringMessage\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Properties for string message.\l&quot;]
  }

  &quot;Integration/classifier&quot; -&gt; &quot;Integration/integration_class&quot;;
  &quot;Integration/classifier.args&quot; -&gt; &quot;Integration/classifier&quot;;
  &quot;Integration/classifier.conf&quot; -&gt; &quot;Integration/classifier.args&quot;;
  &quot;Integration/properties&quot; -&gt; &quot;Integration/classifier&quot;

}</p></object></div>
</section>
<section id="geometrysearch-tool">
<h2>GeometrySearch Tool<a class="headerlink" href="#geometrysearch-tool" title="Link to this heading">#</a></h2>
<p>GeometrySearch Tool. Locate objects in high precision based on traditional image processing algorithms.</p>
<div class="graphviz"><object data="../_images/graphviz-a10a16ec1af5b57cc97352a3a8618d5ad6f02c1c.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: GeometrySearch&quot; {
  label=&quot;OnlyTool: GeometrySearch&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;GeometrySearch/infer&quot;;
  &quot;GeometrySearch/label_oper&quot;;
  &quot;GeometrySearch/view_tagger&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;GeometrySearch/infer.conf&quot;;
  &quot;GeometrySearch/label_classes.conf&quot;;
  &quot;GeometrySearch/label_oper.conf&quot;;
  &quot;GeometrySearch/trainer&quot;;
  &quot;GeometrySearch/trainer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;GeometrySearch/mask&quot;;
  &quot;GeometrySearch/tagged_polygons&quot;;
  &quot;GeometrySearch/tagged_views&quot;;
  &quot;GeometrySearch/truth&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;GeometrySearch/image&quot;;
  &quot;GeometrySearch/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;GeometrySearch/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;GeometrySearch/classes&quot;;
  &quot;GeometrySearch/feature_model_list&quot;;
  &quot;GeometrySearch/infer.args&quot;;
  &quot;GeometrySearch/label_oper.args&quot;;
  &quot;GeometrySearch/model&quot;;
  &quot;GeometrySearch/trainer.args&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style



  subgraph &quot;cluster_GeometrySearch&quot; {
    label=&quot;GeometrySearch&quot;;
    &quot;GeometrySearch/classes&quot; [label=&quot;id: GeometrySearch/classes\ltype: visionflow::param::LabelClasses\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage label classes.\l&quot;];
    &quot;GeometrySearch/feature_model_list&quot; [label=&quot;id: GeometrySearch/feature_model_list\ltype: visionflow::param::GeometrySearchFeatureModelList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure to store list \lof template match feature chains.\l&quot;];
    &quot;GeometrySearch/infer&quot; [label=&quot;id: GeometrySearch/infer\ltype: visionflow::opers::GeometrySearchInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: GeometrySearch inference engine.\l&quot;];
    &quot;GeometrySearch/infer.args&quot; [label=&quot;id: GeometrySearch/infer.args\ltype: visionflow::param::GeometrySearchInferParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;GeometrySearch/infer.conf&quot; [label=&quot;id: GeometrySearch/infer.conf\ltype: visionflow::confs::GeometrySearchInferConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set GeometrySearch \linference parameters.\l&quot;];
    &quot;GeometrySearch/label_classes.conf&quot; [label=&quot;id: GeometrySearch/label_classes.conf\ltype: visionflow::confs::LabelClassesConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \llabel classes parameter.\l&quot;];
    &quot;GeometrySearch/label_oper&quot; [label=&quot;id: GeometrySearch/label_oper\ltype: visionflow::opers::GeometrySearchLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for GeometrySearch \ltool.\l&quot;];
    &quot;GeometrySearch/label_oper.args&quot; [label=&quot;id: GeometrySearch/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;GeometrySearch/label_oper.conf&quot; [label=&quot;id: GeometrySearch/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;GeometrySearch/mask&quot; [label=&quot;id: GeometrySearch/mask\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;GeometrySearch/model&quot; [label=&quot;id: GeometrySearch/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;GeometrySearch/pred&quot; [label=&quot;id: GeometrySearch/pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;GeometrySearch/tagged_polygons&quot; [label=&quot;id: GeometrySearch/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;GeometrySearch/tagged_views&quot; [label=&quot;id: GeometrySearch/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;GeometrySearch/trainer&quot; [label=&quot;id: GeometrySearch/trainer\ltype: visionflow::confs::GeometrySearchTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: GeometrySearch model trainer.\l&quot;];
    &quot;GeometrySearch/trainer.args&quot; [label=&quot;id: GeometrySearch/trainer.args\ltype: visionflow::param::GeometrySearchTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: GeometrySearch Training  Parameter \lGroup\l&quot;];
    &quot;GeometrySearch/trainer.conf&quot; [label=&quot;id: GeometrySearch/trainer.conf\ltype: visionflow::confs::GeometrySearchTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set GeometrySearch \ltrainer options.\l&quot;];
    &quot;GeometrySearch/truth&quot; [label=&quot;id: GeometrySearch/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;GeometrySearch/view_tagger&quot; [label=&quot;id: GeometrySearch/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;]
  }

  &quot;GeometrySearch/classes&quot; -&gt; &quot;GeometrySearch/label_oper&quot;;
  &quot;GeometrySearch/classes&quot; -&gt; &quot;GeometrySearch/trainer&quot;;
  &quot;GeometrySearch/image&quot; -&gt; &quot;GeometrySearch/infer&quot;;
  &quot;GeometrySearch/image&quot; -&gt; &quot;GeometrySearch/label_oper&quot;;
  &quot;GeometrySearch/image&quot; -&gt; &quot;GeometrySearch/trainer&quot;;
  &quot;GeometrySearch/infer&quot; -&gt; &quot;GeometrySearch/pred&quot;;
  &quot;GeometrySearch/infer.args&quot; -&gt; &quot;GeometrySearch/infer&quot;;
  &quot;GeometrySearch/infer.conf&quot; -&gt; &quot;GeometrySearch/infer.args&quot;;
  &quot;GeometrySearch/label_classes.conf&quot; -&gt; &quot;GeometrySearch/classes&quot;;
  &quot;GeometrySearch/label_oper&quot; -&gt; &quot;GeometrySearch/mask&quot;;
  &quot;GeometrySearch/label_oper&quot; -&gt; &quot;GeometrySearch/tagged_polygons&quot;;
  &quot;GeometrySearch/label_oper&quot; -&gt; &quot;GeometrySearch/truth&quot;;
  &quot;GeometrySearch/label_oper.args&quot; -&gt; &quot;GeometrySearch/label_oper&quot;;
  &quot;GeometrySearch/label_oper.conf&quot; -&gt; &quot;GeometrySearch/label_oper.args&quot;;
  &quot;GeometrySearch/mask&quot; -&gt; &quot;GeometrySearch/trainer&quot;;
  &quot;GeometrySearch/model&quot; -&gt; &quot;GeometrySearch/infer&quot;;
  &quot;GeometrySearch/tagged_polygons&quot; -&gt; &quot;GeometrySearch/view_tagger&quot;;
  &quot;GeometrySearch/tagged_views&quot; -&gt; &quot;GeometrySearch/trainer&quot;;
  &quot;GeometrySearch/trainer&quot; -&gt; &quot;GeometrySearch/feature_model_list&quot;;
  &quot;GeometrySearch/trainer&quot; -&gt; &quot;GeometrySearch/model&quot;;
  &quot;GeometrySearch/trainer.args&quot; -&gt; &quot;GeometrySearch/trainer&quot;;
  &quot;GeometrySearch/trainer.conf&quot; -&gt; &quot;GeometrySearch/trainer.args&quot;;
  &quot;GeometrySearch/truth&quot; -&gt; &quot;GeometrySearch/trainer&quot;;
  &quot;GeometrySearch/view_tagger&quot; -&gt; &quot;GeometrySearch/tagged_views&quot;;
  &quot;GeometrySearch/views&quot; -&gt; &quot;GeometrySearch/infer&quot;;
  &quot;GeometrySearch/views&quot; -&gt; &quot;GeometrySearch/view_tagger&quot;

}</p></object></div>
</section>
<section id="unsuperclassification-tool">
<h2>UnsuperClassification Tool<a class="headerlink" href="#unsuperclassification-tool" title="Link to this heading">#</a></h2>
<p>Unsuper Classification Tool</p>
<div class="graphviz"><object data="../_images/graphviz-c79cb9cd772d771f46bbafc69f2875d0ddb584cd.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: UnsuperClassification&quot; {
  label=&quot;OnlyTool: UnsuperClassification&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;UnsuperClassification/comparator&quot;;
  &quot;UnsuperClassification/infer&quot;;
  &quot;UnsuperClassification/label_oper&quot;;
  &quot;UnsuperClassification/view_tagger&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;UnsuperClassification/base_color_conf&quot;;
  &quot;UnsuperClassification/batch_size_conf&quot;;
  &quot;UnsuperClassification/image_mean_conf&quot;;
  &quot;UnsuperClassification/infer.conf&quot;;
  &quot;UnsuperClassification/label_oper.conf&quot;;
  &quot;UnsuperClassification/statistician&quot;;
  &quot;UnsuperClassification/trainer&quot;;
  &quot;UnsuperClassification/trainer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;UnsuperClassification/feature_map&quot;;
  &quot;UnsuperClassification/mask&quot;;
  &quot;UnsuperClassification/match_result&quot;;
  &quot;UnsuperClassification/tagged_polygons&quot;;
  &quot;UnsuperClassification/tagged_views&quot;;
  &quot;UnsuperClassification/truth&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;UnsuperClassification/image&quot;;
  &quot;UnsuperClassification/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;UnsuperClassification/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;UnsuperClassification/base_color&quot;;
  &quot;UnsuperClassification/batch_size&quot;;
  &quot;UnsuperClassification/image_mean&quot;;
  &quot;UnsuperClassification/infer.args&quot;;
  &quot;UnsuperClassification/label_oper.args&quot;;
  &quot;UnsuperClassification/model&quot;;
  &quot;UnsuperClassification/statistics&quot;;
  &quot;UnsuperClassification/trainer.args&quot;;
  &quot;UnsuperClassification/training_log&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style



  subgraph &quot;cluster_UnsuperClassification&quot; {
    label=&quot;UnsuperClassification&quot;;
    &quot;UnsuperClassification/base_color&quot; [label=&quot;id: UnsuperClassification/base_color\ltype: visionflow::param::BaseColor\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;UnsuperClassification/base_color_conf&quot; [label=&quot;id: UnsuperClassification/base_color_conf\ltype: visionflow::confs::BaseColorConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config input images' \lbase color.\l&quot;];
    &quot;UnsuperClassification/batch_size&quot; [label=&quot;id: UnsuperClassification/batch_size\ltype: visionflow::param::InferenceBatchSize\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Inference BatchSize and Inference \lMode. Currently only contains \lbatch size. It may need to be \lrefactored in the future.\l&quot;];
    &quot;UnsuperClassification/batch_size_conf&quot; [label=&quot;id: UnsuperClassification/batch_size_conf\ltype: visionflow::confs::InferenceBatchSizeConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set inference \lbatch size.\l&quot;];
    &quot;UnsuperClassification/comparator&quot; [label=&quot;id: UnsuperClassification/comparator\ltype: visionflow::opers::RegionsMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to compare the predicted \lregions with the ground truth \lto get the category (in [TP, FP, \lTN, FN]) of each region.\l&quot;];
    &quot;UnsuperClassification/feature_map&quot; [label=&quot;id: UnsuperClassification/feature_map\ltype: visionflow::props::FeatureMap\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure used to store \lfeature maps detected by each \lalgorithm module.\l&quot;];
    &quot;UnsuperClassification/image_mean&quot; [label=&quot;id: UnsuperClassification/image_mean\ltype: visionflow::param::ImageMean\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Image mean parameters\l&quot;];
    &quot;UnsuperClassification/image_mean_conf&quot; [label=&quot;id: UnsuperClassification/image_mean_conf\ltype: visionflow::confs::ImageMeanConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: ImageMeanConf Configurator class \lto compute the image mean values \lin the views.\l&quot;];
    &quot;UnsuperClassification/infer&quot; [label=&quot;id: UnsuperClassification/infer\ltype: visionflow::opers::UnsuperClassificationInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Unsuper Segmentation Caffe inference \lengine.\l&quot;];
    &quot;UnsuperClassification/infer.args&quot; [label=&quot;id: UnsuperClassification/infer.args\ltype: visionflow::param::UnsuperClassificationInferenceParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Parameters using for unsuper classification \linference\l&quot;];
    &quot;UnsuperClassification/infer.conf&quot; [label=&quot;id: UnsuperClassification/infer.conf\ltype: visionflow::confs::UnsuperClassificationInferConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set unsuper classification \linfer param\l&quot;];
    &quot;UnsuperClassification/label_oper&quot; [label=&quot;id: UnsuperClassification/label_oper\ltype: visionflow::opers::UnsuperClassificationLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for unsuper \lclassification tool.\l&quot;];
    &quot;UnsuperClassification/label_oper.args&quot; [label=&quot;id: UnsuperClassification/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;UnsuperClassification/label_oper.conf&quot; [label=&quot;id: UnsuperClassification/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;UnsuperClassification/mask&quot; [label=&quot;id: UnsuperClassification/mask\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;UnsuperClassification/match_result&quot; [label=&quot;id: UnsuperClassification/match_result\ltype: visionflow::props::RegionMatchResultList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure to store list \lof RegionMatchResult.\l&quot;];
    &quot;UnsuperClassification/model&quot; [label=&quot;id: UnsuperClassification/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;UnsuperClassification/pred&quot; [label=&quot;id: UnsuperClassification/pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;UnsuperClassification/statistician&quot; [label=&quot;id: UnsuperClassification/statistician\ltype: visionflow::confs::ClassificationRegionMatchResultCounter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count classification \lregion match results.\l&quot;];
    &quot;UnsuperClassification/statistics&quot; [label=&quot;id: UnsuperClassification/statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;UnsuperClassification/tagged_polygons&quot; [label=&quot;id: UnsuperClassification/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;UnsuperClassification/tagged_views&quot; [label=&quot;id: UnsuperClassification/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;UnsuperClassification/trainer&quot; [label=&quot;id: UnsuperClassification/trainer\ltype: visionflow::confs::UnsuperClassificationTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Model trainer for Unsuper Classification \lTool.\l&quot;];
    &quot;UnsuperClassification/trainer.args&quot; [label=&quot;id: UnsuperClassification/trainer.args\ltype: visionflow::param::UnsuperClassificationTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Unsuper Classification Training \lParameters Group.\l&quot;];
    &quot;UnsuperClassification/trainer.conf&quot; [label=&quot;id: UnsuperClassification/trainer.conf\ltype: visionflow::confs::UnsuperClassificationTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set unsuper classification \ltrainer options.\l&quot;];
    &quot;UnsuperClassification/training_log&quot; [label=&quot;id: UnsuperClassification/training_log\ltype: visionflow::param::TrainingLog\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;UnsuperClassification/truth&quot; [label=&quot;id: UnsuperClassification/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;UnsuperClassification/view_tagger&quot; [label=&quot;id: UnsuperClassification/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;]
  }

  &quot;UnsuperClassification/base_color&quot; -&gt; &quot;UnsuperClassification/image_mean_conf&quot;;
  &quot;UnsuperClassification/base_color&quot; -&gt; &quot;UnsuperClassification/trainer&quot;;
  &quot;UnsuperClassification/base_color_conf&quot; -&gt; &quot;UnsuperClassification/base_color&quot;;
  &quot;UnsuperClassification/batch_size&quot; -&gt; &quot;UnsuperClassification/infer&quot;;
  &quot;UnsuperClassification/batch_size_conf&quot; -&gt; &quot;UnsuperClassification/batch_size&quot;;
  &quot;UnsuperClassification/comparator&quot; -&gt; &quot;UnsuperClassification/match_result&quot;;
  &quot;UnsuperClassification/image&quot; -&gt; &quot;UnsuperClassification/image_mean_conf&quot;;
  &quot;UnsuperClassification/image&quot; -&gt; &quot;UnsuperClassification/infer&quot;;
  &quot;UnsuperClassification/image&quot; -&gt; &quot;UnsuperClassification/label_oper&quot;;
  &quot;UnsuperClassification/image&quot; -&gt; &quot;UnsuperClassification/trainer&quot;;
  &quot;UnsuperClassification/image_mean&quot; -&gt; &quot;UnsuperClassification/trainer&quot;;
  &quot;UnsuperClassification/image_mean_conf&quot; -&gt; &quot;UnsuperClassification/image_mean&quot;;
  &quot;UnsuperClassification/infer&quot; -&gt; &quot;UnsuperClassification/feature_map&quot;;
  &quot;UnsuperClassification/infer&quot; -&gt; &quot;UnsuperClassification/pred&quot;;
  &quot;UnsuperClassification/infer.args&quot; -&gt; &quot;UnsuperClassification/infer&quot;;
  &quot;UnsuperClassification/infer.conf&quot; -&gt; &quot;UnsuperClassification/infer.args&quot;;
  &quot;UnsuperClassification/label_oper&quot; -&gt; &quot;UnsuperClassification/mask&quot;;
  &quot;UnsuperClassification/label_oper&quot; -&gt; &quot;UnsuperClassification/tagged_polygons&quot;;
  &quot;UnsuperClassification/label_oper&quot; -&gt; &quot;UnsuperClassification/truth&quot;;
  &quot;UnsuperClassification/label_oper.args&quot; -&gt; &quot;UnsuperClassification/label_oper&quot;;
  &quot;UnsuperClassification/label_oper.conf&quot; -&gt; &quot;UnsuperClassification/label_oper.args&quot;;
  &quot;UnsuperClassification/mask&quot; -&gt; &quot;UnsuperClassification/trainer&quot;;
  &quot;UnsuperClassification/model&quot; -&gt; &quot;UnsuperClassification/infer&quot;;
  &quot;UnsuperClassification/pred&quot; -&gt; &quot;UnsuperClassification/comparator&quot;;
  &quot;UnsuperClassification/pred&quot; -&gt; &quot;UnsuperClassification/statistician&quot;;
  &quot;UnsuperClassification/statistician&quot; -&gt; &quot;UnsuperClassification/statistics&quot;;
  &quot;UnsuperClassification/tagged_polygons&quot; -&gt; &quot;UnsuperClassification/view_tagger&quot;;
  &quot;UnsuperClassification/tagged_views&quot; -&gt; &quot;UnsuperClassification/comparator&quot;;
  &quot;UnsuperClassification/tagged_views&quot; -&gt; &quot;UnsuperClassification/image_mean_conf&quot;;
  &quot;UnsuperClassification/tagged_views&quot; -&gt; &quot;UnsuperClassification/statistician&quot;;
  &quot;UnsuperClassification/tagged_views&quot; -&gt; &quot;UnsuperClassification/trainer&quot;;
  &quot;UnsuperClassification/trainer&quot; -&gt; &quot;UnsuperClassification/model&quot;;
  &quot;UnsuperClassification/trainer&quot; -&gt; &quot;UnsuperClassification/training_log&quot;;
  &quot;UnsuperClassification/trainer.args&quot; -&gt; &quot;UnsuperClassification/trainer&quot;;
  &quot;UnsuperClassification/trainer.conf&quot; -&gt; &quot;UnsuperClassification/trainer.args&quot;;
  &quot;UnsuperClassification/truth&quot; -&gt; &quot;UnsuperClassification/comparator&quot;;
  &quot;UnsuperClassification/truth&quot; -&gt; &quot;UnsuperClassification/statistician&quot;;
  &quot;UnsuperClassification/truth&quot; -&gt; &quot;UnsuperClassification/trainer&quot;;
  &quot;UnsuperClassification/view_tagger&quot; -&gt; &quot;UnsuperClassification/tagged_views&quot;;
  &quot;UnsuperClassification/views&quot; -&gt; &quot;UnsuperClassification/infer&quot;;
  &quot;UnsuperClassification/views&quot; -&gt; &quot;UnsuperClassification/view_tagger&quot;

}</p></object></div>
</section>
<section id="assemblyverification-tool">
<h2>AssemblyVerification Tool<a class="headerlink" href="#assemblyverification-tool" title="Link to this heading">#</a></h2>
<p>AssemblyVerification Tool.</p>
<div class="graphviz"><object data="../_images/graphviz-1212c654606aa1f5440fc6cc1d8edda18fd9fa12.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: AssemblyVerification&quot; {
  label=&quot;OnlyTool: AssemblyVerification&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;AssemblyVerification/comparator&quot;;
  &quot;AssemblyVerification/filter&quot;;
  &quot;AssemblyVerification/infer&quot;;
  &quot;AssemblyVerification/label_oper&quot;;
  &quot;AssemblyVerification/prediction_objects_matcher&quot;;
  &quot;AssemblyVerification/truth_objects_matcher&quot;;
  &quot;AssemblyVerification/view_tagger&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;AssemblyVerification/base_color_conf&quot;;
  &quot;AssemblyVerification/batch_size_conf&quot;;
  &quot;AssemblyVerification/filter.conf&quot;;
  &quot;AssemblyVerification/image_mean_conf&quot;;
  &quot;AssemblyVerification/label_classes.conf&quot;;
  &quot;AssemblyVerification/label_oper.conf&quot;;
  &quot;AssemblyVerification/objects_statistician&quot;;
  &quot;AssemblyVerification/statistician&quot;;
  &quot;AssemblyVerification/templates_conf&quot;;
  &quot;AssemblyVerification/trainer&quot;;
  &quot;AssemblyVerification/trainer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;AssemblyVerification/feature_map&quot;;
  &quot;AssemblyVerification/mask&quot;;
  &quot;AssemblyVerification/match_result&quot;;
  &quot;AssemblyVerification/tagged_polygons&quot;;
  &quot;AssemblyVerification/tagged_views&quot;;
  &quot;AssemblyVerification/truth&quot;;
  &quot;AssemblyVerification/truth.objects&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;AssemblyVerification/image&quot;;
  &quot;AssemblyVerification/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;AssemblyVerification/pred.keypoints&quot;;
  &quot;AssemblyVerification/pred.objects&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;AssemblyVerification/base_color&quot;;
  &quot;AssemblyVerification/batch_size&quot;;
  &quot;AssemblyVerification/filter.args&quot;;
  &quot;AssemblyVerification/image_mean&quot;;
  &quot;AssemblyVerification/label_oper.args&quot;;
  &quot;AssemblyVerification/model&quot;;
  &quot;AssemblyVerification/objects_statistics&quot;;
  &quot;AssemblyVerification/statistics&quot;;
  &quot;AssemblyVerification/templates&quot;;
  &quot;AssemblyVerification/trainer.args&quot;;
  &quot;AssemblyVerification/training_log&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style
  &quot;AssemblyVerification/classes&quot;


  subgraph &quot;cluster_AssemblyVerification&quot; {
    label=&quot;AssemblyVerification&quot;;
    &quot;AssemblyVerification/base_color&quot; [label=&quot;id: AssemblyVerification/base_color\ltype: visionflow::param::BaseColor\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;AssemblyVerification/base_color_conf&quot; [label=&quot;id: AssemblyVerification/base_color_conf\ltype: visionflow::confs::BaseColorConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config input images' \lbase color.\l&quot;];
    &quot;AssemblyVerification/batch_size&quot; [label=&quot;id: AssemblyVerification/batch_size\ltype: visionflow::param::InferenceBatchSize\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Inference BatchSize and Inference \lMode. Currently only contains \lbatch size. It may need to be \lrefactored in the future.\l&quot;];
    &quot;AssemblyVerification/batch_size_conf&quot; [label=&quot;id: AssemblyVerification/batch_size_conf\ltype: visionflow::confs::InferenceBatchSizeConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set inference \lbatch size.\l&quot;];
    &quot;AssemblyVerification/classes&quot; [label=&quot;id: AssemblyVerification/classes\ltype: visionflow::param::LabelClasses\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage label classes.\l&quot;];
    &quot;AssemblyVerification/comparator&quot; [label=&quot;id: AssemblyVerification/comparator\ltype: visionflow::opers::RegionsMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to compare the predicted \lregions with the ground truth \lto get the category (in [TP, FP, \lTN, FN]) of each region.\l&quot;];
    &quot;AssemblyVerification/feature_map&quot; [label=&quot;id: AssemblyVerification/feature_map\ltype: visionflow::props::FeatureMap\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure used to store \lfeature maps detected by each \lalgorithm module.\l&quot;];
    &quot;AssemblyVerification/filter&quot; [label=&quot;id: AssemblyVerification/filter\ltype: visionflow::opers::AssemblyVerificationFilter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: AssemblyVerification feature map \lfilter.\l&quot;];
    &quot;AssemblyVerification/filter.args&quot; [label=&quot;id: AssemblyVerification/filter.args\ltype: visionflow::param::AssemblyVerificationFilterParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;AssemblyVerification/filter.conf&quot; [label=&quot;id: AssemblyVerification/filter.conf\ltype: visionflow::confs::AssemblyVerificationFeatureFilterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to config AssemblyVerification \lnms and filter parameters.\l&quot;];
    &quot;AssemblyVerification/image_mean&quot; [label=&quot;id: AssemblyVerification/image_mean\ltype: visionflow::param::ImageMean\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Image mean parameters\l&quot;];
    &quot;AssemblyVerification/image_mean_conf&quot; [label=&quot;id: AssemblyVerification/image_mean_conf\ltype: visionflow::confs::ImageMeanConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: ImageMeanConf Configurator class \lto compute the image mean values \lin the views.\l&quot;];
    &quot;AssemblyVerification/infer&quot; [label=&quot;id: AssemblyVerification/infer\ltype: visionflow::opers::AssemblyVerificationInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: AssemblyVerification Caffe inference \lengine.\l&quot;];
    &quot;AssemblyVerification/label_classes.conf&quot; [label=&quot;id: AssemblyVerification/label_classes.conf\ltype: visionflow::confs::LabelClassesConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \llabel classes parameter.\l&quot;];
    &quot;AssemblyVerification/label_oper&quot; [label=&quot;id: AssemblyVerification/label_oper\ltype: visionflow::opers::AssemblyVerificationLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for AssemblyVerification \ltool.\l&quot;];
    &quot;AssemblyVerification/label_oper.args&quot; [label=&quot;id: AssemblyVerification/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;AssemblyVerification/label_oper.conf&quot; [label=&quot;id: AssemblyVerification/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;AssemblyVerification/mask&quot; [label=&quot;id: AssemblyVerification/mask\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;AssemblyVerification/match_result&quot; [label=&quot;id: AssemblyVerification/match_result\ltype: visionflow::props::RegionMatchResultList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure to store list \lof RegionMatchResult.\l&quot;];
    &quot;AssemblyVerification/model&quot; [label=&quot;id: AssemblyVerification/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;AssemblyVerification/objects_statistician&quot; [label=&quot;id: AssemblyVerification/objects_statistician\ltype: visionflow::confs::RegionMatchResultCounterV3\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count region match \lresults after filtered the truths \land predictions whose center overlaps \lwithin no-train regions.\l&quot;];
    &quot;AssemblyVerification/objects_statistics&quot; [label=&quot;id: AssemblyVerification/objects_statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;AssemblyVerification/pred.keypoints&quot; [label=&quot;id: AssemblyVerification/pred.keypoints\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;AssemblyVerification/pred.objects&quot; [label=&quot;id: AssemblyVerification/pred.objects\ltype: visionflow::props::PolygonWithStringMapRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;AssemblyVerification/prediction_objects_matcher&quot; [label=&quot;id: AssemblyVerification/prediction_objects_matcher\ltype: visionflow::opers::AssemblyVerificationObjectMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: AssemblyVerification object matcher.\l&quot;];
    &quot;AssemblyVerification/statistician&quot; [label=&quot;id: AssemblyVerification/statistician\ltype: visionflow::confs::RegionMatchResultCounter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count region match \lresults.\l&quot;];
    &quot;AssemblyVerification/statistics&quot; [label=&quot;id: AssemblyVerification/statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;AssemblyVerification/tagged_polygons&quot; [label=&quot;id: AssemblyVerification/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;AssemblyVerification/tagged_views&quot; [label=&quot;id: AssemblyVerification/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;AssemblyVerification/templates&quot; [label=&quot;id: AssemblyVerification/templates\ltype: visionflow::param::AssemblyVerificationTemplates\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;AssemblyVerification/templates_conf&quot; [label=&quot;id: AssemblyVerification/templates_conf\ltype: visionflow::confs::AssemblyVerificationTemplateConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to config AssemblyVerification \lmatch templates.\l&quot;];
    &quot;AssemblyVerification/trainer&quot; [label=&quot;id: AssemblyVerification/trainer\ltype: visionflow::confs::AssemblyVerificationTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: AssemblyVerification model trainer.\l&quot;];
    &quot;AssemblyVerification/trainer.args&quot; [label=&quot;id: AssemblyVerification/trainer.args\ltype: visionflow::param::AssemblyVerificationTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;AssemblyVerification/trainer.conf&quot; [label=&quot;id: AssemblyVerification/trainer.conf\ltype: visionflow::confs::AssemblyVerificationTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set AssemblyVerification \ltrainer options.\l&quot;];
    &quot;AssemblyVerification/training_log&quot; [label=&quot;id: AssemblyVerification/training_log\ltype: visionflow::param::TrainingLog\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;AssemblyVerification/truth&quot; [label=&quot;id: AssemblyVerification/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;AssemblyVerification/truth.objects&quot; [label=&quot;id: AssemblyVerification/truth.objects\ltype: visionflow::props::PolygonWithStringMapRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;AssemblyVerification/truth_objects_matcher&quot; [label=&quot;id: AssemblyVerification/truth_objects_matcher\ltype: visionflow::opers::AssemblyVerificationObjectMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: AssemblyVerification object matcher.\l&quot;];
    &quot;AssemblyVerification/view_tagger&quot; [label=&quot;id: AssemblyVerification/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;]
  }

  &quot;AssemblyVerification/base_color&quot; -&gt; &quot;AssemblyVerification/image_mean_conf&quot;;
  &quot;AssemblyVerification/base_color&quot; -&gt; &quot;AssemblyVerification/trainer&quot;;
  &quot;AssemblyVerification/base_color_conf&quot; -&gt; &quot;AssemblyVerification/base_color&quot;;
  &quot;AssemblyVerification/batch_size&quot; -&gt; &quot;AssemblyVerification/infer&quot;;
  &quot;AssemblyVerification/batch_size_conf&quot; -&gt; &quot;AssemblyVerification/batch_size&quot;;
  &quot;AssemblyVerification/classes&quot; -&gt; &quot;AssemblyVerification/label_oper&quot;;
  &quot;AssemblyVerification/classes&quot; -&gt; &quot;AssemblyVerification/trainer&quot;;
  &quot;AssemblyVerification/comparator&quot; -&gt; &quot;AssemblyVerification/match_result&quot;;
  &quot;AssemblyVerification/feature_map&quot; -&gt; &quot;AssemblyVerification/filter&quot;;
  &quot;AssemblyVerification/filter&quot; -&gt; &quot;AssemblyVerification/pred.keypoints&quot;;
  &quot;AssemblyVerification/filter.args&quot; -&gt; &quot;AssemblyVerification/filter&quot;;
  &quot;AssemblyVerification/filter.conf&quot; -&gt; &quot;AssemblyVerification/filter.args&quot;;
  &quot;AssemblyVerification/image&quot; -&gt; &quot;AssemblyVerification/image_mean_conf&quot;;
  &quot;AssemblyVerification/image&quot; -&gt; &quot;AssemblyVerification/infer&quot;;
  &quot;AssemblyVerification/image&quot; -&gt; &quot;AssemblyVerification/label_oper&quot;;
  &quot;AssemblyVerification/image&quot; -&gt; &quot;AssemblyVerification/trainer&quot;;
  &quot;AssemblyVerification/image_mean&quot; -&gt; &quot;AssemblyVerification/trainer&quot;;
  &quot;AssemblyVerification/image_mean_conf&quot; -&gt; &quot;AssemblyVerification/image_mean&quot;;
  &quot;AssemblyVerification/infer&quot; -&gt; &quot;AssemblyVerification/feature_map&quot;;
  &quot;AssemblyVerification/label_classes.conf&quot; -&gt; &quot;AssemblyVerification/classes&quot;;
  &quot;AssemblyVerification/label_oper&quot; -&gt; &quot;AssemblyVerification/mask&quot;;
  &quot;AssemblyVerification/label_oper&quot; -&gt; &quot;AssemblyVerification/tagged_polygons&quot;;
  &quot;AssemblyVerification/label_oper&quot; -&gt; &quot;AssemblyVerification/truth&quot;;
  &quot;AssemblyVerification/label_oper.args&quot; -&gt; &quot;AssemblyVerification/label_oper&quot;;
  &quot;AssemblyVerification/label_oper.conf&quot; -&gt; &quot;AssemblyVerification/label_oper.args&quot;;
  &quot;AssemblyVerification/mask&quot; -&gt; &quot;AssemblyVerification/objects_statistician&quot;;
  &quot;AssemblyVerification/mask&quot; -&gt; &quot;AssemblyVerification/trainer&quot;;
  &quot;AssemblyVerification/model&quot; -&gt; &quot;AssemblyVerification/filter&quot;;
  &quot;AssemblyVerification/model&quot; -&gt; &quot;AssemblyVerification/infer&quot;;
  &quot;AssemblyVerification/objects_statistician&quot; -&gt; &quot;AssemblyVerification/objects_statistics&quot;;
  &quot;AssemblyVerification/pred.keypoints&quot; -&gt; &quot;AssemblyVerification/comparator&quot;;
  &quot;AssemblyVerification/pred.keypoints&quot; -&gt; &quot;AssemblyVerification/prediction_objects_matcher&quot;;
  &quot;AssemblyVerification/pred.keypoints&quot; -&gt; &quot;AssemblyVerification/statistician&quot;;
  &quot;AssemblyVerification/pred.objects&quot; -&gt; &quot;AssemblyVerification/objects_statistician&quot;;
  &quot;AssemblyVerification/prediction_objects_matcher&quot; -&gt; &quot;AssemblyVerification/pred.objects&quot;;
  &quot;AssemblyVerification/statistician&quot; -&gt; &quot;AssemblyVerification/statistics&quot;;
  &quot;AssemblyVerification/tagged_polygons&quot; -&gt; &quot;AssemblyVerification/view_tagger&quot;;
  &quot;AssemblyVerification/tagged_views&quot; -&gt; &quot;AssemblyVerification/comparator&quot;;
  &quot;AssemblyVerification/tagged_views&quot; -&gt; &quot;AssemblyVerification/image_mean_conf&quot;;
  &quot;AssemblyVerification/tagged_views&quot; -&gt; &quot;AssemblyVerification/objects_statistician&quot;;
  &quot;AssemblyVerification/tagged_views&quot; -&gt; &quot;AssemblyVerification/statistician&quot;;
  &quot;AssemblyVerification/tagged_views&quot; -&gt; &quot;AssemblyVerification/trainer&quot;;
  &quot;AssemblyVerification/tagged_views&quot; -&gt; &quot;AssemblyVerification/truth_objects_matcher&quot;;
  &quot;AssemblyVerification/templates&quot; -&gt; &quot;AssemblyVerification/prediction_objects_matcher&quot;;
  &quot;AssemblyVerification/templates&quot; -&gt; &quot;AssemblyVerification/truth_objects_matcher&quot;;
  &quot;AssemblyVerification/templates_conf&quot; -&gt; &quot;AssemblyVerification/templates&quot;;
  &quot;AssemblyVerification/trainer&quot; -&gt; &quot;AssemblyVerification/model&quot;;
  &quot;AssemblyVerification/trainer&quot; -&gt; &quot;AssemblyVerification/training_log&quot;;
  &quot;AssemblyVerification/trainer.args&quot; -&gt; &quot;AssemblyVerification/trainer&quot;;
  &quot;AssemblyVerification/trainer.conf&quot; -&gt; &quot;AssemblyVerification/trainer.args&quot;;
  &quot;AssemblyVerification/truth&quot; -&gt; &quot;AssemblyVerification/comparator&quot;;
  &quot;AssemblyVerification/truth&quot; -&gt; &quot;AssemblyVerification/statistician&quot;;
  &quot;AssemblyVerification/truth&quot; -&gt; &quot;AssemblyVerification/trainer&quot;;
  &quot;AssemblyVerification/truth&quot; -&gt; &quot;AssemblyVerification/truth_objects_matcher&quot;;
  &quot;AssemblyVerification/truth.objects&quot; -&gt; &quot;AssemblyVerification/objects_statistician&quot;;
  &quot;AssemblyVerification/truth_objects_matcher&quot; -&gt; &quot;AssemblyVerification/truth.objects&quot;;
  &quot;AssemblyVerification/view_tagger&quot; -&gt; &quot;AssemblyVerification/tagged_views&quot;;
  &quot;AssemblyVerification/views&quot; -&gt; &quot;AssemblyVerification/filter&quot;;
  &quot;AssemblyVerification/views&quot; -&gt; &quot;AssemblyVerification/infer&quot;;
  &quot;AssemblyVerification/views&quot; -&gt; &quot;AssemblyVerification/prediction_objects_matcher&quot;;
  &quot;AssemblyVerification/views&quot; -&gt; &quot;AssemblyVerification/view_tagger&quot;

}</p></object></div>
</section>
<section id="location-tool">
<h2>Location Tool<a class="headerlink" href="#location-tool" title="Link to this heading">#</a></h2>
<p>Location Tool.</p>
<div class="graphviz"><object data="../_images/graphviz-d481116984ac3c8f226040e7023fb2b3e6d6d9c7.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: Location&quot; {
  label=&quot;OnlyTool: Location&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;Location/comparator&quot;;
  &quot;Location/filter&quot;;
  &quot;Location/infer&quot;;
  &quot;Location/label_oper&quot;;
  &quot;Location/prediction_objects_matcher&quot;;
  &quot;Location/truth_objects_matcher&quot;;
  &quot;Location/view_tagger&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;Location/base_color_conf&quot;;
  &quot;Location/batch_size_conf&quot;;
  &quot;Location/filter.conf&quot;;
  &quot;Location/image_mean_conf&quot;;
  &quot;Location/label_classes.conf&quot;;
  &quot;Location/label_oper.conf&quot;;
  &quot;Location/objects_statistician&quot;;
  &quot;Location/statistician&quot;;
  &quot;Location/templates_conf&quot;;
  &quot;Location/trainer&quot;;
  &quot;Location/trainer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;Location/feature_map&quot;;
  &quot;Location/mask&quot;;
  &quot;Location/match_result&quot;;
  &quot;Location/tagged_polygons&quot;;
  &quot;Location/tagged_views&quot;;
  &quot;Location/truth&quot;;
  &quot;Location/truth.objects&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;Location/image&quot;;
  &quot;Location/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;Location/pred.keypoints&quot;;
  &quot;Location/pred.objects&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;Location/base_color&quot;;
  &quot;Location/batch_size&quot;;
  &quot;Location/filter.args&quot;;
  &quot;Location/image_mean&quot;;
  &quot;Location/label_oper.args&quot;;
  &quot;Location/model&quot;;
  &quot;Location/objects_statistics&quot;;
  &quot;Location/statistics&quot;;
  &quot;Location/templates&quot;;
  &quot;Location/trainer.args&quot;;
  &quot;Location/training_log&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style
  &quot;Location/classes&quot;


  subgraph &quot;cluster_Location&quot; {
    label=&quot;Location&quot;;
    &quot;Location/base_color&quot; [label=&quot;id: Location/base_color\ltype: visionflow::param::BaseColor\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Location/base_color_conf&quot; [label=&quot;id: Location/base_color_conf\ltype: visionflow::confs::BaseColorConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config input images' \lbase color.\l&quot;];
    &quot;Location/batch_size&quot; [label=&quot;id: Location/batch_size\ltype: visionflow::param::InferenceBatchSize\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Inference BatchSize and Inference \lMode. Currently only contains \lbatch size. It may need to be \lrefactored in the future.\l&quot;];
    &quot;Location/batch_size_conf&quot; [label=&quot;id: Location/batch_size_conf\ltype: visionflow::confs::InferenceBatchSizeConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set inference \lbatch size.\l&quot;];
    &quot;Location/classes&quot; [label=&quot;id: Location/classes\ltype: visionflow::param::LabelClasses\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage label classes.\l&quot;];
    &quot;Location/comparator&quot; [label=&quot;id: Location/comparator\ltype: visionflow::opers::RegionsMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to compare the predicted \lregions with the ground truth \lto get the category (in [TP, FP, \lTN, FN]) of each region.\l&quot;];
    &quot;Location/feature_map&quot; [label=&quot;id: Location/feature_map\ltype: visionflow::props::FeatureMap\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure used to store \lfeature maps detected by each \lalgorithm module.\l&quot;];
    &quot;Location/filter&quot; [label=&quot;id: Location/filter\ltype: visionflow::opers::LocationFilter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Location feature map filter.\l&quot;];
    &quot;Location/filter.args&quot; [label=&quot;id: Location/filter.args\ltype: visionflow::param::LocationFilterParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Location/filter.conf&quot; [label=&quot;id: Location/filter.conf\ltype: visionflow::confs::LocationFeatureFilterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to config Location \lnms and filter parameters.\l&quot;];
    &quot;Location/image_mean&quot; [label=&quot;id: Location/image_mean\ltype: visionflow::param::ImageMean\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Image mean parameters\l&quot;];
    &quot;Location/image_mean_conf&quot; [label=&quot;id: Location/image_mean_conf\ltype: visionflow::confs::ImageMeanConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: ImageMeanConf Configurator class \lto compute the image mean values \lin the views.\l&quot;];
    &quot;Location/infer&quot; [label=&quot;id: Location/infer\ltype: visionflow::opers::LocationInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Location Caffe inference engine.\l&quot;];
    &quot;Location/label_classes.conf&quot; [label=&quot;id: Location/label_classes.conf\ltype: visionflow::confs::LabelClassesConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \llabel classes parameter.\l&quot;];
    &quot;Location/label_oper&quot; [label=&quot;id: Location/label_oper\ltype: visionflow::opers::LocationLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for Location \ltool.\l&quot;];
    &quot;Location/label_oper.args&quot; [label=&quot;id: Location/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;Location/label_oper.conf&quot; [label=&quot;id: Location/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;Location/mask&quot; [label=&quot;id: Location/mask\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Location/match_result&quot; [label=&quot;id: Location/match_result\ltype: visionflow::props::RegionMatchResultList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure to store list \lof RegionMatchResult.\l&quot;];
    &quot;Location/model&quot; [label=&quot;id: Location/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;Location/objects_statistician&quot; [label=&quot;id: Location/objects_statistician\ltype: visionflow::confs::RegionMatchResultCounter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count region match \lresults.\l&quot;];
    &quot;Location/objects_statistics&quot; [label=&quot;id: Location/objects_statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;Location/pred.keypoints&quot; [label=&quot;id: Location/pred.keypoints\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Location/pred.objects&quot; [label=&quot;id: Location/pred.objects\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Location/prediction_objects_matcher&quot; [label=&quot;id: Location/prediction_objects_matcher\ltype: visionflow::opers::LocationObjectMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Location object matcher.\l&quot;];
    &quot;Location/statistician&quot; [label=&quot;id: Location/statistician\ltype: visionflow::confs::LocationRegionMatchResultCounter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count location \lregion match results.\l&quot;];
    &quot;Location/statistics&quot; [label=&quot;id: Location/statistics\ltype: visionflow::param::LocationModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;Location/tagged_polygons&quot; [label=&quot;id: Location/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;Location/tagged_views&quot; [label=&quot;id: Location/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;Location/templates&quot; [label=&quot;id: Location/templates\ltype: visionflow::param::LocationTemplates\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Location/templates_conf&quot; [label=&quot;id: Location/templates_conf\ltype: visionflow::confs::LocationTemplateConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to config Location \lmatch templates.\l&quot;];
    &quot;Location/trainer&quot; [label=&quot;id: Location/trainer\ltype: visionflow::confs::LocationTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Location model trainer.\l&quot;];
    &quot;Location/trainer.args&quot; [label=&quot;id: Location/trainer.args\ltype: visionflow::param::LocationTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Location/trainer.conf&quot; [label=&quot;id: Location/trainer.conf\ltype: visionflow::confs::LocationTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set Location trainer \loptions.\l&quot;];
    &quot;Location/training_log&quot; [label=&quot;id: Location/training_log\ltype: visionflow::param::TrainingLog\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Location/truth&quot; [label=&quot;id: Location/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Location/truth.objects&quot; [label=&quot;id: Location/truth.objects\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Location/truth_objects_matcher&quot; [label=&quot;id: Location/truth_objects_matcher\ltype: visionflow::opers::LocationObjectMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Location object matcher.\l&quot;];
    &quot;Location/view_tagger&quot; [label=&quot;id: Location/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;]
  }

  &quot;Location/base_color&quot; -&gt; &quot;Location/image_mean_conf&quot;;
  &quot;Location/base_color&quot; -&gt; &quot;Location/trainer&quot;;
  &quot;Location/base_color_conf&quot; -&gt; &quot;Location/base_color&quot;;
  &quot;Location/batch_size&quot; -&gt; &quot;Location/infer&quot;;
  &quot;Location/batch_size_conf&quot; -&gt; &quot;Location/batch_size&quot;;
  &quot;Location/classes&quot; -&gt; &quot;Location/label_oper&quot;;
  &quot;Location/classes&quot; -&gt; &quot;Location/trainer&quot;;
  &quot;Location/comparator&quot; -&gt; &quot;Location/match_result&quot;;
  &quot;Location/feature_map&quot; -&gt; &quot;Location/filter&quot;;
  &quot;Location/filter&quot; -&gt; &quot;Location/pred.keypoints&quot;;
  &quot;Location/filter.args&quot; -&gt; &quot;Location/filter&quot;;
  &quot;Location/filter.conf&quot; -&gt; &quot;Location/filter.args&quot;;
  &quot;Location/image&quot; -&gt; &quot;Location/image_mean_conf&quot;;
  &quot;Location/image&quot; -&gt; &quot;Location/infer&quot;;
  &quot;Location/image&quot; -&gt; &quot;Location/label_oper&quot;;
  &quot;Location/image&quot; -&gt; &quot;Location/trainer&quot;;
  &quot;Location/image_mean&quot; -&gt; &quot;Location/trainer&quot;;
  &quot;Location/image_mean_conf&quot; -&gt; &quot;Location/image_mean&quot;;
  &quot;Location/infer&quot; -&gt; &quot;Location/feature_map&quot;;
  &quot;Location/label_classes.conf&quot; -&gt; &quot;Location/classes&quot;;
  &quot;Location/label_oper&quot; -&gt; &quot;Location/mask&quot;;
  &quot;Location/label_oper&quot; -&gt; &quot;Location/tagged_polygons&quot;;
  &quot;Location/label_oper&quot; -&gt; &quot;Location/truth&quot;;
  &quot;Location/label_oper.args&quot; -&gt; &quot;Location/label_oper&quot;;
  &quot;Location/label_oper.conf&quot; -&gt; &quot;Location/label_oper.args&quot;;
  &quot;Location/mask&quot; -&gt; &quot;Location/statistician&quot;;
  &quot;Location/mask&quot; -&gt; &quot;Location/trainer&quot;;
  &quot;Location/model&quot; -&gt; &quot;Location/filter&quot;;
  &quot;Location/model&quot; -&gt; &quot;Location/infer&quot;;
  &quot;Location/objects_statistician&quot; -&gt; &quot;Location/objects_statistics&quot;;
  &quot;Location/pred.keypoints&quot; -&gt; &quot;Location/comparator&quot;;
  &quot;Location/pred.keypoints&quot; -&gt; &quot;Location/prediction_objects_matcher&quot;;
  &quot;Location/pred.keypoints&quot; -&gt; &quot;Location/statistician&quot;;
  &quot;Location/pred.objects&quot; -&gt; &quot;Location/objects_statistician&quot;;
  &quot;Location/prediction_objects_matcher&quot; -&gt; &quot;Location/pred.objects&quot;;
  &quot;Location/statistician&quot; -&gt; &quot;Location/statistics&quot;;
  &quot;Location/tagged_polygons&quot; -&gt; &quot;Location/view_tagger&quot;;
  &quot;Location/tagged_views&quot; -&gt; &quot;Location/comparator&quot;;
  &quot;Location/tagged_views&quot; -&gt; &quot;Location/image_mean_conf&quot;;
  &quot;Location/tagged_views&quot; -&gt; &quot;Location/objects_statistician&quot;;
  &quot;Location/tagged_views&quot; -&gt; &quot;Location/statistician&quot;;
  &quot;Location/tagged_views&quot; -&gt; &quot;Location/trainer&quot;;
  &quot;Location/tagged_views&quot; -&gt; &quot;Location/truth_objects_matcher&quot;;
  &quot;Location/templates&quot; -&gt; &quot;Location/prediction_objects_matcher&quot;;
  &quot;Location/templates&quot; -&gt; &quot;Location/truth_objects_matcher&quot;;
  &quot;Location/templates_conf&quot; -&gt; &quot;Location/templates&quot;;
  &quot;Location/trainer&quot; -&gt; &quot;Location/model&quot;;
  &quot;Location/trainer&quot; -&gt; &quot;Location/training_log&quot;;
  &quot;Location/trainer.args&quot; -&gt; &quot;Location/trainer&quot;;
  &quot;Location/trainer.conf&quot; -&gt; &quot;Location/trainer.args&quot;;
  &quot;Location/truth&quot; -&gt; &quot;Location/comparator&quot;;
  &quot;Location/truth&quot; -&gt; &quot;Location/statistician&quot;;
  &quot;Location/truth&quot; -&gt; &quot;Location/trainer&quot;;
  &quot;Location/truth&quot; -&gt; &quot;Location/truth_objects_matcher&quot;;
  &quot;Location/truth.objects&quot; -&gt; &quot;Location/objects_statistician&quot;;
  &quot;Location/truth_objects_matcher&quot; -&gt; &quot;Location/truth.objects&quot;;
  &quot;Location/view_tagger&quot; -&gt; &quot;Location/tagged_views&quot;;
  &quot;Location/views&quot; -&gt; &quot;Location/filter&quot;;
  &quot;Location/views&quot; -&gt; &quot;Location/infer&quot;;
  &quot;Location/views&quot; -&gt; &quot;Location/prediction_objects_matcher&quot;;
  &quot;Location/views&quot; -&gt; &quot;Location/view_tagger&quot;

}</p></object></div>
</section>
<section id="classification-tool">
<h2>Classification Tool<a class="headerlink" href="#classification-tool" title="Link to this heading">#</a></h2>
<p>Classification Tool</p>
<div class="graphviz"><object data="../_images/graphviz-98ea5028622e37a88dbd80a50c5fa060dcdf6ecc.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: Classification&quot; {
  label=&quot;OnlyTool: Classification&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;Classification/comparator&quot;;
  &quot;Classification/infer&quot;;
  &quot;Classification/label_oper&quot;;
  &quot;Classification/view_tagger&quot;;
  &quot;Classification/visualizer&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;Classification/base_color_conf&quot;;
  &quot;Classification/batch_size_conf&quot;;
  &quot;Classification/image_mean_conf&quot;;
  &quot;Classification/label_classes.conf&quot;;
  &quot;Classification/label_oper.conf&quot;;
  &quot;Classification/sample_recommend&quot;;
  &quot;Classification/sample_recommend.conf&quot;;
  &quot;Classification/statistician&quot;;
  &quot;Classification/trainer&quot;;
  &quot;Classification/trainer.conf&quot;;
  &quot;Classification/training_set_recommend&quot;;
  &quot;Classification/training_set_recommend.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;Classification/heatmap&quot;;
  &quot;Classification/mask&quot;;
  &quot;Classification/match_result&quot;;
  &quot;Classification/tagged_polygons&quot;;
  &quot;Classification/tagged_views&quot;;
  &quot;Classification/truth&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;Classification/image&quot;;
  &quot;Classification/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;Classification/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;Classification/base_color&quot;;
  &quot;Classification/batch_size&quot;;
  &quot;Classification/image_mean&quot;;
  &quot;Classification/label_oper.args&quot;;
  &quot;Classification/model&quot;;
  &quot;Classification/recommend_sample_set&quot;;
  &quot;Classification/recommend_training_set&quot;;
  &quot;Classification/sample_recommend.args&quot;;
  &quot;Classification/statistics&quot;;
  &quot;Classification/trainer.args&quot;;
  &quot;Classification/training_log&quot;;
  &quot;Classification/training_set_recommend.args&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style
  &quot;Classification/classes&quot;


  subgraph &quot;cluster_Classification&quot; {
    label=&quot;Classification&quot;;
    &quot;Classification/base_color&quot; [label=&quot;id: Classification/base_color\ltype: visionflow::param::BaseColor\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Classification/base_color_conf&quot; [label=&quot;id: Classification/base_color_conf\ltype: visionflow::confs::BaseColorConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config input images' \lbase color.\l&quot;];
    &quot;Classification/batch_size&quot; [label=&quot;id: Classification/batch_size\ltype: visionflow::param::InferenceBatchSize\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Inference BatchSize and Inference \lMode. Currently only contains \lbatch size. It may need to be \lrefactored in the future.\l&quot;];
    &quot;Classification/batch_size_conf&quot; [label=&quot;id: Classification/batch_size_conf\ltype: visionflow::confs::InferenceBatchSizeConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set inference \lbatch size.\l&quot;];
    &quot;Classification/classes&quot; [label=&quot;id: Classification/classes\ltype: visionflow::param::LabelClasses\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage label classes.\l&quot;];
    &quot;Classification/comparator&quot; [label=&quot;id: Classification/comparator\ltype: visionflow::opers::RegionsMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to compare the predicted \lregions with the ground truth \lto get the category (in [TP, FP, \lTN, FN]) of each region.\l&quot;];
    &quot;Classification/heatmap&quot; [label=&quot;id: Classification/heatmap\ltype: visionflow::props::FeatureMap\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure used to store \lfeature maps detected by each \lalgorithm module.\l&quot;];
    &quot;Classification/image_mean&quot; [label=&quot;id: Classification/image_mean\ltype: visionflow::param::ImageMean\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Image mean parameters\l&quot;];
    &quot;Classification/image_mean_conf&quot; [label=&quot;id: Classification/image_mean_conf\ltype: visionflow::confs::ImageMeanConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: ImageMeanConf Configurator class \lto compute the image mean values \lin the views.\l&quot;];
    &quot;Classification/infer&quot; [label=&quot;id: Classification/infer\ltype: visionflow::opers::ClassificationInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Classification inference engine.\l&quot;];
    &quot;Classification/label_classes.conf&quot; [label=&quot;id: Classification/label_classes.conf\ltype: visionflow::confs::LabelClassesConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \llabel classes parameter.\l&quot;];
    &quot;Classification/label_oper&quot; [label=&quot;id: Classification/label_oper\ltype: visionflow::opers::ClassificationLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for Classification \ltool.\l&quot;];
    &quot;Classification/label_oper.args&quot; [label=&quot;id: Classification/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;Classification/label_oper.conf&quot; [label=&quot;id: Classification/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;Classification/mask&quot; [label=&quot;id: Classification/mask\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Classification/match_result&quot; [label=&quot;id: Classification/match_result\ltype: visionflow::props::RegionMatchResultList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure to store list \lof RegionMatchResult.\l&quot;];
    &quot;Classification/model&quot; [label=&quot;id: Classification/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;Classification/pred&quot; [label=&quot;id: Classification/pred\ltype: visionflow::props::MultiNamesPolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Classification/recommend_sample_set&quot; [label=&quot;id: Classification/recommend_sample_set\ltype: visionflow::param::PropertyObjectIdSet\lupdate: 1970-01-01 00:00:00.0000000\ldocs:
    Parameter group for a set \lof property object IDs.
    \l&quot;];
    &quot;Classification/recommend_training_set&quot; [label=&quot;id: Classification/recommend_training_set\ltype: visionflow::param::PropertyObjectIdSet\lupdate: 1970-01-01 00:00:00.0000000\ldocs:
    Parameter group for a set \lof property object IDs.
    \l&quot;];
    &quot;Classification/sample_recommend&quot; [label=&quot;id: Classification/sample_recommend\ltype: visionflow::confs::ClassificationSampleRecommend\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Classification sample recommend \ltool.\l&quot;];
    &quot;Classification/sample_recommend.args&quot; [label=&quot;id: Classification/sample_recommend.args\ltype: visionflow::param::SampleRecommendationParameter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Parameter for the sample recommendation \lalgorithm\l&quot;];
    &quot;Classification/sample_recommend.conf&quot; [label=&quot;id: Classification/sample_recommend.conf\ltype: visionflow::confs::SampleRecommendationParameterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set sample recommend \lparam.\l&quot;];
    &quot;Classification/statistician&quot; [label=&quot;id: Classification/statistician\ltype: visionflow::confs::ClassificationRegionMatchResultCounter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count classification \lregion match results.\l&quot;];
    &quot;Classification/statistics&quot; [label=&quot;id: Classification/statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;Classification/tagged_polygons&quot; [label=&quot;id: Classification/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;Classification/tagged_views&quot; [label=&quot;id: Classification/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;Classification/trainer&quot; [label=&quot;id: Classification/trainer\ltype: visionflow::confs::ClassificationTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Classification model trainer.\l&quot;];
    &quot;Classification/trainer.args&quot; [label=&quot;id: Classification/trainer.args\ltype: visionflow::param::ClassificationTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Classification/trainer.conf&quot; [label=&quot;id: Classification/trainer.conf\ltype: visionflow::confs::ClassificationTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set Classification \ltrainer options.\l&quot;];
    &quot;Classification/training_log&quot; [label=&quot;id: Classification/training_log\ltype: visionflow::param::TrainingLog\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Classification/training_set_recommend&quot; [label=&quot;id: Classification/training_set_recommend\ltype: visionflow::confs::TrainingSetRecommend\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to automatic inter \lclass balancing for training set \lpartitioning. \l&quot;];
    &quot;Classification/training_set_recommend.args&quot; [label=&quot;id: Classification/training_set_recommend.args\ltype: visionflow::param::TrainingSetRecommendParameter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Parameter for the auto class balance\l&quot;];
    &quot;Classification/training_set_recommend.conf&quot; [label=&quot;id: Classification/training_set_recommend.conf\ltype: visionflow::confs::TrainingSetRecommendParameterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to training set recommend \lparams.\l&quot;];
    &quot;Classification/truth&quot; [label=&quot;id: Classification/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Classification/view_tagger&quot; [label=&quot;id: Classification/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;];
    &quot;Classification/visualizer&quot; [label=&quot;id: Classification/visualizer\ltype: visionflow::opers::ClassificationVisualizer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Classification Visualizer.\l&quot;]
  }

  &quot;Classification/base_color&quot; -&gt; &quot;Classification/image_mean_conf&quot;;
  &quot;Classification/base_color&quot; -&gt; &quot;Classification/trainer&quot;;
  &quot;Classification/base_color_conf&quot; -&gt; &quot;Classification/base_color&quot;;
  &quot;Classification/batch_size&quot; -&gt; &quot;Classification/infer&quot;;
  &quot;Classification/batch_size&quot; -&gt; &quot;Classification/visualizer&quot;;
  &quot;Classification/batch_size_conf&quot; -&gt; &quot;Classification/batch_size&quot;;
  &quot;Classification/classes&quot; -&gt; &quot;Classification/label_oper&quot;;
  &quot;Classification/classes&quot; -&gt; &quot;Classification/trainer&quot;;
  &quot;Classification/comparator&quot; -&gt; &quot;Classification/match_result&quot;;
  &quot;Classification/image&quot; -&gt; &quot;Classification/image_mean_conf&quot;;
  &quot;Classification/image&quot; -&gt; &quot;Classification/infer&quot;;
  &quot;Classification/image&quot; -&gt; &quot;Classification/label_oper&quot;;
  &quot;Classification/image&quot; -&gt; &quot;Classification/sample_recommend&quot;;
  &quot;Classification/image&quot; -&gt; &quot;Classification/trainer&quot;;
  &quot;Classification/image&quot; -&gt; &quot;Classification/visualizer&quot;;
  &quot;Classification/image_mean&quot; -&gt; &quot;Classification/trainer&quot;;
  &quot;Classification/image_mean_conf&quot; -&gt; &quot;Classification/image_mean&quot;;
  &quot;Classification/infer&quot; -&gt; &quot;Classification/pred&quot;;
  &quot;Classification/label_classes.conf&quot; -&gt; &quot;Classification/classes&quot;;
  &quot;Classification/label_oper&quot; -&gt; &quot;Classification/mask&quot;;
  &quot;Classification/label_oper&quot; -&gt; &quot;Classification/tagged_polygons&quot;;
  &quot;Classification/label_oper&quot; -&gt; &quot;Classification/truth&quot;;
  &quot;Classification/label_oper.args&quot; -&gt; &quot;Classification/label_oper&quot;;
  &quot;Classification/label_oper.conf&quot; -&gt; &quot;Classification/label_oper.args&quot;;
  &quot;Classification/mask&quot; -&gt; &quot;Classification/trainer&quot;;
  &quot;Classification/model&quot; -&gt; &quot;Classification/infer&quot;;
  &quot;Classification/model&quot; -&gt; &quot;Classification/sample_recommend&quot;;
  &quot;Classification/model&quot; -&gt; &quot;Classification/visualizer&quot;;
  &quot;Classification/pred&quot; -&gt; &quot;Classification/comparator&quot;;
  &quot;Classification/pred&quot; -&gt; &quot;Classification/statistician&quot;;
  &quot;Classification/sample_recommend&quot; -&gt; &quot;Classification/recommend_sample_set&quot;;
  &quot;Classification/sample_recommend.args&quot; -&gt; &quot;Classification/sample_recommend&quot;;
  &quot;Classification/sample_recommend.conf&quot; -&gt; &quot;Classification/sample_recommend.args&quot;;
  &quot;Classification/statistician&quot; -&gt; &quot;Classification/statistics&quot;;
  &quot;Classification/tagged_polygons&quot; -&gt; &quot;Classification/view_tagger&quot;;
  &quot;Classification/tagged_views&quot; -&gt; &quot;Classification/comparator&quot;;
  &quot;Classification/tagged_views&quot; -&gt; &quot;Classification/image_mean_conf&quot;;
  &quot;Classification/tagged_views&quot; -&gt; &quot;Classification/sample_recommend&quot;;
  &quot;Classification/tagged_views&quot; -&gt; &quot;Classification/statistician&quot;;
  &quot;Classification/tagged_views&quot; -&gt; &quot;Classification/trainer&quot;;
  &quot;Classification/tagged_views&quot; -&gt; &quot;Classification/training_set_recommend&quot;;
  &quot;Classification/trainer&quot; -&gt; &quot;Classification/model&quot;;
  &quot;Classification/trainer&quot; -&gt; &quot;Classification/training_log&quot;;
  &quot;Classification/trainer.args&quot; -&gt; &quot;Classification/trainer&quot;;
  &quot;Classification/trainer.conf&quot; -&gt; &quot;Classification/trainer.args&quot;;
  &quot;Classification/training_set_recommend&quot; -&gt; &quot;Classification/recommend_training_set&quot;;
  &quot;Classification/training_set_recommend.args&quot; -&gt; &quot;Classification/training_set_recommend&quot;;
  &quot;Classification/training_set_recommend.conf&quot; -&gt; &quot;Classification/training_set_recommend.args&quot;;
  &quot;Classification/truth&quot; -&gt; &quot;Classification/comparator&quot;;
  &quot;Classification/truth&quot; -&gt; &quot;Classification/statistician&quot;;
  &quot;Classification/truth&quot; -&gt; &quot;Classification/trainer&quot;;
  &quot;Classification/truth&quot; -&gt; &quot;Classification/training_set_recommend&quot;;
  &quot;Classification/view_tagger&quot; -&gt; &quot;Classification/tagged_views&quot;;
  &quot;Classification/views&quot; -&gt; &quot;Classification/infer&quot;;
  &quot;Classification/views&quot; -&gt; &quot;Classification/view_tagger&quot;;
  &quot;Classification/views&quot; -&gt; &quot;Classification/visualizer&quot;;
  &quot;Classification/visualizer&quot; -&gt; &quot;Classification/heatmap&quot;

}</p></object></div>
</section>
<section id="elclassification-tool">
<h2>ELClassification Tool<a class="headerlink" href="#elclassification-tool" title="Link to this heading">#</a></h2>
<p>EL Classification Tool</p>
<div class="graphviz"><object data="../_images/graphviz-01bdafd36684fc2ad1994d742b01a8ad6c01150b.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: ELClassification&quot; {
  label=&quot;OnlyTool: ELClassification&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;ELClassification/comparator&quot;;
  &quot;ELClassification/infer&quot;;
  &quot;ELClassification/label_oper&quot;;
  &quot;ELClassification/view_tagger&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;ELClassification/batch_size_conf&quot;;
  &quot;ELClassification/label_classes.conf&quot;;
  &quot;ELClassification/label_oper.conf&quot;;
  &quot;ELClassification/model_health_evaluator&quot;;
  &quot;ELClassification/statistician&quot;;
  &quot;ELClassification/trainer&quot;;
  &quot;ELClassification/trainer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;ELClassification/mask&quot;;
  &quot;ELClassification/match_result&quot;;
  &quot;ELClassification/tagged_polygons&quot;;
  &quot;ELClassification/tagged_views&quot;;
  &quot;ELClassification/truth&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;ELClassification/image&quot;;
  &quot;ELClassification/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;ELClassification/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;ELClassification/batch_size&quot;;
  &quot;ELClassification/label_oper.args&quot;;
  &quot;ELClassification/model&quot;;
  &quot;ELClassification/model_health&quot;;
  &quot;ELClassification/statistics&quot;;
  &quot;ELClassification/trainer.args&quot;;
  &quot;ELClassification/training_log&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style
  &quot;ELClassification/classes&quot;


  subgraph &quot;cluster_ELClassification&quot; {
    label=&quot;ELClassification&quot;;
    &quot;ELClassification/batch_size&quot; [label=&quot;id: ELClassification/batch_size\ltype: visionflow::param::InferenceBatchSize\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Inference BatchSize and Inference \lMode. Currently only contains \lbatch size. It may need to be \lrefactored in the future.\l&quot;];
    &quot;ELClassification/batch_size_conf&quot; [label=&quot;id: ELClassification/batch_size_conf\ltype: visionflow::confs::InferenceBatchSizeConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set inference \lbatch size.\l&quot;];
    &quot;ELClassification/classes&quot; [label=&quot;id: ELClassification/classes\ltype: visionflow::param::LabelClasses\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage label classes.\l&quot;];
    &quot;ELClassification/comparator&quot; [label=&quot;id: ELClassification/comparator\ltype: visionflow::opers::RegionsMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to compare the predicted \lregions with the ground truth \lto get the category (in [TP, FP, \lTN, FN]) of each region.\l&quot;];
    &quot;ELClassification/infer&quot; [label=&quot;id: ELClassification/infer\ltype: visionflow::opers::ELClassificationInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: EL Classification inference engine.\l&quot;];
    &quot;ELClassification/label_classes.conf&quot; [label=&quot;id: ELClassification/label_classes.conf\ltype: visionflow::confs::LabelClassesConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \llabel classes parameter.\l&quot;];
    &quot;ELClassification/label_oper&quot; [label=&quot;id: ELClassification/label_oper\ltype: visionflow::opers::ClassificationLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for Classification \ltool.\l&quot;];
    &quot;ELClassification/label_oper.args&quot; [label=&quot;id: ELClassification/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;ELClassification/label_oper.conf&quot; [label=&quot;id: ELClassification/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;ELClassification/mask&quot; [label=&quot;id: ELClassification/mask\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELClassification/match_result&quot; [label=&quot;id: ELClassification/match_result\ltype: visionflow::props::RegionMatchResultList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure to store list \lof RegionMatchResult.\l&quot;];
    &quot;ELClassification/model&quot; [label=&quot;id: ELClassification/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;ELClassification/model_health&quot; [label=&quot;id: ELClassification/model_health\ltype: visionflow::param::ModelHealth\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage model health.\l&quot;];
    &quot;ELClassification/model_health_evaluator&quot; [label=&quot;id: ELClassification/model_health_evaluator\ltype: visionflow::confs::ELClassificationModelHealthEvaluator\lupdate: 1970-01-01 00:00:00.0000000\ldocs: EL Classification Model Health \lEvaluator.\l&quot;];
    &quot;ELClassification/pred&quot; [label=&quot;id: ELClassification/pred\ltype: visionflow::props::MultiNamesPolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELClassification/statistician&quot; [label=&quot;id: ELClassification/statistician\ltype: visionflow::confs::ClassificationRegionMatchResultCounter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count classification \lregion match results.\l&quot;];
    &quot;ELClassification/statistics&quot; [label=&quot;id: ELClassification/statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;ELClassification/tagged_polygons&quot; [label=&quot;id: ELClassification/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;ELClassification/tagged_views&quot; [label=&quot;id: ELClassification/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;ELClassification/trainer&quot; [label=&quot;id: ELClassification/trainer\ltype: visionflow::confs::ELClassificationTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: EL Classification model trainer.\l&quot;];
    &quot;ELClassification/trainer.args&quot; [label=&quot;id: ELClassification/trainer.args\ltype: visionflow::param::ELClassificationTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ELClassification/trainer.conf&quot; [label=&quot;id: ELClassification/trainer.conf\ltype: visionflow::confs::ELClassificationTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set EL classification \ltrainer options.\l&quot;];
    &quot;ELClassification/training_log&quot; [label=&quot;id: ELClassification/training_log\ltype: visionflow::param::TrainingLog\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ELClassification/truth&quot; [label=&quot;id: ELClassification/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELClassification/view_tagger&quot; [label=&quot;id: ELClassification/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;]
  }

  &quot;ELClassification/batch_size&quot; -&gt; &quot;ELClassification/infer&quot;;
  &quot;ELClassification/batch_size_conf&quot; -&gt; &quot;ELClassification/batch_size&quot;;
  &quot;ELClassification/classes&quot; -&gt; &quot;ELClassification/label_oper&quot;;
  &quot;ELClassification/classes&quot; -&gt; &quot;ELClassification/trainer&quot;;
  &quot;ELClassification/comparator&quot; -&gt; &quot;ELClassification/match_result&quot;;
  &quot;ELClassification/image&quot; -&gt; &quot;ELClassification/infer&quot;;
  &quot;ELClassification/image&quot; -&gt; &quot;ELClassification/label_oper&quot;;
  &quot;ELClassification/image&quot; -&gt; &quot;ELClassification/trainer&quot;;
  &quot;ELClassification/infer&quot; -&gt; &quot;ELClassification/pred&quot;;
  &quot;ELClassification/label_classes.conf&quot; -&gt; &quot;ELClassification/classes&quot;;
  &quot;ELClassification/label_oper&quot; -&gt; &quot;ELClassification/mask&quot;;
  &quot;ELClassification/label_oper&quot; -&gt; &quot;ELClassification/tagged_polygons&quot;;
  &quot;ELClassification/label_oper&quot; -&gt; &quot;ELClassification/truth&quot;;
  &quot;ELClassification/label_oper.args&quot; -&gt; &quot;ELClassification/label_oper&quot;;
  &quot;ELClassification/label_oper.conf&quot; -&gt; &quot;ELClassification/label_oper.args&quot;;
  &quot;ELClassification/mask&quot; -&gt; &quot;ELClassification/trainer&quot;;
  &quot;ELClassification/model&quot; -&gt; &quot;ELClassification/infer&quot;;
  &quot;ELClassification/model_health_evaluator&quot; -&gt; &quot;ELClassification/model_health&quot;;
  &quot;ELClassification/pred&quot; -&gt; &quot;ELClassification/comparator&quot;;
  &quot;ELClassification/pred&quot; -&gt; &quot;ELClassification/model_health_evaluator&quot;;
  &quot;ELClassification/pred&quot; -&gt; &quot;ELClassification/statistician&quot;;
  &quot;ELClassification/statistician&quot; -&gt; &quot;ELClassification/statistics&quot;;
  &quot;ELClassification/tagged_polygons&quot; -&gt; &quot;ELClassification/view_tagger&quot;;
  &quot;ELClassification/tagged_views&quot; -&gt; &quot;ELClassification/comparator&quot;;
  &quot;ELClassification/tagged_views&quot; -&gt; &quot;ELClassification/model_health_evaluator&quot;;
  &quot;ELClassification/tagged_views&quot; -&gt; &quot;ELClassification/statistician&quot;;
  &quot;ELClassification/tagged_views&quot; -&gt; &quot;ELClassification/trainer&quot;;
  &quot;ELClassification/trainer&quot; -&gt; &quot;ELClassification/model&quot;;
  &quot;ELClassification/trainer&quot; -&gt; &quot;ELClassification/training_log&quot;;
  &quot;ELClassification/trainer.args&quot; -&gt; &quot;ELClassification/trainer&quot;;
  &quot;ELClassification/trainer.conf&quot; -&gt; &quot;ELClassification/trainer.args&quot;;
  &quot;ELClassification/truth&quot; -&gt; &quot;ELClassification/comparator&quot;;
  &quot;ELClassification/truth&quot; -&gt; &quot;ELClassification/statistician&quot;;
  &quot;ELClassification/truth&quot; -&gt; &quot;ELClassification/trainer&quot;;
  &quot;ELClassification/view_tagger&quot; -&gt; &quot;ELClassification/tagged_views&quot;;
  &quot;ELClassification/views&quot; -&gt; &quot;ELClassification/infer&quot;;
  &quot;ELClassification/views&quot; -&gt; &quot;ELClassification/view_tagger&quot;

}</p></object></div>
</section>
<section id="elunsuperclassification-tool">
<h2>ELUnsuperClassification Tool<a class="headerlink" href="#elunsuperclassification-tool" title="Link to this heading">#</a></h2>
<p>EL Unsuper Classification Tool</p>
<div class="graphviz"><object data="../_images/graphviz-41c4e9fa795a2c75a7252b438fd856df16a4eb00.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: ELUnsuperClassification&quot; {
  label=&quot;OnlyTool: ELUnsuperClassification&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;ELUnsuperClassification/infer&quot;;
  &quot;ELUnsuperClassification/label_oper&quot;;
  &quot;ELUnsuperClassification/view_tagger&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;ELUnsuperClassification/batch_size_conf&quot;;
  &quot;ELUnsuperClassification/infer.conf&quot;;
  &quot;ELUnsuperClassification/label_oper.conf&quot;;
  &quot;ELUnsuperClassification/trainer&quot;;
  &quot;ELUnsuperClassification/trainer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;ELUnsuperClassification/mask&quot;;
  &quot;ELUnsuperClassification/tagged_polygons&quot;;
  &quot;ELUnsuperClassification/tagged_views&quot;;
  &quot;ELUnsuperClassification/truth&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;ELUnsuperClassification/image&quot;;
  &quot;ELUnsuperClassification/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;ELUnsuperClassification/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;ELUnsuperClassification/batch_size&quot;;
  &quot;ELUnsuperClassification/infer.args&quot;;
  &quot;ELUnsuperClassification/label_oper.args&quot;;
  &quot;ELUnsuperClassification/model&quot;;
  &quot;ELUnsuperClassification/trainer.args&quot;;
  &quot;ELUnsuperClassification/training_log&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style



  subgraph &quot;cluster_ELUnsuperClassification&quot; {
    label=&quot;ELUnsuperClassification&quot;;
    &quot;ELUnsuperClassification/batch_size&quot; [label=&quot;id: ELUnsuperClassification/batch_size\ltype: visionflow::param::InferenceBatchSize\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Inference BatchSize and Inference \lMode. Currently only contains \lbatch size. It may need to be \lrefactored in the future.\l&quot;];
    &quot;ELUnsuperClassification/batch_size_conf&quot; [label=&quot;id: ELUnsuperClassification/batch_size_conf\ltype: visionflow::confs::InferenceBatchSizeConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set inference \lbatch size.\l&quot;];
    &quot;ELUnsuperClassification/infer&quot; [label=&quot;id: ELUnsuperClassification/infer\ltype: visionflow::opers::ELUnsuperClassificationInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: EL Unsuper Classification inference \lengine.\l&quot;];
    &quot;ELUnsuperClassification/infer.args&quot; [label=&quot;id: ELUnsuperClassification/infer.args\ltype: visionflow::param::ELUnsuperClassificationInferenceParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ELUnsuperClassification/infer.conf&quot; [label=&quot;id: ELUnsuperClassification/infer.conf\ltype: visionflow::confs::ELUnsuperClassificationInferenceConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set EL Unsuper \lclassification Inference options.\l&quot;];
    &quot;ELUnsuperClassification/label_oper&quot; [label=&quot;id: ELUnsuperClassification/label_oper\ltype: visionflow::opers::UnsuperClassificationLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for unsuper \lclassification tool.\l&quot;];
    &quot;ELUnsuperClassification/label_oper.args&quot; [label=&quot;id: ELUnsuperClassification/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;ELUnsuperClassification/label_oper.conf&quot; [label=&quot;id: ELUnsuperClassification/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;ELUnsuperClassification/mask&quot; [label=&quot;id: ELUnsuperClassification/mask\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELUnsuperClassification/model&quot; [label=&quot;id: ELUnsuperClassification/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;ELUnsuperClassification/pred&quot; [label=&quot;id: ELUnsuperClassification/pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELUnsuperClassification/tagged_polygons&quot; [label=&quot;id: ELUnsuperClassification/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;ELUnsuperClassification/tagged_views&quot; [label=&quot;id: ELUnsuperClassification/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;ELUnsuperClassification/trainer&quot; [label=&quot;id: ELUnsuperClassification/trainer\ltype: visionflow::confs::ELUnsuperClassificationTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: EL Classification model trainer.\l&quot;];
    &quot;ELUnsuperClassification/trainer.args&quot; [label=&quot;id: ELUnsuperClassification/trainer.args\ltype: visionflow::param::ELUnsuperClassificationTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ELUnsuperClassification/trainer.conf&quot; [label=&quot;id: ELUnsuperClassification/trainer.conf\ltype: visionflow::confs::ELUnsuperClassificationTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set EL Unsuper \lclassification trainer options.\l&quot;];
    &quot;ELUnsuperClassification/training_log&quot; [label=&quot;id: ELUnsuperClassification/training_log\ltype: visionflow::param::TrainingLog\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ELUnsuperClassification/truth&quot; [label=&quot;id: ELUnsuperClassification/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELUnsuperClassification/view_tagger&quot; [label=&quot;id: ELUnsuperClassification/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;]
  }

  &quot;ELUnsuperClassification/batch_size&quot; -&gt; &quot;ELUnsuperClassification/infer&quot;;
  &quot;ELUnsuperClassification/batch_size_conf&quot; -&gt; &quot;ELUnsuperClassification/batch_size&quot;;
  &quot;ELUnsuperClassification/image&quot; -&gt; &quot;ELUnsuperClassification/infer&quot;;
  &quot;ELUnsuperClassification/image&quot; -&gt; &quot;ELUnsuperClassification/label_oper&quot;;
  &quot;ELUnsuperClassification/image&quot; -&gt; &quot;ELUnsuperClassification/trainer&quot;;
  &quot;ELUnsuperClassification/infer&quot; -&gt; &quot;ELUnsuperClassification/pred&quot;;
  &quot;ELUnsuperClassification/infer.args&quot; -&gt; &quot;ELUnsuperClassification/infer&quot;;
  &quot;ELUnsuperClassification/infer.conf&quot; -&gt; &quot;ELUnsuperClassification/infer.args&quot;;
  &quot;ELUnsuperClassification/label_oper&quot; -&gt; &quot;ELUnsuperClassification/mask&quot;;
  &quot;ELUnsuperClassification/label_oper&quot; -&gt; &quot;ELUnsuperClassification/tagged_polygons&quot;;
  &quot;ELUnsuperClassification/label_oper&quot; -&gt; &quot;ELUnsuperClassification/truth&quot;;
  &quot;ELUnsuperClassification/label_oper.args&quot; -&gt; &quot;ELUnsuperClassification/label_oper&quot;;
  &quot;ELUnsuperClassification/label_oper.conf&quot; -&gt; &quot;ELUnsuperClassification/label_oper.args&quot;;
  &quot;ELUnsuperClassification/mask&quot; -&gt; &quot;ELUnsuperClassification/trainer&quot;;
  &quot;ELUnsuperClassification/model&quot; -&gt; &quot;ELUnsuperClassification/infer&quot;;
  &quot;ELUnsuperClassification/tagged_polygons&quot; -&gt; &quot;ELUnsuperClassification/view_tagger&quot;;
  &quot;ELUnsuperClassification/tagged_views&quot; -&gt; &quot;ELUnsuperClassification/trainer&quot;;
  &quot;ELUnsuperClassification/trainer&quot; -&gt; &quot;ELUnsuperClassification/model&quot;;
  &quot;ELUnsuperClassification/trainer&quot; -&gt; &quot;ELUnsuperClassification/training_log&quot;;
  &quot;ELUnsuperClassification/trainer.args&quot; -&gt; &quot;ELUnsuperClassification/trainer&quot;;
  &quot;ELUnsuperClassification/trainer.conf&quot; -&gt; &quot;ELUnsuperClassification/trainer.args&quot;;
  &quot;ELUnsuperClassification/truth&quot; -&gt; &quot;ELUnsuperClassification/trainer&quot;;
  &quot;ELUnsuperClassification/view_tagger&quot; -&gt; &quot;ELUnsuperClassification/tagged_views&quot;;
  &quot;ELUnsuperClassification/views&quot; -&gt; &quot;ELUnsuperClassification/infer&quot;;
  &quot;ELUnsuperClassification/views&quot; -&gt; &quot;ELUnsuperClassification/view_tagger&quot;

}</p></object></div>
</section>
<section id="detection-tool">
<h2>Detection Tool<a class="headerlink" href="#detection-tool" title="Link to this heading">#</a></h2>
<p>Detection Tool</p>
<div class="graphviz"><object data="../_images/graphviz-9dc95a98ec6a9739fb1a34b86d6548ff13d25668.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: Detection&quot; {
  label=&quot;OnlyTool: Detection&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;Detection/comparator&quot;;
  &quot;Detection/filter&quot;;
  &quot;Detection/infer&quot;;
  &quot;Detection/label_oper&quot;;
  &quot;Detection/view_tagger&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;Detection/base_color_conf&quot;;
  &quot;Detection/batch_size_conf&quot;;
  &quot;Detection/filter.conf&quot;;
  &quot;Detection/image_mean_conf&quot;;
  &quot;Detection/infer.conf&quot;;
  &quot;Detection/label_classes.conf&quot;;
  &quot;Detection/label_oper.conf&quot;;
  &quot;Detection/sample_recommend&quot;;
  &quot;Detection/sample_recommend.conf&quot;;
  &quot;Detection/statistician&quot;;
  &quot;Detection/trainer&quot;;
  &quot;Detection/trainer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;Detection/mask&quot;;
  &quot;Detection/match_result&quot;;
  &quot;Detection/raw_pred&quot;;
  &quot;Detection/tagged_polygons&quot;;
  &quot;Detection/tagged_views&quot;;
  &quot;Detection/truth&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;Detection/image&quot;;
  &quot;Detection/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;Detection/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;Detection/base_color&quot;;
  &quot;Detection/batch_size&quot;;
  &quot;Detection/filter.args&quot;;
  &quot;Detection/image_mean&quot;;
  &quot;Detection/infer.args&quot;;
  &quot;Detection/label_oper.args&quot;;
  &quot;Detection/model&quot;;
  &quot;Detection/recommend_sample_set&quot;;
  &quot;Detection/sample_recommend.args&quot;;
  &quot;Detection/statistics&quot;;
  &quot;Detection/trainer.args&quot;;
  &quot;Detection/training_log&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style
  &quot;Detection/classes&quot;


  subgraph &quot;cluster_Detection&quot; {
    label=&quot;Detection&quot;;
    &quot;Detection/base_color&quot; [label=&quot;id: Detection/base_color\ltype: visionflow::param::BaseColor\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Detection/base_color_conf&quot; [label=&quot;id: Detection/base_color_conf\ltype: visionflow::confs::BaseColorConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config input images' \lbase color.\l&quot;];
    &quot;Detection/batch_size&quot; [label=&quot;id: Detection/batch_size\ltype: visionflow::param::InferenceBatchSize\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Inference BatchSize and Inference \lMode. Currently only contains \lbatch size. It may need to be \lrefactored in the future.\l&quot;];
    &quot;Detection/batch_size_conf&quot; [label=&quot;id: Detection/batch_size_conf\ltype: visionflow::confs::InferenceBatchSizeConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set inference \lbatch size.\l&quot;];
    &quot;Detection/classes&quot; [label=&quot;id: Detection/classes\ltype: visionflow::param::LabelClasses\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage label classes.\l&quot;];
    &quot;Detection/comparator&quot; [label=&quot;id: Detection/comparator\ltype: visionflow::opers::RegionsMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to compare the predicted \lregions with the ground truth \lto get the category (in [TP, FP, \lTN, FN]) of each region.\l&quot;];
    &quot;Detection/filter&quot; [label=&quot;id: Detection/filter\ltype: visionflow::opers::PolygonsFilter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: An operator to filter list of \lregions with some common thresholds \lor customized python filter script.\l&quot;];
    &quot;Detection/filter.args&quot; [label=&quot;id: Detection/filter.args\ltype: visionflow::param::PolygonsFilterParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Detection/filter.conf&quot; [label=&quot;id: Detection/filter.conf\ltype: visionflow::confs::PolygonsFilterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to generate the \lpolygon filter args.\l&quot;];
    &quot;Detection/image_mean&quot; [label=&quot;id: Detection/image_mean\ltype: visionflow::param::ImageMean\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Image mean parameters\l&quot;];
    &quot;Detection/image_mean_conf&quot; [label=&quot;id: Detection/image_mean_conf\ltype: visionflow::confs::ImageMeanConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: ImageMeanConf Configurator class \lto compute the image mean values \lin the views.\l&quot;];
    &quot;Detection/infer&quot; [label=&quot;id: Detection/infer\ltype: visionflow::opers::DetectionInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Detection inference engine.\l&quot;];
    &quot;Detection/infer.args&quot; [label=&quot;id: Detection/infer.args\ltype: visionflow::param::DetectionInferParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Detection/infer.conf&quot; [label=&quot;id: Detection/infer.conf\ltype: visionflow::confs::DetectionInferConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set Detection \linference parameters.\l&quot;];
    &quot;Detection/label_classes.conf&quot; [label=&quot;id: Detection/label_classes.conf\ltype: visionflow::confs::LabelClassesConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \llabel classes parameter.\l&quot;];
    &quot;Detection/label_oper&quot; [label=&quot;id: Detection/label_oper\ltype: visionflow::opers::DetectionLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for Classification \ltool.\l&quot;];
    &quot;Detection/label_oper.args&quot; [label=&quot;id: Detection/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;Detection/label_oper.conf&quot; [label=&quot;id: Detection/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;Detection/mask&quot; [label=&quot;id: Detection/mask\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Detection/match_result&quot; [label=&quot;id: Detection/match_result\ltype: visionflow::props::RegionMatchResultList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure to store list \lof RegionMatchResult.\l&quot;];
    &quot;Detection/model&quot; [label=&quot;id: Detection/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;Detection/pred&quot; [label=&quot;id: Detection/pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Detection/raw_pred&quot; [label=&quot;id: Detection/raw_pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Detection/recommend_sample_set&quot; [label=&quot;id: Detection/recommend_sample_set\ltype: visionflow::param::PropertyObjectIdSet\lupdate: 1970-01-01 00:00:00.0000000\ldocs:
    Parameter group for a set \lof property object IDs.
    \l&quot;];
    &quot;Detection/sample_recommend&quot; [label=&quot;id: Detection/sample_recommend\ltype: visionflow::confs::DetectionSampleRecommend\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Detection sample recommend tool.\l&quot;];
    &quot;Detection/sample_recommend.args&quot; [label=&quot;id: Detection/sample_recommend.args\ltype: visionflow::param::SampleRecommendationParameter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Parameter for the sample recommendation \lalgorithm\l&quot;];
    &quot;Detection/sample_recommend.conf&quot; [label=&quot;id: Detection/sample_recommend.conf\ltype: visionflow::confs::SampleRecommendationParameterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set sample recommend \lparam.\l&quot;];
    &quot;Detection/statistician&quot; [label=&quot;id: Detection/statistician\ltype: visionflow::confs::RegionMatchResultCounterV3\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count region match \lresults after filtered the truths \land predictions whose center overlaps \lwithin no-train regions.\l&quot;];
    &quot;Detection/statistics&quot; [label=&quot;id: Detection/statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;Detection/tagged_polygons&quot; [label=&quot;id: Detection/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;Detection/tagged_views&quot; [label=&quot;id: Detection/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;Detection/trainer&quot; [label=&quot;id: Detection/trainer\ltype: visionflow::confs::DetectionTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Detection model trainer.\l&quot;];
    &quot;Detection/trainer.args&quot; [label=&quot;id: Detection/trainer.args\ltype: visionflow::param::DetectionTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Detection/trainer.conf&quot; [label=&quot;id: Detection/trainer.conf\ltype: visionflow::confs::DetectionTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set Detection \ltrainer options.\l&quot;];
    &quot;Detection/training_log&quot; [label=&quot;id: Detection/training_log\ltype: visionflow::param::TrainingLog\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;Detection/truth&quot; [label=&quot;id: Detection/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;Detection/view_tagger&quot; [label=&quot;id: Detection/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;]
  }

  &quot;Detection/base_color&quot; -&gt; &quot;Detection/image_mean_conf&quot;;
  &quot;Detection/base_color&quot; -&gt; &quot;Detection/trainer&quot;;
  &quot;Detection/base_color_conf&quot; -&gt; &quot;Detection/base_color&quot;;
  &quot;Detection/batch_size&quot; -&gt; &quot;Detection/infer&quot;;
  &quot;Detection/batch_size_conf&quot; -&gt; &quot;Detection/batch_size&quot;;
  &quot;Detection/classes&quot; -&gt; &quot;Detection/label_oper&quot;;
  &quot;Detection/classes&quot; -&gt; &quot;Detection/trainer&quot;;
  &quot;Detection/comparator&quot; -&gt; &quot;Detection/match_result&quot;;
  &quot;Detection/filter&quot; -&gt; &quot;Detection/pred&quot;;
  &quot;Detection/filter.args&quot; -&gt; &quot;Detection/filter&quot;;
  &quot;Detection/filter.conf&quot; -&gt; &quot;Detection/filter.args&quot;;
  &quot;Detection/image&quot; -&gt; &quot;Detection/image_mean_conf&quot;;
  &quot;Detection/image&quot; -&gt; &quot;Detection/infer&quot;;
  &quot;Detection/image&quot; -&gt; &quot;Detection/label_oper&quot;;
  &quot;Detection/image&quot; -&gt; &quot;Detection/sample_recommend&quot;;
  &quot;Detection/image&quot; -&gt; &quot;Detection/trainer&quot;;
  &quot;Detection/image_mean&quot; -&gt; &quot;Detection/trainer&quot;;
  &quot;Detection/image_mean_conf&quot; -&gt; &quot;Detection/image_mean&quot;;
  &quot;Detection/infer&quot; -&gt; &quot;Detection/raw_pred&quot;;
  &quot;Detection/infer.args&quot; -&gt; &quot;Detection/infer&quot;;
  &quot;Detection/infer.args&quot; -&gt; &quot;Detection/sample_recommend&quot;;
  &quot;Detection/infer.conf&quot; -&gt; &quot;Detection/infer.args&quot;;
  &quot;Detection/label_classes.conf&quot; -&gt; &quot;Detection/classes&quot;;
  &quot;Detection/label_oper&quot; -&gt; &quot;Detection/mask&quot;;
  &quot;Detection/label_oper&quot; -&gt; &quot;Detection/tagged_polygons&quot;;
  &quot;Detection/label_oper&quot; -&gt; &quot;Detection/truth&quot;;
  &quot;Detection/label_oper.args&quot; -&gt; &quot;Detection/label_oper&quot;;
  &quot;Detection/label_oper.conf&quot; -&gt; &quot;Detection/label_oper.args&quot;;
  &quot;Detection/mask&quot; -&gt; &quot;Detection/statistician&quot;;
  &quot;Detection/mask&quot; -&gt; &quot;Detection/trainer&quot;;
  &quot;Detection/model&quot; -&gt; &quot;Detection/infer&quot;;
  &quot;Detection/model&quot; -&gt; &quot;Detection/sample_recommend&quot;;
  &quot;Detection/pred&quot; -&gt; &quot;Detection/comparator&quot;;
  &quot;Detection/pred&quot; -&gt; &quot;Detection/statistician&quot;;
  &quot;Detection/raw_pred&quot; -&gt; &quot;Detection/filter&quot;;
  &quot;Detection/sample_recommend&quot; -&gt; &quot;Detection/recommend_sample_set&quot;;
  &quot;Detection/sample_recommend.args&quot; -&gt; &quot;Detection/sample_recommend&quot;;
  &quot;Detection/sample_recommend.conf&quot; -&gt; &quot;Detection/sample_recommend.args&quot;;
  &quot;Detection/statistician&quot; -&gt; &quot;Detection/statistics&quot;;
  &quot;Detection/tagged_polygons&quot; -&gt; &quot;Detection/view_tagger&quot;;
  &quot;Detection/tagged_views&quot; -&gt; &quot;Detection/comparator&quot;;
  &quot;Detection/tagged_views&quot; -&gt; &quot;Detection/image_mean_conf&quot;;
  &quot;Detection/tagged_views&quot; -&gt; &quot;Detection/sample_recommend&quot;;
  &quot;Detection/tagged_views&quot; -&gt; &quot;Detection/statistician&quot;;
  &quot;Detection/tagged_views&quot; -&gt; &quot;Detection/trainer&quot;;
  &quot;Detection/trainer&quot; -&gt; &quot;Detection/model&quot;;
  &quot;Detection/trainer&quot; -&gt; &quot;Detection/training_log&quot;;
  &quot;Detection/trainer.args&quot; -&gt; &quot;Detection/trainer&quot;;
  &quot;Detection/trainer.conf&quot; -&gt; &quot;Detection/trainer.args&quot;;
  &quot;Detection/truth&quot; -&gt; &quot;Detection/comparator&quot;;
  &quot;Detection/truth&quot; -&gt; &quot;Detection/statistician&quot;;
  &quot;Detection/truth&quot; -&gt; &quot;Detection/trainer&quot;;
  &quot;Detection/view_tagger&quot; -&gt; &quot;Detection/tagged_views&quot;;
  &quot;Detection/views&quot; -&gt; &quot;Detection/infer&quot;;
  &quot;Detection/views&quot; -&gt; &quot;Detection/view_tagger&quot;

}</p></object></div>
</section>
<section id="cameracalibration-tool">
<h2>CameraCalibration Tool<a class="headerlink" href="#cameracalibration-tool" title="Link to this heading">#</a></h2>
<p>Camera calibrate tool.</p>
<div class="graphviz"><object data="../_images/graphviz-4c707ac2d41108a0eb635c0abf9809c49b39aa11.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: CameraCalibration&quot; {
  label=&quot;OnlyTool: CameraCalibration&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;CameraCalibration/infer&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;CameraCalibration/infer.conf&quot;;
  &quot;CameraCalibration/trainer&quot;;
  &quot;CameraCalibration/trainer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style


  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;CameraCalibration/image&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;CameraCalibration/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;CameraCalibration/camera_model&quot;;
  &quot;CameraCalibration/evaluation&quot;;
  &quot;CameraCalibration/infer.args&quot;;
  &quot;CameraCalibration/pixel_scale&quot;;
  &quot;CameraCalibration/trainer.args&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style



  subgraph &quot;cluster_CameraCalibration&quot; {
    label=&quot;CameraCalibration&quot;;
    &quot;CameraCalibration/camera_model&quot; [label=&quot;id: CameraCalibration/camera_model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;CameraCalibration/evaluation&quot; [label=&quot;id: CameraCalibration/evaluation\ltype: visionflow::param::CameraCalibrationEvaluation\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage camera calibrate \lfeature points.\l&quot;];
    &quot;CameraCalibration/infer&quot; [label=&quot;id: CameraCalibration/infer\ltype: visionflow::opers::CameraCalibrationInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Camera calibrate inference engine.\l&quot;];
    &quot;CameraCalibration/infer.args&quot; [label=&quot;id: CameraCalibration/infer.args\ltype: visionflow::param::CameraCalibrationInferParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Camera calibrate Infer Parameter \lGroup\l&quot;];
    &quot;CameraCalibration/infer.conf&quot; [label=&quot;id: CameraCalibration/infer.conf\ltype: visionflow::confs::CameraCalibrationInferConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set Camera Calibrate \lInfer options.\l&quot;];
    &quot;CameraCalibration/pixel_scale&quot; [label=&quot;id: CameraCalibration/pixel_scale\ltype: visionflow::param::CameraCalibrationPixelScale\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Camera calibrate Pixel Scale\l&quot;];
    &quot;CameraCalibration/pred&quot; [label=&quot;id: CameraCalibration/pred\ltype: visionflow::props::Image\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property Image implementation.\l&quot;];
    &quot;CameraCalibration/trainer&quot; [label=&quot;id: CameraCalibration/trainer\ltype: visionflow::confs::CameraCalibrationTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Camera Calibrate model trainer.\l&quot;];
    &quot;CameraCalibration/trainer.args&quot; [label=&quot;id: CameraCalibration/trainer.args\ltype: visionflow::param::CameraCalibrationTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage camera calibration \ltraining parameters.\l&quot;];
    &quot;CameraCalibration/trainer.conf&quot; [label=&quot;id: CameraCalibration/trainer.conf\ltype: visionflow::confs::CameraCalibrationTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set Camera Calibrate \ltrainer options.\l&quot;]
  }

  &quot;CameraCalibration/camera_model&quot; -&gt; &quot;CameraCalibration/infer&quot;;
  &quot;CameraCalibration/image&quot; -&gt; &quot;CameraCalibration/infer&quot;;
  &quot;CameraCalibration/infer&quot; -&gt; &quot;CameraCalibration/pred&quot;;
  &quot;CameraCalibration/infer.args&quot; -&gt; &quot;CameraCalibration/infer&quot;;
  &quot;CameraCalibration/infer.conf&quot; -&gt; &quot;CameraCalibration/infer.args&quot;;
  &quot;CameraCalibration/trainer&quot; -&gt; &quot;CameraCalibration/camera_model&quot;;
  &quot;CameraCalibration/trainer&quot; -&gt; &quot;CameraCalibration/evaluation&quot;;
  &quot;CameraCalibration/trainer&quot; -&gt; &quot;CameraCalibration/pixel_scale&quot;;
  &quot;CameraCalibration/trainer.args&quot; -&gt; &quot;CameraCalibration/trainer&quot;;
  &quot;CameraCalibration/trainer.conf&quot; -&gt; &quot;CameraCalibration/trainer.args&quot;

}</p></object></div>
</section>
<section id="viewtransformer-tool">
<h2>ViewTransformer Tool<a class="headerlink" href="#viewtransformer-tool" title="Link to this heading">#</a></h2>
<p>View transformer tool.</p>
<div class="graphviz"><object data="../_images/graphviz-5316790f8ef33b94d80575bf7c16da22c6291f4d.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: ViewTransformer&quot; {
  label=&quot;OnlyTool: ViewTransformer&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;ViewTransformer/filter&quot;;
  &quot;ViewTransformer/transformer&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;ViewTransformer/filter.conf&quot;;
  &quot;ViewTransformer/transformer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;ViewTransformer/filtered_regions&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;ViewTransformer/image_info&quot;;
  &quot;ViewTransformer/input_views&quot;;
  &quot;ViewTransformer/regions&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;ViewTransformer/transformed_views&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;ViewTransformer/filter.args&quot;;
  &quot;ViewTransformer/transformer.args&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style



  subgraph &quot;cluster_ViewTransformer&quot; {
    label=&quot;ViewTransformer&quot;;
    &quot;ViewTransformer/filter&quot; [label=&quot;id: ViewTransformer/filter\ltype: visionflow::opers::ViewFilter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Region filter in each ViewTransformer \ltool.\l&quot;];
    &quot;ViewTransformer/filter.args&quot; [label=&quot;id: ViewTransformer/filter.args\ltype: visionflow::param::ViewFilterParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ViewTransformer/filter.conf&quot; [label=&quot;id: ViewTransformer/filter.conf\ltype: visionflow::confs::ViewFilterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config the filter \lparameter before view transformer.\l&quot;];
    &quot;ViewTransformer/filtered_regions&quot; [label=&quot;id: ViewTransformer/filtered_regions\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ViewTransformer/transformed_views&quot; [label=&quot;id: ViewTransformer/transformed_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;ViewTransformer/transformer&quot; [label=&quot;id: ViewTransformer/transformer\ltype: visionflow::opers::ViewTransformer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to transform the \lresult of the previous tool's \ldetection output with translation, \lscaling, rotation, masking and \lother transformation parameters \lto obtain new view windows that \lcan be used as input to the next \ltool.\l&quot;];
    &quot;ViewTransformer/transformer.args&quot; [label=&quot;id: ViewTransformer/transformer.args\ltype: visionflow::param::ViewTransformParameterList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lview transform parameters.\l&quot;];
    &quot;ViewTransformer/transformer.conf&quot; [label=&quot;id: ViewTransformer/transformer.conf\ltype: visionflow::confs::ViewTransformerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config the view \ltransformer.\l&quot;]
  }

  &quot;ViewTransformer/filter&quot; -&gt; &quot;ViewTransformer/filtered_regions&quot;;
  &quot;ViewTransformer/filter.args&quot; -&gt; &quot;ViewTransformer/filter&quot;;
  &quot;ViewTransformer/filter.conf&quot; -&gt; &quot;ViewTransformer/filter.args&quot;;
  &quot;ViewTransformer/filtered_regions&quot; -&gt; &quot;ViewTransformer/transformer&quot;;
  &quot;ViewTransformer/image_info&quot; -&gt; &quot;ViewTransformer/transformer&quot;;
  &quot;ViewTransformer/input_views&quot; -&gt; &quot;ViewTransformer/filter&quot;;
  &quot;ViewTransformer/regions&quot; -&gt; &quot;ViewTransformer/filter&quot;;
  &quot;ViewTransformer/transformer&quot; -&gt; &quot;ViewTransformer/transformed_views&quot;;
  &quot;ViewTransformer/transformer.args&quot; -&gt; &quot;ViewTransformer/transformer&quot;;
  &quot;ViewTransformer/transformer.conf&quot; -&gt; &quot;ViewTransformer/transformer.args&quot;

}</p></object></div>
</section>
<section id="regioncalculation-tool">
<h2>RegionCalculation Tool<a class="headerlink" href="#regioncalculation-tool" title="Link to this heading">#</a></h2>
<p>Region calculation tool.</p>
<div class="graphviz"><object data="../_images/graphviz-3021174cd9b1401aa8d45191ea20d93b4dab301b.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: RegionCalculation&quot; {
  label=&quot;OnlyTool: RegionCalculation&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;RegionCalculation/calculator&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;RegionCalculation/calculator.conf&quot;;
  &quot;RegionCalculation/label_classes.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style


  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style


  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style
  &quot;RegionCalculation/properties&quot;

  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;RegionCalculation/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;RegionCalculation/calculator.args&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style
  &quot;RegionCalculation/classes&quot;


  subgraph &quot;cluster_RegionCalculation&quot; {
    label=&quot;RegionCalculation&quot;;
    &quot;RegionCalculation/calculator&quot; [label=&quot;id: RegionCalculation/calculator\ltype: visionflow::opers::RegionCalculator\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Region Calculator operator for \lRegionCalculation tool.\l&quot;];
    &quot;RegionCalculation/calculator.args&quot; [label=&quot;id: RegionCalculation/calculator.args\ltype: visionflow::param::RegionCalculationParameter\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;RegionCalculation/calculator.conf&quot; [label=&quot;id: RegionCalculation/calculator.conf\ltype: visionflow::confs::RegionCalculationConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to config the region \lcalculator parameter.\l&quot;];
    &quot;RegionCalculation/classes&quot; [label=&quot;id: RegionCalculation/classes\ltype: visionflow::param::LabelClasses\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage label classes.\l&quot;];
    &quot;RegionCalculation/label_classes.conf&quot; [label=&quot;id: RegionCalculation/label_classes.conf\ltype: visionflow::confs::LabelClassesConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \llabel classes parameter.\l&quot;];
    &quot;RegionCalculation/pred&quot; [label=&quot;id: RegionCalculation/pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;]
  }

  &quot;RegionCalculation/calculator&quot; -&gt; &quot;RegionCalculation/pred&quot;;
  &quot;RegionCalculation/calculator.args&quot; -&gt; &quot;RegionCalculation/calculator&quot;;
  &quot;RegionCalculation/calculator.conf&quot; -&gt; &quot;RegionCalculation/calculator.args&quot;;
  &quot;RegionCalculation/classes&quot; -&gt; &quot;RegionCalculation/calculator&quot;;
  &quot;RegionCalculation/label_classes.conf&quot; -&gt; &quot;RegionCalculation/classes&quot;;
  &quot;RegionCalculation/properties&quot; -&gt; &quot;RegionCalculation/calculator&quot;

}</p></object></div>
</section>
<section id="elocr-tool">
<h2>ELOCR Tool<a class="headerlink" href="#elocr-tool" title="Link to this heading">#</a></h2>
<p>EL OCR Tool.</p>
<div class="graphviz"><object data="../_images/graphviz-67816e937a6bf2cebe5fe7e6829c897fac38b686.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: ELOCR&quot; {
  label=&quot;OnlyTool: ELOCR&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;ELOCR/comparator&quot;;
  &quot;ELOCR/infer&quot;;
  &quot;ELOCR/infer_string_matcher&quot;;
  &quot;ELOCR/label_oper&quot;;
  &quot;ELOCR/truth_string_matcher&quot;;
  &quot;ELOCR/view_tagger&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;ELOCR/batch_size_conf&quot;;
  &quot;ELOCR/infer.conf&quot;;
  &quot;ELOCR/label_classes.conf&quot;;
  &quot;ELOCR/label_oper.conf&quot;;
  &quot;ELOCR/statistician&quot;;
  &quot;ELOCR/strings_statistician&quot;;
  &quot;ELOCR/templates_conf&quot;;
  &quot;ELOCR/trainer&quot;;
  &quot;ELOCR/trainer.conf&quot;;
  &quot;ELOCR/universal_conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;ELOCR/mask&quot;;
  &quot;ELOCR/match_result&quot;;
  &quot;ELOCR/tagged_polygons&quot;;
  &quot;ELOCR/tagged_views&quot;;
  &quot;ELOCR/truth&quot;;
  &quot;ELOCR/truth.strings&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;ELOCR/image&quot;;
  &quot;ELOCR/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;ELOCR/pred.characters&quot;;
  &quot;ELOCR/pred.strings&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;ELOCR/batch_size&quot;;
  &quot;ELOCR/infer.args&quot;;
  &quot;ELOCR/label_oper.args&quot;;
  &quot;ELOCR/model&quot;;
  &quot;ELOCR/statistics&quot;;
  &quot;ELOCR/strings_statistics&quot;;
  &quot;ELOCR/templates&quot;;
  &quot;ELOCR/trainer.args&quot;;
  &quot;ELOCR/training_log&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style
  &quot;ELOCR/classes&quot;


  subgraph &quot;cluster_ELOCR&quot; {
    label=&quot;ELOCR&quot;;
    &quot;ELOCR/batch_size&quot; [label=&quot;id: ELOCR/batch_size\ltype: visionflow::param::InferenceBatchSize\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Inference BatchSize and Inference \lMode. Currently only contains \lbatch size. It may need to be \lrefactored in the future.\l&quot;];
    &quot;ELOCR/batch_size_conf&quot; [label=&quot;id: ELOCR/batch_size_conf\ltype: visionflow::confs::InferenceBatchSizeConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set inference \lbatch size.\l&quot;];
    &quot;ELOCR/classes&quot; [label=&quot;id: ELOCR/classes\ltype: visionflow::param::LabelClasses\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage label classes.\l&quot;];
    &quot;ELOCR/comparator&quot; [label=&quot;id: ELOCR/comparator\ltype: visionflow::opers::RegionsMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to compare the predicted \lregions with the ground truth \lto get the category (in [TP, FP, \lTN, FN]) of each region.\l&quot;];
    &quot;ELOCR/infer&quot; [label=&quot;id: ELOCR/infer\ltype: visionflow::opers::ELOCRInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: EL-OCR inference engine.\l&quot;];
    &quot;ELOCR/infer.args&quot; [label=&quot;id: ELOCR/infer.args\ltype: visionflow::param::ELOCRInferParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ELOCR/infer.conf&quot; [label=&quot;id: ELOCR/infer.conf\ltype: visionflow::confs::ELOCRInferConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set EL-OCR inference \lparameters.\l&quot;];
    &quot;ELOCR/infer_string_matcher&quot; [label=&quot;id: ELOCR/infer_string_matcher\ltype: visionflow::opers::OCRInferStringMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: OCR infer string matcher.\l&quot;];
    &quot;ELOCR/label_classes.conf&quot; [label=&quot;id: ELOCR/label_classes.conf\ltype: visionflow::confs::LabelClassesConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \llabel classes parameter.\l&quot;];
    &quot;ELOCR/label_oper&quot; [label=&quot;id: ELOCR/label_oper\ltype: visionflow::opers::ELOCRLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for EL-OCR tool.\l&quot;];
    &quot;ELOCR/label_oper.args&quot; [label=&quot;id: ELOCR/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;ELOCR/label_oper.conf&quot; [label=&quot;id: ELOCR/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;ELOCR/mask&quot; [label=&quot;id: ELOCR/mask\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELOCR/match_result&quot; [label=&quot;id: ELOCR/match_result\ltype: visionflow::props::RegionMatchResultList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure to store list \lof RegionMatchResult.\l&quot;];
    &quot;ELOCR/model&quot; [label=&quot;id: ELOCR/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;ELOCR/pred.characters&quot; [label=&quot;id: ELOCR/pred.characters\ltype: visionflow::props::MultiNamesPolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELOCR/pred.strings&quot; [label=&quot;id: ELOCR/pred.strings\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELOCR/statistician&quot; [label=&quot;id: ELOCR/statistician\ltype: visionflow::confs::OCRRegionMatchResultCounter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count ocr region \lmatch results.\l&quot;];
    &quot;ELOCR/statistics&quot; [label=&quot;id: ELOCR/statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;ELOCR/strings_statistician&quot; [label=&quot;id: ELOCR/strings_statistician\ltype: visionflow::confs::RegionMatchResultCounter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to count region match \lresults.\l&quot;];
    &quot;ELOCR/strings_statistics&quot; [label=&quot;id: ELOCR/strings_statistics\ltype: visionflow::param::ModelEvaluationMetrics\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage table.\l&quot;];
    &quot;ELOCR/tagged_polygons&quot; [label=&quot;id: ELOCR/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;ELOCR/tagged_views&quot; [label=&quot;id: ELOCR/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;ELOCR/templates&quot; [label=&quot;id: ELOCR/templates\ltype: visionflow::param::OCRTemplates\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ELOCR/templates_conf&quot; [label=&quot;id: ELOCR/templates_conf\ltype: visionflow::confs::OCRTemplateConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to config OCR \lstring match templates.\l&quot;];
    &quot;ELOCR/trainer&quot; [label=&quot;id: ELOCR/trainer\ltype: visionflow::confs::ELOCRTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: EL-OCR model trainer.\l&quot;];
    &quot;ELOCR/trainer.args&quot; [label=&quot;id: ELOCR/trainer.args\ltype: visionflow::param::ELOCRTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ELOCR/trainer.conf&quot; [label=&quot;id: ELOCR/trainer.conf\ltype: visionflow::confs::ELOCRTrainerConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set EL-OCR trainer \loptions.\l&quot;];
    &quot;ELOCR/training_log&quot; [label=&quot;id: ELOCR/training_log\ltype: visionflow::param::TrainingLog\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ELOCR/truth&quot; [label=&quot;id: ELOCR/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELOCR/truth.strings&quot; [label=&quot;id: ELOCR/truth.strings\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELOCR/truth_string_matcher&quot; [label=&quot;id: ELOCR/truth_string_matcher\ltype: visionflow::opers::OCRTruthStringMatcher\lupdate: 1970-01-01 00:00:00.0000000\ldocs: OCR truth string matcher.\l&quot;];
    &quot;ELOCR/universal_conf&quot; [label=&quot;id: ELOCR/universal_conf\ltype: visionflow::confs::ELOCRUniversalModelConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: EL-OCR universal model configurator.\l&quot;];
    &quot;ELOCR/view_tagger&quot; [label=&quot;id: ELOCR/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;]
  }

  &quot;ELOCR/batch_size&quot; -&gt; &quot;ELOCR/infer&quot;;
  &quot;ELOCR/batch_size_conf&quot; -&gt; &quot;ELOCR/batch_size&quot;;
  &quot;ELOCR/classes&quot; -&gt; &quot;ELOCR/label_oper&quot;;
  &quot;ELOCR/classes&quot; -&gt; &quot;ELOCR/trainer&quot;;
  &quot;ELOCR/comparator&quot; -&gt; &quot;ELOCR/match_result&quot;;
  &quot;ELOCR/image&quot; -&gt; &quot;ELOCR/infer&quot;;
  &quot;ELOCR/image&quot; -&gt; &quot;ELOCR/label_oper&quot;;
  &quot;ELOCR/image&quot; -&gt; &quot;ELOCR/trainer&quot;;
  &quot;ELOCR/infer&quot; -&gt; &quot;ELOCR/pred.characters&quot;;
  &quot;ELOCR/infer.args&quot; -&gt; &quot;ELOCR/infer&quot;;
  &quot;ELOCR/infer.conf&quot; -&gt; &quot;ELOCR/infer.args&quot;;
  &quot;ELOCR/infer_string_matcher&quot; -&gt; &quot;ELOCR/pred.strings&quot;;
  &quot;ELOCR/label_classes.conf&quot; -&gt; &quot;ELOCR/classes&quot;;
  &quot;ELOCR/label_oper&quot; -&gt; &quot;ELOCR/mask&quot;;
  &quot;ELOCR/label_oper&quot; -&gt; &quot;ELOCR/tagged_polygons&quot;;
  &quot;ELOCR/label_oper&quot; -&gt; &quot;ELOCR/truth&quot;;
  &quot;ELOCR/label_oper.args&quot; -&gt; &quot;ELOCR/label_oper&quot;;
  &quot;ELOCR/label_oper.conf&quot; -&gt; &quot;ELOCR/label_oper.args&quot;;
  &quot;ELOCR/mask&quot; -&gt; &quot;ELOCR/statistician&quot;;
  &quot;ELOCR/mask&quot; -&gt; &quot;ELOCR/trainer&quot;;
  &quot;ELOCR/model&quot; -&gt; &quot;ELOCR/infer&quot;;
  &quot;ELOCR/model&quot; -&gt; &quot;ELOCR/infer_string_matcher&quot;;
  &quot;ELOCR/model&quot; -&gt; &quot;ELOCR/truth_string_matcher&quot;;
  &quot;ELOCR/pred.characters&quot; -&gt; &quot;ELOCR/comparator&quot;;
  &quot;ELOCR/pred.characters&quot; -&gt; &quot;ELOCR/infer_string_matcher&quot;;
  &quot;ELOCR/pred.characters&quot; -&gt; &quot;ELOCR/statistician&quot;;
  &quot;ELOCR/pred.strings&quot; -&gt; &quot;ELOCR/strings_statistician&quot;;
  &quot;ELOCR/statistician&quot; -&gt; &quot;ELOCR/statistics&quot;;
  &quot;ELOCR/strings_statistician&quot; -&gt; &quot;ELOCR/strings_statistics&quot;;
  &quot;ELOCR/tagged_polygons&quot; -&gt; &quot;ELOCR/view_tagger&quot;;
  &quot;ELOCR/tagged_views&quot; -&gt; &quot;ELOCR/comparator&quot;;
  &quot;ELOCR/tagged_views&quot; -&gt; &quot;ELOCR/statistician&quot;;
  &quot;ELOCR/tagged_views&quot; -&gt; &quot;ELOCR/strings_statistician&quot;;
  &quot;ELOCR/tagged_views&quot; -&gt; &quot;ELOCR/trainer&quot;;
  &quot;ELOCR/templates&quot; -&gt; &quot;ELOCR/infer_string_matcher&quot;;
  &quot;ELOCR/templates&quot; -&gt; &quot;ELOCR/truth_string_matcher&quot;;
  &quot;ELOCR/templates_conf&quot; -&gt; &quot;ELOCR/templates&quot;;
  &quot;ELOCR/trainer&quot; -&gt; &quot;ELOCR/model&quot;;
  &quot;ELOCR/trainer&quot; -&gt; &quot;ELOCR/training_log&quot;;
  &quot;ELOCR/trainer.args&quot; -&gt; &quot;ELOCR/trainer&quot;;
  &quot;ELOCR/trainer.args&quot; -&gt; &quot;ELOCR/universal_conf&quot;;
  &quot;ELOCR/trainer.conf&quot; -&gt; &quot;ELOCR/trainer.args&quot;;
  &quot;ELOCR/truth&quot; -&gt; &quot;ELOCR/comparator&quot;;
  &quot;ELOCR/truth&quot; -&gt; &quot;ELOCR/statistician&quot;;
  &quot;ELOCR/truth&quot; -&gt; &quot;ELOCR/trainer&quot;;
  &quot;ELOCR/truth&quot; -&gt; &quot;ELOCR/truth_string_matcher&quot;;
  &quot;ELOCR/truth.strings&quot; -&gt; &quot;ELOCR/strings_statistician&quot;;
  &quot;ELOCR/truth_string_matcher&quot; -&gt; &quot;ELOCR/truth.strings&quot;;
  &quot;ELOCR/universal_conf&quot; -&gt; &quot;ELOCR/model&quot;;
  &quot;ELOCR/view_tagger&quot; -&gt; &quot;ELOCR/tagged_views&quot;;
  &quot;ELOCR/views&quot; -&gt; &quot;ELOCR/infer&quot;;
  &quot;ELOCR/views&quot; -&gt; &quot;ELOCR/infer_string_matcher&quot;;
  &quot;ELOCR/views&quot; -&gt; &quot;ELOCR/truth_string_matcher&quot;;
  &quot;ELOCR/views&quot; -&gt; &quot;ELOCR/universal_conf&quot;;
  &quot;ELOCR/views&quot; -&gt; &quot;ELOCR/view_tagger&quot;

}</p></object></div>
</section>
<section id="elunsupersegmentation-tool">
<h2>ELUnsuperSegmentation Tool<a class="headerlink" href="#elunsupersegmentation-tool" title="Link to this heading">#</a></h2>
<p>EL Unsupervised Segmentation Tool, suitable for projects with good image consistency and obvious defects, where defective areas need to be detected.</p>
<div class="graphviz"><object data="../_images/graphviz-16afea716c124aee290fda97af4e48e96d6a4606.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: ELUnsuperSegmentation&quot; {
  label=&quot;OnlyTool: ELUnsuperSegmentation&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;ELUnsuperSegmentation/featmap_filter&quot;;
  &quot;ELUnsuperSegmentation/filter&quot;;
  &quot;ELUnsuperSegmentation/infer&quot;;
  &quot;ELUnsuperSegmentation/label_oper&quot;;
  &quot;ELUnsuperSegmentation/view_tagger&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;ELUnsuperSegmentation/featmap_filter.conf&quot;;
  &quot;ELUnsuperSegmentation/filter.conf&quot;;
  &quot;ELUnsuperSegmentation/infer.conf&quot;;
  &quot;ELUnsuperSegmentation/label_oper.conf&quot;;
  &quot;ELUnsuperSegmentation/trainer&quot;;
  &quot;ELUnsuperSegmentation/trainer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style
  &quot;ELUnsuperSegmentation/feature_map&quot;;
  &quot;ELUnsuperSegmentation/raw_pred&quot;;
  &quot;ELUnsuperSegmentation/tagged_polygons&quot;;
  &quot;ELUnsuperSegmentation/tagged_views&quot;;
  &quot;ELUnsuperSegmentation/truth&quot;

  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;ELUnsuperSegmentation/image&quot;;
  &quot;ELUnsuperSegmentation/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;ELUnsuperSegmentation/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;ELUnsuperSegmentation/featmap_filter.args&quot;;
  &quot;ELUnsuperSegmentation/filter.args&quot;;
  &quot;ELUnsuperSegmentation/infer.args&quot;;
  &quot;ELUnsuperSegmentation/label_oper.args&quot;;
  &quot;ELUnsuperSegmentation/model&quot;;
  &quot;ELUnsuperSegmentation/trainer.args&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style



  subgraph &quot;cluster_ELUnsuperSegmentation&quot; {
    label=&quot;ELUnsuperSegmentation&quot;;
    &quot;ELUnsuperSegmentation/featmap_filter&quot; [label=&quot;id: ELUnsuperSegmentation/featmap_filter\ltype: visionflow::opers::SegmentationFeatureMapFilter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator to filter feature map \linto list of polygon regions.\l&quot;];
    &quot;ELUnsuperSegmentation/featmap_filter.args&quot; [label=&quot;id: ELUnsuperSegmentation/featmap_filter.args\ltype: visionflow::param::FeatureMapFilterParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Parameters to config the feature \lmap filter.\l&quot;];
    &quot;ELUnsuperSegmentation/featmap_filter.conf&quot; [label=&quot;id: ELUnsuperSegmentation/featmap_filter.conf\ltype: visionflow::confs::FeatureMapFilterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to config the \lfeature map filter.\l&quot;];
    &quot;ELUnsuperSegmentation/feature_map&quot; [label=&quot;id: ELUnsuperSegmentation/feature_map\ltype: visionflow::props::FeatureMap\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A data structure used to store \lfeature maps detected by each \lalgorithm module.\l&quot;];
    &quot;ELUnsuperSegmentation/filter&quot; [label=&quot;id: ELUnsuperSegmentation/filter\ltype: visionflow::opers::PolygonsFilter\lupdate: 1970-01-01 00:00:00.0000000\ldocs: An operator to filter list of \lregions with some common thresholds \lor customized python filter script.\l&quot;];
    &quot;ELUnsuperSegmentation/filter.args&quot; [label=&quot;id: ELUnsuperSegmentation/filter.args\ltype: visionflow::param::PolygonsFilterParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ELUnsuperSegmentation/filter.conf&quot; [label=&quot;id: ELUnsuperSegmentation/filter.conf\ltype: visionflow::confs::PolygonsFilterConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator UI to generate the \lpolygon filter args.\l&quot;];
    &quot;ELUnsuperSegmentation/infer&quot; [label=&quot;id: ELUnsuperSegmentation/infer\ltype: visionflow::opers::ELUnsuperSegmentationInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: EL-UnsuperSegmentation inference \loperator.\l&quot;];
    &quot;ELUnsuperSegmentation/infer.args&quot; [label=&quot;id: ELUnsuperSegmentation/infer.args\ltype: visionflow::param::ELUnsuperSegmentationInferParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ELUnsuperSegmentation/infer.conf&quot; [label=&quot;id: ELUnsuperSegmentation/infer.conf\ltype: visionflow::confs::ELUnsuperSegmentationInferConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: EL-UnsuperSegmentation heatmap \lfilter parameters configurator.\l&quot;];
    &quot;ELUnsuperSegmentation/label_oper&quot; [label=&quot;id: ELUnsuperSegmentation/label_oper\ltype: visionflow::opers::ELUnsuperSegmentationLabeler\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Annotate operator for EL-UnsuperSegmentation \ltool.\l&quot;];
    &quot;ELUnsuperSegmentation/label_oper.args&quot; [label=&quot;id: ELUnsuperSegmentation/label_oper.args\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;ELUnsuperSegmentation/label_oper.conf&quot; [label=&quot;id: ELUnsuperSegmentation/label_oper.conf\ltype: visionflow::confs::CustomConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator class to generate \lany user-defined parameters\l&quot;];
    &quot;ELUnsuperSegmentation/model&quot; [label=&quot;id: ELUnsuperSegmentation/model\ltype: visionflow::param::BinaryPacks\lupdate: 1970-01-01 00:00:00.0000000\ldocs: A container to manage list of \lbinary data.\l&quot;];
    &quot;ELUnsuperSegmentation/pred&quot; [label=&quot;id: ELUnsuperSegmentation/pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELUnsuperSegmentation/raw_pred&quot; [label=&quot;id: ELUnsuperSegmentation/raw_pred\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELUnsuperSegmentation/tagged_polygons&quot; [label=&quot;id: ELUnsuperSegmentation/tagged_polygons\ltype: visionflow::props::TaggedPolygonList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property TaggedPolygonList implementation.\l&quot;];
    &quot;ELUnsuperSegmentation/tagged_views&quot; [label=&quot;id: ELUnsuperSegmentation/tagged_views\ltype: visionflow::props::ViewList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Property ViewList implementation.\l&quot;];
    &quot;ELUnsuperSegmentation/trainer&quot; [label=&quot;id: ELUnsuperSegmentation/trainer\ltype: visionflow::confs::ELUnsuperSegmentationTrainer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: EL-UnsuperSegmentation model trainer.\l&quot;];
    &quot;ELUnsuperSegmentation/trainer.args&quot; [label=&quot;id: ELUnsuperSegmentation/trainer.args\ltype: visionflow::param::ELUnsuperSegmentationTrainingParameters\lupdate: 1970-01-01 00:00:00.0000000\l&quot;];
    &quot;ELUnsuperSegmentation/trainer.conf&quot; [label=&quot;id: ELUnsuperSegmentation/trainer.conf\ltype: visionflow::confs::ELUnsuperSegmentationTrainingConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: EL-UnsuperSegmentation Training \lParameters Configurator.\l&quot;];
    &quot;ELUnsuperSegmentation/truth&quot; [label=&quot;id: ELUnsuperSegmentation/truth\ltype: visionflow::props::PolygonRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;];
    &quot;ELUnsuperSegmentation/view_tagger&quot; [label=&quot;id: ELUnsuperSegmentation/view_tagger\ltype: visionflow::opers::ViewTagger\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Operator used to tag the views \lwith some already tagged polygons \lautomatically. The spilt_tag and \ltags of the most matched tagged_polygon \lselected using CIou will be set \lto the view, otherwise, the view \lwill remain its original spilt_tag \land tags info.\l&quot;]
  }

  &quot;ELUnsuperSegmentation/featmap_filter&quot; -&gt; &quot;ELUnsuperSegmentation/raw_pred&quot;;
  &quot;ELUnsuperSegmentation/featmap_filter.args&quot; -&gt; &quot;ELUnsuperSegmentation/featmap_filter&quot;;
  &quot;ELUnsuperSegmentation/featmap_filter.conf&quot; -&gt; &quot;ELUnsuperSegmentation/featmap_filter.args&quot;;
  &quot;ELUnsuperSegmentation/feature_map&quot; -&gt; &quot;ELUnsuperSegmentation/featmap_filter&quot;;
  &quot;ELUnsuperSegmentation/filter&quot; -&gt; &quot;ELUnsuperSegmentation/pred&quot;;
  &quot;ELUnsuperSegmentation/filter.args&quot; -&gt; &quot;ELUnsuperSegmentation/filter&quot;;
  &quot;ELUnsuperSegmentation/filter.conf&quot; -&gt; &quot;ELUnsuperSegmentation/filter.args&quot;;
  &quot;ELUnsuperSegmentation/image&quot; -&gt; &quot;ELUnsuperSegmentation/infer&quot;;
  &quot;ELUnsuperSegmentation/image&quot; -&gt; &quot;ELUnsuperSegmentation/label_oper&quot;;
  &quot;ELUnsuperSegmentation/image&quot; -&gt; &quot;ELUnsuperSegmentation/trainer&quot;;
  &quot;ELUnsuperSegmentation/infer&quot; -&gt; &quot;ELUnsuperSegmentation/feature_map&quot;;
  &quot;ELUnsuperSegmentation/infer.args&quot; -&gt; &quot;ELUnsuperSegmentation/infer&quot;;
  &quot;ELUnsuperSegmentation/infer.conf&quot; -&gt; &quot;ELUnsuperSegmentation/infer.args&quot;;
  &quot;ELUnsuperSegmentation/label_oper&quot; -&gt; &quot;ELUnsuperSegmentation/tagged_polygons&quot;;
  &quot;ELUnsuperSegmentation/label_oper&quot; -&gt; &quot;ELUnsuperSegmentation/truth&quot;;
  &quot;ELUnsuperSegmentation/label_oper.args&quot; -&gt; &quot;ELUnsuperSegmentation/label_oper&quot;;
  &quot;ELUnsuperSegmentation/label_oper.conf&quot; -&gt; &quot;ELUnsuperSegmentation/label_oper.args&quot;;
  &quot;ELUnsuperSegmentation/model&quot; -&gt; &quot;ELUnsuperSegmentation/infer&quot;;
  &quot;ELUnsuperSegmentation/raw_pred&quot; -&gt; &quot;ELUnsuperSegmentation/filter&quot;;
  &quot;ELUnsuperSegmentation/tagged_polygons&quot; -&gt; &quot;ELUnsuperSegmentation/view_tagger&quot;;
  &quot;ELUnsuperSegmentation/tagged_views&quot; -&gt; &quot;ELUnsuperSegmentation/trainer&quot;;
  &quot;ELUnsuperSegmentation/trainer&quot; -&gt; &quot;ELUnsuperSegmentation/model&quot;;
  &quot;ELUnsuperSegmentation/trainer.args&quot; -&gt; &quot;ELUnsuperSegmentation/trainer&quot;;
  &quot;ELUnsuperSegmentation/trainer.conf&quot; -&gt; &quot;ELUnsuperSegmentation/trainer.args&quot;;
  &quot;ELUnsuperSegmentation/truth&quot; -&gt; &quot;ELUnsuperSegmentation/trainer&quot;;
  &quot;ELUnsuperSegmentation/view_tagger&quot; -&gt; &quot;ELUnsuperSegmentation/tagged_views&quot;;
  &quot;ELUnsuperSegmentation/views&quot; -&gt; &quot;ELUnsuperSegmentation/infer&quot;;
  &quot;ELUnsuperSegmentation/views&quot; -&gt; &quot;ELUnsuperSegmentation/view_tagger&quot;

}</p></object></div>
</section>
<section id="gauge-tool">
<h2>Gauge Tool<a class="headerlink" href="#gauge-tool" title="Link to this heading">#</a></h2>
<p>Gauge Tool.</p>
<div class="graphviz"><object data="../_images/graphviz-f75acc0ebcf525209aa21a2d03695869704e5248.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph &quot;OnlyTool: Gauge&quot; {
  label=&quot;OnlyTool: Gauge&quot;;
  rankdir=&quot;TB&quot;;

  node [shape=ellipse, style=filled, color=blue, fillcolor=lightblue]; // Operator style
  &quot;Gauge/infer&quot;

  node [shape=ellipse, style=filled, color=red, fillcolor=pink]; // Configurator style
  &quot;Gauge/infer.conf&quot;

  node [shape=rect, style=filled, color=blue, fillcolor=lightblue]; // Property style


  node [shape=point, style=filled, color=blue, fillcolor=lightblue]; // SingleVirtualInput property style
  &quot;Gauge/image&quot;;
  &quot;Gauge/views&quot;

  node [shape=invtriangle, style=filled, color=blue, fillcolor=lightblue]; // MultiVirtualInput property style


  node [shape=rect, style=dashed, color=blue, fillcolor=default]; // Output property style
  &quot;Gauge/pred&quot;

  node [shape=rect, style=filled, color=red, fillcolor=pink]; // Parameter style
  &quot;Gauge/infer.args&quot;

  node [shape=point, style=filled, color=red, fillcolor=pink]; // SingleVirtualInput parameter style


  node [shape=invtriangle, style=filled, color=red, fillcolor=pink]; // MultiVirtualInput parameter style


  node [shape=rect, style=dashed, color=red, fillcolor=default]; // Output parameter style



  subgraph &quot;cluster_Gauge&quot; {
    label=&quot;Gauge&quot;;
    &quot;Gauge/infer&quot; [label=&quot;id: Gauge/infer\ltype: visionflow::opers::GaugeInfer\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Gauge tool inference operator.\l&quot;];
    &quot;Gauge/infer.args&quot; [label=&quot;id: Gauge/infer.args\ltype: visionflow::param::GaugeParameters\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Parameter for gauge tool.\l&quot;];
    &quot;Gauge/infer.conf&quot; [label=&quot;id: Gauge/infer.conf\ltype: visionflow::confs::GaugeInferConf\lupdate: 1970-01-01 00:00:00.0000000\ldocs: Configurator to set Gauge tool \lparameters.\l&quot;];
    &quot;Gauge/pred&quot; [label=&quot;id: Gauge/pred\ltype: visionflow::props::GaugeRegionList\lupdate: 1970-01-01 00:00:00.0000000\ldocs: List structure to manage polygon \lregions.\l&quot;]
  }

  &quot;Gauge/image&quot; -&gt; &quot;Gauge/infer&quot;;
  &quot;Gauge/infer&quot; -&gt; &quot;Gauge/pred&quot;;
  &quot;Gauge/infer.args&quot; -&gt; &quot;Gauge/infer&quot;;
  &quot;Gauge/infer.conf&quot; -&gt; &quot;Gauge/infer.args&quot;;
  &quot;Gauge/views&quot; -&gt; &quot;Gauge/infer&quot;

}</p></object></div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../cpp_api/cpp_index.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">C++ API Reference</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../advanced_topics/image_draw.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">图片绘制几何图形和文字</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2017-2025, Aqrose-Technology Co., Ltd. All rights reserved.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">工具清单及详细流程图</a><ul>
<li><a class="reference internal" href="#idreader-tool">IDReader Tool</a></li>
<li><a class="reference internal" href="#unsupersegmentation-tool">UnsuperSegmentation Tool</a></li>
<li><a class="reference internal" href="#input-tool">Input Tool</a></li>
<li><a class="reference internal" href="#ocr-tool">OCR Tool</a></li>
<li><a class="reference internal" href="#segmentation-tool">Segmentation Tool</a></li>
<li><a class="reference internal" href="#integration-tool">Integration Tool</a></li>
<li><a class="reference internal" href="#geometrysearch-tool">GeometrySearch Tool</a></li>
<li><a class="reference internal" href="#unsuperclassification-tool">UnsuperClassification Tool</a></li>
<li><a class="reference internal" href="#assemblyverification-tool">AssemblyVerification Tool</a></li>
<li><a class="reference internal" href="#location-tool">Location Tool</a></li>
<li><a class="reference internal" href="#classification-tool">Classification Tool</a></li>
<li><a class="reference internal" href="#elclassification-tool">ELClassification Tool</a></li>
<li><a class="reference internal" href="#elunsuperclassification-tool">ELUnsuperClassification Tool</a></li>
<li><a class="reference internal" href="#detection-tool">Detection Tool</a></li>
<li><a class="reference internal" href="#cameracalibration-tool">CameraCalibration Tool</a></li>
<li><a class="reference internal" href="#viewtransformer-tool">ViewTransformer Tool</a></li>
<li><a class="reference internal" href="#regioncalculation-tool">RegionCalculation Tool</a></li>
<li><a class="reference internal" href="#elocr-tool">ELOCR Tool</a></li>
<li><a class="reference internal" href="#elunsupersegmentation-tool">ELUnsuperSegmentation Tool</a></li>
<li><a class="reference internal" href="#gauge-tool">Gauge Tool</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=bd972503"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    <script src="../_static/tabs.js?v=3ee01567"></script>
    </body>
</html>